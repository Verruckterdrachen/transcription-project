### ‚îÅ‚îÅ‚îÅ 2. docs/TESTING-STRATEGY.md ‚îÅ‚îÅ‚îÅ

```markdown
# üß™ TESTING STRATEGY

–°—Ç—Ä–∞—Ç–µ–≥–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏.

---

## üéØ –§–ò–õ–û–°–û–§–ò–Ø

**Test-Driven Debugging (TDD for Bugs):**
–ë–∞–≥ –Ω–∞–π–¥–µ–Ω ‚Üí Unit test –Ω–∞–ø–∏—Å–∞–Ω ‚Üí –§–∏–∫—Å —Å–æ–∑–¥–∞–Ω ‚Üí –¢–µ—Å—Ç –ø—Ä–æ—à—ë–ª ‚Üí ‚úÖ

text

**–¶–µ–ª—å:** –ö–∞–∂–¥—ã–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π –±–∞–≥ –∑–∞—â–∏—â—ë–Ω unit test –æ—Ç –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ—è–≤–ª–µ–Ω–∏—è

---

## üìä –£–†–û–í–ù–ò –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø

### 1Ô∏è‚É£ Unit Tests (–∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–π)

**–ß—Ç–æ —Ç–µ—Å—Ç–∏—Ä—É–µ–º:**
- ‚úÖ Regex –ø–∞—Ç—Ç–µ—Ä–Ω—ã (`is_journalist_phrase`, `is_expert_phrase`)
- ‚úÖ Text similarity (`text_similarity`)
- ‚úÖ –£—Ç–∏–ª–∏—Ç—ã (`seconds_to_hms`, `format_timestamp`)
- ‚úÖ –í–∞–ª–∏–¥–∞—Ç–æ—Ä—ã (–ø—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö)

**–ü—Ä–∏–º–µ—Ä:**
```python
# tests/test_regex_patterns.py
def test_journalist_phrase_word_boundary():
    """v16.16: Word boundary protection"""
    # –î–æ–ª–∂–Ω—ã –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å—Å—è –∫–∞–∫ –∂—É—Ä–Ω–∞–ª–∏—Å—Ç—Å–∫–∏–µ
    assert is_journalist_phrase("–≤—ã –º–æ–∂–µ—Ç–µ –æ–±—ä—è—Å–Ω–∏—Ç—å") == True
    
    # –ù–ï –¥–æ–ª–∂–Ω—ã (false positives)
    assert is_journalist_phrase("–±–µ—Ä–µ–≥—É –ù–µ–≤—ã") == False
    assert is_journalist_phrase("—Å–æ–≤—ã –ª–µ—Ç–∞—é—Ç") == False
–ó–∞–ø—É—Å–∫:

bash
pytest tests/test_regex_patterns.py -v
2Ô∏è‚É£ Integration Tests (—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥—É–ª–µ–π –≤–º–µ—Å—Ç–µ)
–ß—Ç–æ —Ç–µ—Å—Ç–∏—Ä—É–µ–º:

‚úÖ Pipeline —ç—Ç–∞–ø–æ–≤ (diarization ‚Üí transcription ‚Üí alignment)

‚úÖ –ú–æ–¥—É–ª–∏ corrections (boundary_fixer ‚Üí speaker_classifier)

‚úÖ Export (JSON, TXT –≥–µ–Ω–µ—Ä–∞—Ü–∏—è)

–ü—Ä–∏–º–µ—Ä:

python
# tests/test_pipeline.py
def test_split_mixed_segments_sync():
    """v16.12: speaker –∏ raw_speaker_id —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω—ã"""
    segments = [
        {"speaker": "–ò—Å–∞–µ–≤", "raw_speaker_id": "SPEAKER_01", "text": "–ù–∞—á–∞–ª–æ. –†–∞—Å—Å–∫–∞–∂–∏—Ç–µ –ø–æ–¥—Ä–æ–±–Ω–µ–µ."}
    ]
    
    result = split_mixed_speaker_segments(segments, "–ò—Å–∞–µ–≤", {"SPEAKER_01": "–ò—Å–∞–µ–≤", "SPEAKER_00": "–ñ—É—Ä–Ω–∞–ª–∏—Å—Ç"})
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é
    for seg in result:
        if seg["speaker"] == "–ñ—É—Ä–Ω–∞–ª–∏—Å—Ç":
            assert seg["raw_speaker_id"] == "SPEAKER_00", "raw_speaker_id –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω!"
3Ô∏è‚É£ End-to-End Tests (–ø–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω)
–ß—Ç–æ —Ç–µ—Å—Ç–∏—Ä—É–µ–º:

‚úÖ –í–µ—Å—å pipeline –æ—Ç WAV ‚Üí JSON + TXT

‚úÖ Golden output comparison (—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å —ç—Ç–∞–ª–æ–Ω–æ–º)

‚úÖ Regression tests (–Ω–æ–≤—ã–π –∫–æ–¥ –Ω–µ –ª–æ–º–∞–µ—Ç —Å—Ç–∞—Ä–æ–µ)

–ü—Ä–∏–º–µ—Ä:

bash
# tests/test_e2e.py
def test_full_pipeline_expert():
    """–ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –¥–ª—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞ —ç–∫—Å–ø–µ—Ä—Ç–∞"""
    input_wav = "tests/fixtures/expert_sample.wav"
    expected_txt = "tests/golden/expert_sample.txt"
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º pipeline
    result_txt = run_pipeline(input_wav)
    
    # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å golden output
    assert_text_similar(result_txt, expected_txt, threshold=0.95)
üóÇÔ∏è –°–¢–†–£–ö–¢–£–†–ê –¢–ï–°–¢–û–í
text
tests/
‚îú‚îÄ‚îÄ test_regex_patterns.py      # Unit tests –¥–ª—è regex
‚îú‚îÄ‚îÄ test_text_utils.py           # Unit tests –¥–ª—è —É—Ç–∏–ª–∏—Ç
‚îú‚îÄ‚îÄ test_pipeline_modules.py     # Integration tests –¥–ª—è –º–æ–¥—É–ª–µ–π
‚îú‚îÄ‚îÄ test_speaker_attribution.py # Integration tests –¥–ª—è –∞—Ç—Ä–∏–±—É—Ü–∏–∏
‚îú‚îÄ‚îÄ test_e2e.py                  # End-to-end tests
‚îú‚îÄ‚îÄ fixtures/                    # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
‚îÇ   ‚îú‚îÄ‚îÄ expert_sample.wav
‚îÇ   ‚îú‚îÄ‚îÄ journalist_sample.wav
‚îÇ   ‚îî‚îÄ‚îÄ edge_cases.txt
‚îî‚îÄ‚îÄ golden/                      # –≠—Ç–∞–ª–æ–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    ‚îú‚îÄ‚îÄ expert_sample.txt
    ‚îú‚îÄ‚îÄ expert_sample.json
    ‚îî‚îÄ‚îÄ ...
üìã TEST COVERAGE GOALS
–ö–∞—Ç–µ–≥–æ—Ä–∏—è	–¢–µ–∫—É—â–∏–π Coverage	–¶–µ–ª—å	–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç
Regex –ø–∞—Ç—Ç–µ—Ä–Ω—ã	0%	100%	üî• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π
Text utilities	0%	80%	‚ö†Ô∏è –í—ã—Å–æ–∫–∏–π
Speaker attribution	0%	90%	‚ö†Ô∏è –í—ã—Å–æ–∫–∏–π
Pipeline modules	0%	70%	üü° –°—Ä–µ–¥–Ω–∏–π
Export functions	0%	60%	üü° –°—Ä–µ–¥–Ω–∏–π
E2E tests	0%	3-5 scenarios	üü° –°—Ä–µ–¥–Ω–∏–π
üö¶ TESTING WORKFLOW
–ü—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –Ω–æ–≤–æ–π —Ñ—É–Ω–∫—Ü–∏–∏:
text
1. –ù–∞–ø–∏—Å–∞—Ç—å function signature + docstring
2. –ù–∞–ø–∏—Å–∞—Ç—å unit tests (TDD!)
3. –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏—é
4. –ó–∞–ø—É—Å—Ç–∏—Ç—å tests ‚Üí GREEN ‚úÖ
5. –ö–æ–º–º–∏—Ç (–∫–æ–¥ + —Ç–µ—Å—Ç—ã –≤–º–µ—Å—Ç–µ)
–ü—Ä–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–∏ –±–∞–≥–∞:
text
1. –í–æ—Å–ø—Ä–æ–∏–∑–≤–µ—Å—Ç–∏ –±–∞–≥ (minimal example)
2. –ù–∞–ø–∏—Å–∞—Ç—å failing test (RED ‚ùå)
3. –ù–∞–π—Ç–∏ ROOT CAUSE (5 Whys)
4. –ò—Å–ø—Ä–∞–≤–∏—Ç—å –±–∞–≥
5. –ó–∞–ø—É—Å—Ç–∏—Ç—å test ‚Üí GREEN ‚úÖ
6. –ö–æ–º–º–∏—Ç (—Ñ–∏–∫—Å + —Ç–µ—Å—Ç –≤–º–µ—Å—Ç–µ)
üß™ –ü–†–ò–ú–ï–†–´ UNIT TESTS
test_regex_patterns.py
python
import pytest
from corrections.boundary_fixer import (
    is_journalist_phrase,
    is_expert_phrase,
    is_continuation_phrase
)

class TestJournalistPhraseDetection:
    """v16.16: –¢–µ—Å—Ç—ã –¥–ª—è –∂—É—Ä–Ω–∞–ª–∏—Å—Ç—Å–∫–∏—Ö —Ñ—Ä–∞–∑"""
    
    def test_positive_cases(self):
        """–§—Ä–∞–∑—ã, –∫–æ—Ç–æ—Ä—ã–µ –î–û–õ–ñ–ù–´ –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å—Å—è –∫–∞–∫ –∂—É—Ä–Ω–∞–ª–∏—Å—Ç—Å–∫–∏–µ"""
        assert is_journalist_phrase("–≤—ã –º–æ–∂–µ—Ç–µ –æ–±—ä—è—Å–Ω–∏—Ç—å") == True
        assert is_journalist_phrase("—Ä–∞—Å—Å–∫–∞–∂–∏—Ç–µ –Ω–∞–º –ø–æ–¥—Ä–æ–±–Ω–µ–µ") == True
        assert is_journalist_phrase("–¥–∞–≤–∞–π—Ç–µ –æ–±—Å—É–¥–∏–º") == True
        assert is_journalist_phrase("–∫–∞–∫ –≤—ã —Å—á–∏—Ç–∞–µ—Ç–µ") == True
        assert is_journalist_phrase("–ø–æ—á–µ–º—É –≤—ã –≤—ã–±—Ä–∞–ª–∏") == True
    
    def test_false_positives_v16_16(self):
        """v16.16 BUG FIX: –°–ª–æ–≤–∞ —Å '–≤—ã' –≤–Ω—É—Ç—Ä–∏ –ù–ï –¥–æ–ª–∂–Ω—ã –ª–æ–≤–∏—Ç—å—Å—è"""
        # Root cause v16.16: regex –±–µ–∑ word boundary
        assert is_journalist_phrase("–Ω–∞ –≤–æ—Å—Ç–æ—á–Ω–æ–º –±–µ—Ä–µ–≥—É –ù–µ–≤—ã") == False
        assert is_journalist_phrase("—Å–æ–≤—ã –æ—Ö–æ—Ç—è—Ç—Å—è –Ω–æ—á—å—é") == False
        assert is_journalist_phrase("—É –∫—Ä–æ–≤—ã –µ—Å—Ç—å –∫—Ä—ã—à–∞") == False
        assert is_journalist_phrase("–ø—Ä–∞–≤—ã –±—ã–ª–∏ –≤—Å–µ") == False
        assert is_journalist_phrase("–Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è —Ç–∞–∫") == False
    
    def test_edge_cases(self):
        """–ü–æ–≥—Ä–∞–Ω–∏—á–Ω—ã–µ —Å–ª—É—á–∞–∏"""
        # "–≤—ã" –≤ –∫–æ–Ω—Ü–µ
        assert is_journalist_phrase("—ç—Ç–æ –±—ã–ª–∏ –≤—ã?") == True
        # "–≤—ã" –≤ –Ω–∞—á–∞–ª–µ
        assert is_journalist_phrase("–í—ã —É–≤–µ—Ä–µ–Ω—ã?") == True
        # Multiple markers
        assert is_journalist_phrase("–≤—ã –º–æ–∂–µ—Ç–µ —Ä–∞—Å—Å–∫–∞–∂–∏—Ç–µ") == True
        # Empty/None
        assert is_journalist_phrase("") == False
        assert is_journalist_phrase(None) == False

class TestExpertPhraseDetection:
    """–¢–µ—Å—Ç—ã –¥–ª—è —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã—Ö —Ñ—Ä–∞–∑"""
    
    def test_positive_cases(self):
        assert is_expert_phrase("—è —Å—á–∏—Ç–∞—é —á—Ç–æ", "–ò—Å–∞–µ–≤") == True
        assert is_expert_phrase("–Ω–∞ –º–æ–π –≤–∑–≥–ª—è–¥", "–ò—Å–∞–µ–≤") == True
        assert is_expert_phrase("–ø–æ –º–Ω–µ–Ω–∏—é –ò—Å–∞–µ–≤–∞", "–ò—Å–∞–µ–≤") == True
    
    def test_surname_detection(self):
        """–§–∞–º–∏–ª–∏—è —ç–∫—Å–ø–µ—Ä—Ç–∞ –≤ —Ç–µ–∫—Å—Ç–µ"""
        assert is_expert_phrase("–ò—Å–∞–µ–≤ —É—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç", "–ò—Å–∞–µ–≤") == True
        assert is_expert_phrase("–∫–∞–∫ —Å–∫–∞–∑–∞–ª –ò—Å–∞–µ–≤", "–ò—Å–∞–µ–≤") == True
        # –î—Ä—É–≥–∞—è —Ñ–∞–º–∏–ª–∏—è
        assert is_expert_phrase("–ü–µ—Ç—Ä–æ–≤ —Å—á–∏—Ç–∞–µ—Ç", "–ò—Å–∞–µ–≤") == False

class TestContinuationPhraseDetection:
    """v16.10: –¢–µ—Å—Ç—ã –¥–ª—è continuation phrases"""
    
    def test_positive_cases(self):
        assert is_continuation_phrase("–¢–æ –µ—Å—Ç—å —ç—Ç–æ –≤–∞–∂–Ω–æ") == True
        assert is_continuation_phrase("–í —á–∞—Å—Ç–Ω–æ—Å—Ç–∏ —Å—Ç–æ–∏—Ç –æ—Ç–º–µ—Ç–∏—Ç—å") == True
        assert is_continuation_phrase("–ö—Ä–æ–º–µ —Ç–æ–≥–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ") == True
    
    def test_negative_cases(self):
        """–ù–ï continuation phrases"""
        assert is_continuation_phrase("–≠—Ç–æ –≤–∞–∂–Ω—ã–π –º–æ–º–µ–Ω—Ç") == False
        assert is_continuation_phrase("–ù–∞—á–Ω—ë–º —Å —Ç–æ–≥–æ —á—Ç–æ") == False
test_text_utils.py
python
import pytest
from core.utils import text_similarity, seconds_to_hms

class TestTextSimilarity:
    """v16.5: –¢–µ—Å—Ç—ã –¥–ª—è text similarity"""
    
    def test_identical_texts(self):
        assert text_similarity("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä", "–ø—Ä–∏–≤–µ—Ç –º–∏—Ä") == 1.0
    
    def test_completely_different(self):
        assert text_similarity("–ø—Ä–∏–≤–µ—Ç", "goodbye") < 0.3
    
    def test_partial_similarity(self):
        text1 = "–ù–µ–≤—Å–∫–∏–π –ø—è—Ç–∞—á–æ–∫ –±—ã–ª –ø–ª–∞—Ü–¥–∞—Ä–º–æ–º"
        text2 = "–ù–µ–≤—Å–∫–∏–π –ø—è—Ç–∞—á–æ–∫ —Ö–æ—Ç—è –æ–Ω —Ä–∞—Å–ø–æ–ª–∞–≥–∞–ª—Å—è"
        similarity = text_similarity(text1, text2)
        assert 0.4 < similarity < 0.7

class TestTimeFormatting:
    """–¢–µ—Å—Ç—ã –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏"""
    
    def test_seconds_to_hms(self):
        assert seconds_to_hms(0) == "00:00:00"
        assert seconds_to_hms(65) == "00:01:05"
        assert seconds_to_hms(3661) == "01:01:01"
üéØ EDGE CASES COLLECTION
–°–æ–∑–¥–∞—ë–º tests/edge_cases.txt:

text
# Edge Cases –¥–ª—è regression testing

## Regex False Positives (v16.16)
- "–Ω–∞ –≤–æ—Å—Ç–æ—á–Ω–æ–º –±–µ—Ä–µ–≥—É –ù–µ–≤—ã –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–ª–æ—Å—å" ‚Üí –ù–ï –∂—É—Ä–Ω–∞–ª–∏—Å—Ç
- "—Å–æ–≤—ã –æ—Ö–æ—Ç—è—Ç—Å—è –≤ —Ç–µ–º–Ω–æ—Ç–µ" ‚Üí –ù–ï –∂—É—Ä–Ω–∞–ª–∏—Å—Ç
- "—É –∫—Ä–æ–≤—ã –ø—Ä–æ—Ç–µ–∫–∞–µ—Ç –∫—Ä—ã—à–∞" ‚Üí –ù–ï –∂—É—Ä–Ω–∞–ª–∏—Å—Ç

## Continuation Phrases (v16.10)
- "–¢–æ –µ—Å—Ç—å —Å –Ω–µ–±–æ–ª—å—à–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞" ‚Üí –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ
- "–í —á–∞—Å—Ç–Ω–æ—Å—Ç–∏ –æ—Ç–º–µ—á—É —á—Ç–æ" ‚Üí –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ
- "–ö—Ä–æ–º–µ —Ç–æ–≥–æ —Å—Ç–æ–∏—Ç —Å–∫–∞–∑–∞—Ç—å" ‚Üí –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ

## Short Confirmations
- "–î–∞." ‚Üí –∫–æ—Ä–æ—Ç–∫–æ–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
- "–ù—É –¥–∞." ‚Üí –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
- "–ê–≥–∞." ‚Üí –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ

## Question Announcements
- "–°–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å –ø—Ä–æ –õ–µ–Ω–∏–Ω–≥—Ä–∞–¥" ‚Üí –∞–Ω–æ–Ω—Å (–Ω–µ —Ä–∞–∑–¥–µ–ª—è—Ç—å)
- "–ï—â—ë –≤–æ–ø—Ä–æ—Å –æ –±–ª–æ–∫–∞–¥–µ" ‚Üí –∞–Ω–æ–Ω—Å

## Overlapping Speech
- –ñ—É—Ä–Ω–∞–ª–∏—Å—Ç –ø–µ—Ä–µ–±–∏–≤–∞–µ—Ç —ç–∫—Å–ø–µ—Ä—Ç–∞
- –ö–æ—Ä–æ—Ç–∫–∏–µ –≤—Å—Ç–∞–≤–∫–∏ (<0.5s)
üöÄ CONTINUOUS INTEGRATION (–±—É–¥—É—â–µ–µ)
–¶–µ–ª—å: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∑–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤ –ø—Ä–∏ –∫–∞–∂–¥–æ–º –∫–æ–º–º–∏—Ç–µ

text
# .github/workflows/tests.yml
name: Tests

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Setup Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.10
      - name: Install dependencies
        run: pip install -r requirements.txt
      - name: Run unit tests
        run: pytest tests/ -v --cov
      - name: Coverage report
        run: coverage report --fail-under=80
üìà METRICS & GOALS
–ö–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ü–µ–ª–∏:
Unit test coverage: 0% ‚Üí 80% (–∑–∞ Q2 2026)

Regression tests: 0 ‚Üí 20 edge cases

Bug reproduction time: 5.5 —á–∞—Å–æ–≤ ‚Üí <30 –º–∏–Ω

Iterations to fix: 8 ‚Üí ‚â§3

–ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ü–µ–ª–∏:
‚úÖ –ö–∞–∂–¥—ã–π –±–∞–≥ –∑–∞—â–∏—â—ë–Ω unit test

‚úÖ Regression suite –¥–ª—è –≤—Å–µ—Ö –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Ñ—É–Ω–∫—Ü–∏–π

‚úÖ Golden output –¥–ª—è end-to-end comparison

‚úÖ CI/CD pipeline —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º–∏ —Ç–µ—Å—Ç–∞–º–∏

–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: 11.02.2026
–í–µ—Ä—Å–∏—è: v16.17