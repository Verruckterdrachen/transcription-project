"""
merge/replica_merger.py - –°–∫–ª–µ–π–∫–∞ —Ä–µ–ø–ª–∏–∫ –æ–¥–Ω–æ–≥–æ —Å–ø–∏–∫–µ—Ä–∞

üÜï v16.20: DEBUG OUTPUT –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –∑–∞–≤–∏—Å–∞–Ω–∏—è
üÜï v16.14: –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX - speaker –æ—Ç –°–ê–ú–û–ì–û –î–õ–ò–ù–ù–û–ì–û —Å–µ–≥–º–µ–Ω—Ç–∞
"""

from difflib import SequenceMatcher
import re
from core.utils import seconds_to_hms
from corrections.hallucinations import clean_hallucinations_from_text

def clean_loops(text, debug=False):
    """
    üîß v16.1: –£–¥–∞–ª—è–µ—Ç –∑–∞—Ü–∏–∫–ª–µ–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã (loop artifacts)
    üÜï v16.20: –î–æ–±–∞–≤–ª–µ–Ω debug –ø–∞—Ä–∞–º–µ—Ç—Ä
    """
    if debug:
        print(f"    üßπ clean_loops: –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ ({len(text)} —Å–∏–º–≤–æ–ª–æ–≤, {len(text.split())} —Å–ª–æ–≤)")
    
    words = text.split()
    seen = set()
    cleaned = []

    i = 0
    while i < len(words):
        phrase = ' '.join(words[i:i+3])

        if phrase.lower() in seen:
            i += 1
            continue

        seen.add(phrase.lower())
        cleaned.extend(words[i:i+3])
        i += 3

    final = ' '.join(cleaned)
    final = re.sub(r'([.,!?])\1{2,}', r'\1', final)

    if debug:
        print(f"    ‚úÖ clean_loops: –≥–æ—Ç–æ–≤–æ ({len(final)} —Å–∏–º–≤–æ–ª–æ–≤)")

    return final.strip()

def merge_replicas(segments, debug=False):
    """
    üîß v16.14: –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX - speaker –æ—Ç –°–ê–ú–û–ì–û –î–õ–ò–ù–ù–û–ì–û —Å–µ–≥–º–µ–Ω—Ç–∞!
    üÜï v16.20: –î–æ–±–∞–≤–ª–µ–Ω debug –ø–∞—Ä–∞–º–µ—Ç—Ä –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –∑–∞–≤–∏—Å–∞–Ω–∏—è

    **–ü—Ä–æ–±–ª–µ–º–∞ v16.13:** –ü—Ä–∏ merge –±—Ä–∞–ª—Å—è speaker –æ—Ç –ü–ï–†–í–û–ì–û —Å–µ–≥–º–µ–Ω—Ç–∞ –≤ –≥—Ä—É–ø–ø–µ.
    –ï—Å–ª–∏ –ø–µ—Ä–≤—ã–π —Å–µ–≥–º–µ–Ω—Ç –∫–æ—Ä–æ—Ç–∫–∏–π/–Ω–µ—É–≤–µ—Ä–µ–Ω–Ω—ã–π, –≤—Å—è —Å–∫–ª–µ–π–∫–∞ –ø–æ–ª—É—á–∞–ª–∞ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π speaker.

    **–†–µ—à–µ–Ω–∏–µ v16.14:** –ë–µ—Ä—ë–º speaker –∏ raw_speaker_id –æ—Ç –°–ê–ú–û–ì–û –î–õ–ò–ù–ù–û–ì–û —Å–µ–≥–º–µ–Ω—Ç–∞ –ø–æ —Ç–µ–∫—Å—Ç—É
    (–¥–ª–∏–Ω–Ω—ã–π = –±–æ–ª–µ–µ –Ω–∞–¥—ë–∂–Ω—ã–π = –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π speaker).

    Args:
        segments: –°–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –ø–æ—Å–ª–µ alignment
        debug: –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å debug output (default: False)

    Returns:
        –°–ø–∏—Å–æ–∫ merged —Å–µ–≥–º–µ–Ω—Ç–æ–≤ (–í–°–ï —Å–µ–≥–º–µ–Ω—Ç—ã –≤–∫–ª—é—á–µ–Ω—ã)
    """
    if not segments:
        return []

    def similarity(a, b):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç—ã –ø–æ—Ö–æ–∂–∏ > 75%"""
        return SequenceMatcher(None, a.lower(), b.lower()).ratio() > 0.75

    merged = []
    i = 0
    merge_count = 0

    while i < len(segments):
        merge_count += 1
        current = segments[i]
        current_speaker = current['speaker']
        texts = [current['text']]
        current_end = current['end']
        start_time = current['start']

        # üÜï v16.14: –°–æ–±–∏—Ä–∞–µ–º –í–°–ï —Å–µ–≥–º–µ–Ω—Ç—ã –≥—Ä—É–ø–ø—ã –¥–ª—è –≤—ã–±–æ—Ä–∞ –¥–æ–º–∏–Ω–∏—Ä—É—é—â–µ–≥–æ
        all_segments_in_group = [current]

        if debug:
            print(f"  üîÄ MERGE #{merge_count}: {current.get('start_hms', seconds_to_hms(start_time))} {current_speaker} ‚Äî –Ω–∞—á–∞–ª–æ")
        else:
            print(f"  üîÄ {current.get('start_hms', seconds_to_hms(start_time))} {current_speaker} ‚Äî –Ω–∞—á–∞–ª–æ merge")

        # –ò—â–µ–º —Å–æ—Å–µ–¥–Ω–∏–µ —Å–µ–≥–º–µ–Ω—Ç—ã —Ç–æ–≥–æ –∂–µ —Å–ø–∏–∫–µ—Ä–∞
        j = i + 1
        merge_continue = True

        while j < len(segments) and merge_continue:
            next_seg = segments[j]
            pause = next_seg['start'] - current_end

            if next_seg['speaker'] != current_speaker:
                merge_continue = False
                break

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ overlap (–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–∞—è –ø–∞—É–∑–∞)
            if pause < 0:
                sim = SequenceMatcher(
                    None, 
                    texts[-1] if texts else "", 
                    next_seg['text']
                ).ratio()

                if sim > 0.85:
                    # –î—É–±–ª–∏–∫–∞—Ç - –±–µ—Ä—ë–º –±–æ–ª–µ–µ –¥–ª–∏–Ω–Ω—ã–π
                    if len(next_seg['text']) > len(texts[-1]):
                        texts[-1] = next_seg['text']
                        # üÜï v16.14: –ó–∞–º–µ–Ω—è–µ–º –∏ –≤ –≥—Ä—É–ø–ø–µ
                        all_segments_in_group[-1] = next_seg
                    current_end = next_seg['end']
                    j += 1
                    continue

                if sim > 0.60:
                    # –ü–æ—Ö–æ–∂–∏–µ - –¥–æ–±–∞–≤–ª—è–µ–º
                    texts.append(next_seg['text'])
                    all_segments_in_group.append(next_seg)  # üÜï v16.14
                    current_end = next_seg['end']
                    j += 1
                    continue

                # –ú–∞–ª–∞—è overlap - —Å–∫–ª–µ–∏–≤–∞–µ–º
                if abs(pause) <= 2.0:
                    texts.append(next_seg['text'])
                    all_segments_in_group.append(next_seg)  # üÜï v16.14
                    current_end = next_seg['end']
                    j += 1
                    continue
                else:
                    # –°–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∞—è overlap
                    j += 1
                    continue

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–±—ã—á–Ω–æ–π –ø–∞—É–∑—ã
            else:
                # –î–ª—è –ù–ï-–ñ—É—Ä–Ω–∞–ª–∏—Å—Ç–∞
                if current_speaker != "–ñ—É—Ä–Ω–∞–ª–∏—Å—Ç":
                    if pause <= 2.0:
                        texts.append(next_seg['text'])
                        all_segments_in_group.append(next_seg)  # üÜï v16.14
                        print(f"    ‚Ü≥ {next_seg.get('start_hms', '')} ‚è∏Ô∏è {pause:.1f}s ‚Üí ‚úÖ merge")
                        current_end = next_seg['end']
                        j += 1
                        continue
                    elif pause <= 5.0 and any(similarity(next_seg['text'], t) for t in texts[-2:]):
                        # –ü–∞—É–∑–∞ 2-5s, –Ω–æ –µ—Å—Ç—å similarity —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º–∏
                        texts.append(next_seg['text'])
                        all_segments_in_group.append(next_seg)  # üÜï v16.14
                        print(f"    ‚Ü≥ {next_seg.get('start_hms', '')} ‚è∏Ô∏è {pause:.1f}s ‚Üí ‚úÖ merge (similarity)")
                        current_end = next_seg['end']
                        j += 1
                        continue
                    else:
                        print(f"    ‚Ü≥ {current_speaker} –ø–∞—É–∑–∞ {pause:.1f}s > 5.0s ‚Üí ‚ùå STOP")
                        merge_continue = False
                        break

                # –î–ª—è –ñ—É—Ä–Ω–∞–ª–∏—Å—Ç–∞ –ù–ï —Å–∫–ª–µ–∏–≤–∞–µ–º –ø—Ä–∏ –ø–∞—É–∑–µ > 3s
                if current_speaker == "–ñ—É—Ä–Ω–∞–ª–∏—Å—Ç":
                    if pause <= 3.0 and pause >= -12.0:
                        texts.append(next_seg['text'])
                        all_segments_in_group.append(next_seg)  # üÜï v16.14
                        print(f"    ‚Ü≥ {next_seg.get('start_hms', '')} ‚è∏Ô∏è {pause:.1f}s ‚Üí ‚úÖ merge")
                        current_end = next_seg['end']
                        j += 1
                        continue
                    else:
                        print(f"    ‚Ü≥ –ñ—É—Ä–Ω–∞–ª–∏—Å—Ç –ø–∞—É–∑–∞ {pause:.1f}s > 3.0s ‚Üí ‚ùå STOP")
                        merge_continue = False
                        break

        # üÜï v16.20: DEBUG - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤
        if debug:
            total_words = sum(len(t.split()) for t in texts)
            print(f"    üìä –°–æ–±—Ä–∞–Ω–æ: {len(texts)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤, {total_words} —Å–ª–æ–≤")

        # üÜï v16.14: –í–´–ë–ò–†–ê–ï–ú –î–û–ú–ò–ù–ò–†–£–Æ–©–ò–ô –°–ï–ì–ú–ï–ù–¢ (—Å–∞–º—ã–π –¥–ª–∏–Ω–Ω—ã–π –ø–æ —Ç–µ–∫—Å—Ç—É)
        dominant_segment = max(all_segments_in_group, key=lambda s: len(s.get('text', '')))
        
        if len(all_segments_in_group) > 1:
            print(f"    üéØ –î–æ–º–∏–Ω–∏—Ä—É—é—â–∏–π: {dominant_segment.get('speaker')} / {dominant_segment.get('raw_speaker_id')} (–¥–ª–∏–Ω–∞: {len(dominant_segment.get('text', ''))} —Å–∏–º–≤–æ–ª–æ–≤)")

        # üÜï v16.20: DEBUG –ø–µ—Ä–µ–¥ —Å–∫–ª–µ–π–∫–æ–π
        if debug:
            print(f"    üîó –°–∫–ª–µ–π–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤...")

        # –°–∫–ª–µ–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç—ã
        final_text = ' '.join(texts)
        
        # üÜï v16.20: DEBUG –ø–µ—Ä–µ–¥ clean_loops
        if debug:
            print(f"    üßπ –í—ã–∑–æ–≤ clean_loops ({len(final_text)} —Å–∏–º–≤–æ–ª–æ–≤)...")
        
        final_text = clean_loops(final_text, debug=debug)
        
        # üÜï v16.20: DEBUG –ø–µ—Ä–µ–¥ clean_hallucinations
        if debug:
            print(f"    üßπ –í—ã–∑–æ–≤ clean_hallucinations_from_text...")
        
        final_text = clean_hallucinations_from_text(final_text, current_speaker, debug=debug)
        
        # üÜï v16.20: DEBUG –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏
        if debug:
            print(f"    ‚úÖ –û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞, —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç: {len(final_text)} —Å–∏–º–≤–æ–ª–æ–≤")

        if final_text:
            # üÜï v16.14: –ë–µ—Ä—ë–º speaker –∏ raw_speaker_id –æ—Ç –î–û–ú–ò–ù–ò–†–£–Æ–©–ï–ì–û —Å–µ–≥–º–µ–Ω—Ç–∞!
            merged.append({
                "speaker": dominant_segment.get('speaker', current_speaker),  # üÜï v16.14
                "time": current.get('start_hms', seconds_to_hms(start_time)),
                "start": start_time,
                "end": current_end,
                "text": final_text,
                "confidence": current.get('confidence', ''),
                "raw_speaker_id": dominant_segment.get('raw_speaker_id', '')  # üÜï v16.14
            })

            if len(texts) > 1:
                print(f"  ‚úÖ –°–∫–ª–µ–µ–Ω–æ {len(texts)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤ ‚Üí {len(final_text.split())} —Å–ª–æ–≤")

        i = j

    if debug:
        print(f"\n‚úÖ merge_replicas –∑–∞–≤–µ—Ä—à—ë–Ω: {len(merged)} merged —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –∏–∑ {len(segments)} –∏—Å—Ö–æ–¥–Ω—ã—Ö")

    return merged
