#!/usr/bin/env python3
"""
merge/deduplicator.py - Ğ”ĞµĞ´ÑƒĞ¿Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ñ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ´Ğ»Ñ v16.0
"""

import re
from core.utils import text_similarity, check_overlap_with_existing

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TEXT JOINING WITH DEDUPLICATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def join_texts_deduplicated(texts, debug=False):
    """
    ğŸ†• v17.4: FIX Ğ‘ĞĞ“ #17 - Ğ£Ğ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ Ğ´ÑƒĞ±Ğ»ĞµĞ¹ ÑĞ»Ğ¾Ğ² Ğ½Ğ° ÑÑ‚Ñ‹ĞºĞ°Ñ… Ğ¿Ñ€Ğ¸ ÑĞºĞ»ĞµĞ¹ĞºĞµ
    
    Ğ¡ĞºĞ»ĞµĞ¸Ğ²Ğ°ĞµÑ‚ ÑĞ¿Ğ¸ÑĞ¾Ğº Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ², ÑƒĞ´Ğ°Ğ»ÑÑ Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€ÑÑÑ‰Ğ¸ĞµÑÑ ÑĞ»Ğ¾Ğ²Ğ° Ğ½Ğ° Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ†Ğ°Ñ….
    Ğ¡Ñ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ case-insensitive, Ğ½Ğ¾ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑĞµÑ‚ ĞºĞ°Ğ¿Ğ¸Ñ‚Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¸Ğ· Ğ¿ĞµÑ€Ğ²Ğ¾Ğ³Ğ¾ Ñ‚ĞµĞºÑÑ‚Ğ°.
    
    **ĞŸĞ ĞĞ‘Ğ›Ğ•ĞœĞ (Ğ‘ĞĞ“ #17):**
    GAP_FILLED ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚ "Ğ”Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ ÑˆĞ°Ñ‚ĞºÑƒÑ..." ÑĞºĞ»ĞµĞ¸Ğ²Ğ°Ğ»ÑÑ Ñ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ğ¼
    "Ğ¾Ğ¿Ğ¸Ñ€Ğ°ĞµÑ‚ÑÑ Ğ½Ğ° Ğ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾" Ñ‡ĞµÑ€ĞµĞ· Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ğ¹ ' '.join() â†’
    "Ğ¾Ğ¿Ğ¸Ñ€Ğ°ĞµÑ‚ÑÑ Ğ½Ğ° Ğ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ”Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ ÑˆĞ°Ñ‚ĞºÑƒÑ"
    
    **ROOT CAUSE:**
    ĞÑ‚ÑÑƒÑ‚ÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ğ»Ğ° Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ´ÑƒĞ±Ğ»ĞµĞ¹ ÑĞ»Ğ¾Ğ² Ğ½Ğ° ÑÑ‚Ñ‹ĞºĞ°Ñ… Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ².
    
    **FIX:**
    ĞŸÑ€Ğ¸ ÑĞºĞ»ĞµĞ¹ĞºĞµ ÑÑ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğµ 5 ÑĞ»Ğ¾Ğ² Ñ‚ĞµĞºÑÑ‚Ğ° A Ñ Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¼Ğ¸ 5 ÑĞ»Ğ¾Ğ²Ğ°Ğ¼Ğ¸
    Ñ‚ĞµĞºÑÑ‚Ğ° B (case-insensitive). Ğ•ÑĞ»Ğ¸ Ğ½Ğ°Ñ…Ğ¾Ğ´Ğ¸Ğ¼ Ğ´ÑƒĞ±Ğ»Ğ¸ - ÑƒĞ´Ğ°Ğ»ÑĞµĞ¼ Ğ¸Ğ· Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° B.
    
    Args:
        texts: Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ² Ğ´Ğ»Ñ ÑĞºĞ»ĞµĞ¹ĞºĞ¸
        debug: ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°Ñ‚ÑŒ debug output
        
    Returns:
        Ğ¡ĞºĞ»ĞµĞµĞ½Ğ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚ Ğ±ĞµĞ· Ğ´ÑƒĞ±Ğ»ĞµĞ¹ Ğ½Ğ° ÑÑ‚Ñ‹ĞºĞ°Ñ…
    """
    if not texts:
        return ""
    
    if len(texts) == 1:
        return texts[0]
    
    result = texts[0]
    
    for i in range(1, len(texts)):
        current_text = texts[i]
        
        # Ğ‘ĞµÑ€Ñ‘Ğ¼ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğµ 5 ÑĞ»Ğ¾Ğ² Ğ¸Ğ· result
        result_words = result.split()
        current_words = current_text.split()
        
        # Ğ˜Ñ‰ĞµĞ¼ Ğ¼Ğ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¿ĞµÑ€ĞµĞºÑ€Ñ‹Ñ‚Ğ¸Ğµ (Ğ¾Ñ‚ 5 Ğ´Ğ¾ 1 ÑĞ»Ğ¾Ğ²Ğ°)
        overlap_length = 0
        
        for check_len in range(min(5, len(result_words), len(current_words)), 0, -1):
            tail = result_words[-check_len:]
            head = current_words[:check_len]
            
            # Case-insensitive ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ
            tail_lower = [w.lower() for w in tail]
            head_lower = [w.lower() for w in head]
            
            if tail_lower == head_lower:
                overlap_length = check_len
                
                if debug:
                    print(f"      ğŸ”— ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ğ¿ĞµÑ€ĞµĞºÑ€Ñ‹Ñ‚Ğ¸Ğµ {check_len} ÑĞ»Ğ¾Ğ²: {' '.join(tail)} â‰ˆ {' '.join(head)}")
                
                break
        
        # Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ Ğ´ÑƒĞ±Ğ»Ğ¸ Ğ¸Ğ· Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° current_text
        if overlap_length > 0:
            deduplicated_current = ' '.join(current_words[overlap_length:])
            
            if debug:
                print(f"      âœ‚ï¸ Ğ£Ğ´Ğ°Ğ»ĞµĞ½Ğ¾ {overlap_length} Ğ´ÑƒĞ±Ğ»ĞµĞ¹ Ğ¸Ğ· Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ° #{i}")
                print(f"         Ğ‘Ñ‹Ğ»Ğ¾: \"{current_text[:60]}...\"")
                print(f"         Ğ¡Ñ‚Ğ°Ğ»Ğ¾: \"{deduplicated_current[:60]}...\"")
            
            result = result + ' ' + deduplicated_current
        else:
            result = result + ' ' + current_text
    
    return result.strip()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CROSS-SPEAKER DEDUPLICATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def remove_cross_speaker_text_duplicates(segments):
    """
    Ğ£Ğ´Ğ°Ğ»ÑĞµÑ‚ Ğ´ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ñ‹ Ğ¼ĞµĞ¶Ğ´Ñƒ Ñ€Ğ°Ğ·Ğ½Ñ‹Ğ¼Ğ¸ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ°Ğ¼Ğ¸

    Args:
        segments: Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²

    Returns:
        ĞÑ‡Ğ¸Ñ‰ĞµĞ½Ğ½Ñ‹Ğ¹ ÑĞ¿Ğ¸ÑĞ¾Ğº
    """
    if len(segments) < 2:
        return segments

    segments_sorted = sorted(segments, key=lambda x: x["start"])
    to_remove = set()

    for i in range(len(segments_sorted)):
        if i in to_remove:
            continue

        current = segments_sorted[i]

        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğµ 10 ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²
        for j in range(i + 1, min(i + 10, len(segments_sorted))):
            if j in to_remove:
                continue

            next_seg = segments_sorted[j]

            # Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… ÑĞ¿Ğ¸ĞºĞµÑ€Ğ¾Ğ²
            if current["speaker"] == next_seg["speaker"]:
                continue

            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾ Ñ‚ĞµĞºÑÑ‚Ğ°
            sim = text_similarity(current["text"], next_seg["text"])
            time_diff = abs(current["start"] - next_seg["start"])

            if sim > 0.85 and time_diff < 5.0:
                # ĞÑÑ‚Ğ°Ğ²Ğ»ÑĞµĞ¼ Ñ‚Ğ¾Ñ‚, Ñƒ ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ¾Ğ³Ğ¾ Ğ¼ĞµĞ½ÑŒÑˆĞµ overlap Ñ Ğ´Ñ€ÑƒĞ³Ğ¸Ğ¼Ğ¸
                other_segments = [s for k, s in enumerate(segments_sorted) if k != i and k != j]

                current_overlap = check_overlap_with_existing(
                    current["start"], current["end"], other_segments
                )
                next_overlap = check_overlap_with_existing(
                    next_seg["start"], next_seg["end"], other_segments
                )

                # Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ Ñ‚Ğ¾Ñ‚, Ñƒ ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ¾Ğ³Ğ¾ Ğ±Ğ¾Ğ»ÑŒÑˆĞµ overlap
                if current_overlap > 50 and next_overlap <= 50:
                    to_remove.add(i)
                    break
                elif next_overlap > 50 and current_overlap <= 50:
                    to_remove.add(j)
                    continue
                else:
                    # Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ Ğ¿Ğ¾ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ (Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ±Ğ¾Ğ»ĞµĞµ Ñ€Ğ°Ğ½Ğ½Ğ¸Ğ¹)
                    if current["start"] > next_seg["start"]:
                        to_remove.add(i)
                        break
                    else:
                        to_remove.add(j)

    cleaned = [seg for i, seg in enumerate(segments_sorted) if i not in to_remove]
    removed_count = len(segments) - len(cleaned)

    if removed_count > 0:
        print(f"âœ… Cross-speaker dedup: ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¾ {removed_count} Ğ´ÑƒĞ±Ğ»ĞµĞ¹")

    return cleaned

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ĞœĞĞĞ“ĞĞ£Ğ ĞĞ’ĞĞ•Ğ’ĞĞ¯ Ğ”Ğ•Ğ”Ğ£ĞŸĞ›Ğ˜ĞšĞĞ¦Ğ˜Ğ¯
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def deduplicate_segments(segments):
    """
    ĞœĞ½Ğ¾Ğ³Ğ¾ÑƒÑ€Ğ¾Ğ²Ğ½ĞµĞ²Ğ°Ñ Ğ´ĞµĞ´ÑƒĞ¿Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ñ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ°

    Args:
        segments: Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²

    Returns:
        Ğ”ĞµĞ´ÑƒĞ¿Ğ»Ğ¸Ñ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ ÑĞ¿Ğ¸ÑĞ¾Ğº
    """
    if len(segments) < 2:
        return segments

    segments_sorted = sorted(segments, key=lambda x: x["start"])
    deduplicated = []
    skip_indices = set()

    for i in range(len(segments_sorted)):
        if i in skip_indices:
            continue

        current = segments_sorted[i]
        duplicates = [current]

        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğµ 11 ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²
        for j in range(i + 1, min(i + 11, len(segments_sorted))):
            if j in skip_indices:
                continue

            next_seg = segments_sorted[j]

            # Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ğ´Ğ»Ñ Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ°
            if current["speaker"] != next_seg["speaker"]:
                continue

            # Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµĞ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾Ğµ Ğ¿ĞµÑ€ĞµĞºÑ€Ñ‹Ñ‚Ğ¸Ğµ
            time_overlap = (min(current["end"], next_seg["end"]) - 
                          max(current["start"], next_seg["start"]))
            seg_duration = current["end"] - current["start"]

            if seg_duration > 0:
                time_overlap_pct = (time_overlap / seg_duration) * 100
            else:
                time_overlap_pct = 0

            sim = text_similarity(current["text"], next_seg["text"])

            # Ğ£ÑĞ»Ğ¾Ğ²Ğ¸Ñ Ğ´Ğ»Ñ Ğ´ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ğ°
            if sim > 0.85:
                duplicates.append(next_seg)
                skip_indices.add(j)
                continue

            if time_overlap_pct > 95 and sim > 0.70:
                duplicates.append(next_seg)
                skip_indices.add(j)
                continue

            if time_overlap_pct > 80:
                # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ¸Ñ Ğ² Ñ‡Ğ¸ÑĞ»Ğ°Ñ…
                numbers_current = set(re.findall(r'\b\d+\b', current["text"]))
                numbers_next = set(re.findall(r'\b\d+\b', next_seg["text"]))

                if (numbers_current - numbers_next) or (numbers_next - numbers_current):
                    continue

                len_ratio = (min(len(current["text"]), len(next_seg["text"])) / 
                           max(len(current["text"]), len(next_seg["text"])))

                if len_ratio < 0.5 or sim < 0.70:
                    continue

        # ĞÑÑ‚Ğ°Ğ²Ğ»ÑĞµĞ¼ ÑĞ°Ğ¼Ñ‹Ğ¹ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğ¹ Ğ¸Ğ· Ğ´ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ğ¾Ğ²
        best = max(duplicates, key=lambda x: len(x["text"]))
        deduplicated.append(best)

    return deduplicated
