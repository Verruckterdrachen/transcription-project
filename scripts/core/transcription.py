#!/usr/bin/env python3
"""
core/transcription.py - Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ñ Whisper

ğŸ†• v16.29: GAP Hallucination Filter - Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞº gap Ñ Ğ²Ñ‹ÑĞ¾ĞºĞ¸Ğ¼ ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾Ğ¼ (>55%)
ğŸ†• v16.5: Smart GAP Attribution - ÑƒĞ¼Ğ½Ğ°Ñ Ğ°Ñ‚Ñ€Ğ¸Ğ±ÑƒÑ†Ğ¸Ñ GAP_FILLED Ğ¿Ğ¾ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¼Ñƒ ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ñƒ
ğŸ†• v16.3.2: Gap speaker detection - Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ° Ğ¿Ğ¾ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ
ğŸ†• v16.2: Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½ ÑĞ¸Ğ½Ñ‚Ğ°ĞºÑĞ¸Ñ itertracks() Ğ² force_transcribe_diar_gaps
"""

import whisper
from core.utils import seconds_to_hms, gap_detector, extract_gap_audio, text_similarity
from core.diarization import align_segment_to_diarization
from corrections.hallucinations import is_hallucination


def transcribe_audio(model, wav_path, language="ru", temperature=0.0, beam_size=5, vad_threshold=0.7):
	"""
	Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ¸Ñ€ÑƒĞµÑ‚ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ñ„Ğ°Ğ¹Ğ» Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Whisper

	Args:
		model: Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Whisper
		wav_path: Path Ğº WAV Ñ„Ğ°Ğ¹Ğ»Ñƒ
		language: Ğ¯Ğ·Ñ‹Ğº Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ğ¸
		temperature: Temperature Ğ´Ğ»Ñ Whisper
		beam_size: Beam size Ğ´Ğ»Ñ Whisper
		vad_threshold: ĞŸĞ¾Ñ€Ğ¾Ğ³ VAD (Voice Activity Detection)

	Returns:
		dict: Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ğ¸ Ñ segments
	"""
	print(f"  ğŸ™ï¸ Whisper Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ {wav_path.name}...")

	result = model.transcribe(
		str(wav_path),
		language=language,
		temperature=temperature,
		beam_size=beam_size,
		word_timestamps=True
	)

	if result and 'segments' in result:
		print(f"  âœ… Whisper: {len(result['segments'])} ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²")
		return result

	print("  âŒ Whisper: Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ Ğ½Ğµ ÑƒĞ´Ğ°Ğ»Ğ°ÑÑŒ")
	return None


def detect_speaker_for_gap(existing_segments, gap_start, gap_end, speaker_surname):
	"""
	ğŸ†• v16.3.2: ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµÑ‚ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ° Ğ´Ğ»Ñ gap ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ° Ğ¿Ğ¾ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ

	Ğ›Ğ¾Ğ³Ğ¸ĞºĞ°:
	1. Ğ¡Ğ¼Ğ¾Ñ‚Ñ€Ğ¸Ğ¼ Ğ½Ğ° Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ğ¹ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚ (Ğ´Ğ¾ gap)
	2. Ğ¡Ğ¼Ğ¾Ñ‚Ñ€Ğ¸Ğ¼ Ğ½Ğ° ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğ¹ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚ (Ğ¿Ğ¾ÑĞ»Ğµ gap)
	3. Ğ•ÑĞ»Ğ¸ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½ Ğ¾Ğ´Ğ½Ğ¸Ğ¼ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ¾Ğ¼ â†’ gap Ğ¿Ñ€Ğ¸Ğ½Ğ°Ğ´Ğ»ĞµĞ¶Ğ¸Ñ‚ ĞµĞ¼Ñƒ
	4. Ğ•ÑĞ»Ğ¸ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½ Ñ€Ğ°Ğ·Ğ½Ñ‹Ğ¼Ğ¸ â†’ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ Ğ´Ğ»Ğ¸Ğ½Ñƒ gap

	Args:
		existing_segments: Ğ’ÑĞµ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ñ‹
		gap_start: ĞĞ°Ñ‡Ğ°Ğ»Ğ¾ gap (ÑĞµĞºÑƒĞ½Ğ´Ñ‹)
		gap_end: ĞšĞ¾Ğ½ĞµÑ† gap (ÑĞµĞºÑƒĞ½Ğ´Ñ‹)
		speaker_surname: Ğ¤Ğ°Ğ¼Ğ¸Ğ»Ğ¸Ñ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ°

	Returns:
		speaker: 'Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚', speaker_surname, Ğ¸Ğ»Ğ¸ 'ĞĞµĞ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ğ¾'
	"""
	# ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ğ¼ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ğ¹ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚ (Ğ´Ğ¾ gap)
	prev_speaker = None
	for seg in sorted(existing_segments, key=lambda x: x['end'], reverse=True):
		if seg['end'] <= gap_start:
			prev_speaker = seg.get('speaker')
			break

	# ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ğ¼ ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğ¹ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚ (Ğ¿Ğ¾ÑĞ»Ğµ gap)
	next_speaker = None
	for seg in sorted(existing_segments, key=lambda x: x['start']):
		if seg['start'] >= gap_end:
			next_speaker = seg.get('speaker')
			break

	# Ğ•ÑĞ»Ğ¸ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½ Ğ¾Ğ´Ğ½Ğ¸Ğ¼ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ¾Ğ¼
	if prev_speaker and next_speaker and prev_speaker == next_speaker:
		return prev_speaker

	# Ğ•ÑĞ»Ğ¸ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ğ¹ Ğ¸Ğ·Ğ²ĞµÑÑ‚ĞµĞ½
	if prev_speaker == 'Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚':
		# Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚ Ğ¾Ğ±Ñ‹Ñ‡Ğ½Ğ¾ Ğ·Ğ°Ğ´Ğ°ĞµÑ‚ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ, Ğ¿Ğ¾Ñ‚Ğ¾Ğ¼ ÑĞºÑĞ¿ĞµÑ€Ñ‚ Ğ¾Ñ‚Ğ²ĞµÑ‡Ğ°ĞµÑ‚
		# Ğ•ÑĞ»Ğ¸ gap Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğ¹ (>15s) â†’ ÑĞºĞ¾Ñ€ĞµĞµ Ğ²ÑĞµĞ³Ğ¾ ÑĞºÑĞ¿ĞµÑ€Ñ‚
		gap_duration = gap_end - gap_start

		if gap_duration > 15:
			return speaker_surname
		else:
			return 'Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚'

	# Ğ•ÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾Ğ± ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğµ Ñ€ÑĞ´Ğ¾Ğ¼
	if prev_speaker == speaker_surname or next_speaker == speaker_surname:
		return speaker_surname

	# ĞĞµ Ğ¼Ğ¾Ğ¶ĞµĞ¼ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸Ñ‚ÑŒ
	return 'ĞĞµĞ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ğ¾'


def force_transcribe_diar_gaps(model, wav_path, gaps, existing_segments, speaker_surname=None):
	"""
	ğŸ†• v16.29: GAP Hallucination Filter - Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞº gap Ñ Ğ²Ñ‹ÑĞ¾ĞºĞ¸Ğ¼ ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾Ğ¼ (>55%)
	ğŸ†• v16.8: GAP Overlap Protection - Ğ¾Ğ±Ñ€ĞµĞ·ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¿ĞµÑ€ĞµÑĞµÑ‡ĞµĞ½Ğ¸Ğ¸ Ñ ÑĞ¾ÑĞµĞ´Ğ½Ğ¸Ğ¼Ğ¸
	ğŸ†• v16.5: Smart GAP Attribution - ÑƒĞ¼Ğ½Ğ°Ñ Ğ°Ñ‚Ñ€Ğ¸Ğ±ÑƒÑ†Ğ¸Ñ Ğ¿Ğ¾ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¼Ñƒ ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ñƒ
	ğŸ†• v16.3.2: Gap speaker detection Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½
	ğŸ”§ v16.2: Force-transcribe gaps Ñ Ğ¸ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ğ¼ itertracks

	ĞŸĞ¾Ğ²Ñ‚Ğ¾Ñ€Ğ½Ğ¾ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½Ğ½Ñ‹Ğµ ÑƒÑ‡Ğ°ÑÑ‚ĞºĞ¸ (gaps) Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ
	Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ¸Ğ°Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ Ğ±Ğ¾Ğ»ĞµĞµ Ğ¼ÑĞ³ĞºĞ¸Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Whisper.
	
	ğŸ†• v16.29 Ğ˜Ğ—ĞœĞ•ĞĞ•ĞĞ˜Ğ¯:
	- ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ: lowercase + ÑÑ€Ğ°Ğ²Ğ½ĞµĞ½Ğ¸Ğµ Ğ¿ĞµÑ€Ğ²Ñ‹Ñ… N ÑĞ»Ğ¾Ğ² next_text
	- Threshold: >55% = hallucination (Ğ¿Ğ¾Ğ½Ğ¸Ğ¶ĞµĞ½ Ğ¸Ğ·-Ğ·Ğ° Ğ¼Ğ¾Ñ€Ñ„Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ğ¸ Ñ€ÑƒÑÑĞºĞ¾Ğ³Ğ¾)
	- "ÑĞ¾Ğ²ĞµÑ‚ÑĞºĞ°Ñ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ°" vs "ÑĞ¾Ğ²ĞµÑ‚ÑĞºĞ¾Ğµ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ" = 57.7% â†’ SKIP!
	- Ğ—Ğ°Ñ‰Ğ¸Ñ‚Ğ° Ğ¾Ñ‚ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ³Ğ°Ğ»Ğ»ÑÑ†Ğ¸Ğ½Ğ°Ñ†Ğ¸Ğ¹ Whisper (ÑˆÑƒĞ¼Ñ‹ ĞºĞ°Ğº Ñ‚ĞµĞºÑÑ‚)
	
	ğŸ†• v16.8 Ğ˜Ğ—ĞœĞ•ĞĞ•ĞĞ˜Ğ¯:
	- GAP overlap detection Ñ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ğ¼Ğ¸ GAP Ğ¸ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğ¼Ğ¸ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸
	- ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ¾Ğ±Ñ€ĞµĞ·ĞºĞ° Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ† Ğ¿Ñ€Ğ¸ overlap
	- ĞŸÑ€Ğ¾Ğ¿ÑƒÑĞº ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ñ… GAP Ğ¿Ğ¾ÑĞ»Ğµ Ğ¾Ğ±Ñ€ĞµĞ·ĞºĞ¸ (<1s)
	
	ğŸ†• v16.5 Ğ˜Ğ—ĞœĞ•ĞĞ•ĞĞ˜Ğ¯:
	- ĞŸĞ¾ÑĞ»Ğµ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚ÑÑ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾ Ñ next_segment
	- Ğ•ÑĞ»Ğ¸ ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾ >50% â†’ GAP_FILLED Ğ°Ñ‚Ñ€Ğ¸Ğ±ÑƒÑ‚Ğ¸Ñ€ÑƒĞµÑ‚ÑÑ ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ¼Ñƒ ÑĞ¿Ğ¸ĞºĞµÑ€Ñƒ
	- Ğ—Ğ°Ñ‰Ğ¸Ñ‚Ğ° Ğ¾Ñ‚ Ğ¾ÑˆĞ¸Ğ±Ğ¾Ñ‡Ğ½Ğ¾Ğ¹ Ğ°Ñ‚Ñ€Ğ¸Ğ±ÑƒÑ†Ğ¸Ğ¸ Ğ·Ğ°Ğ¿Ğ¸Ğ½Ğ¾Ğº/Ğ¿ĞµÑ€ĞµÑ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ¾Ğº

	Args:
		model: Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Whisper
		wav_path: Path Ğº WAV Ñ„Ğ°Ğ¹Ğ»Ñƒ
		gaps: Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº gaps Ğ¸Ğ· gap_detector
		existing_segments: Ğ¡ÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğµ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ñ‹ (Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ overlap)
		speaker_surname: ğŸ†• v16.3.2 - Ğ¤Ğ°Ğ¼Ğ¸Ğ»Ğ¸Ñ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ° Ğ´Ğ»Ñ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ°

	Returns:
		list: ĞĞ¾Ğ²Ñ‹Ğµ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¸Ğ· gaps
	"""
	print(f"\nğŸ”„ Force-transcribe gaps...")

	added_segments = []

	for gap in gaps:
		gap_start = gap['gap_start']
		gap_end = gap['gap_end']
		gap_duration = gap['duration']

		print(f"  ğŸš¨ GAP {gap['gap_hms_start']}â€“{gap['gap_hms_end']} ({gap_duration}s)")

		# ğŸ†• v16.3.2: ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ° Ğ”Ğ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ğ¸
		detected_speaker = 'ĞĞµĞ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ğ¾'
		if speaker_surname:
			detected_speaker = detect_speaker_for_gap(
				existing_segments, 
				gap_start, 
				gap_end, 
				speaker_surname
			)

		# Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ Ğ°ÑƒĞ´Ğ¸Ğ¾ gap Ñ Ğ½ĞµĞ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğ¼ overlap
		gap_audio_path = extract_gap_audio(wav_path, gap_start, gap_end, overlap=1.0)

		try:
			# ğŸ”§ v16.0: ĞŸĞ¾Ğ½Ğ¸Ğ¶ĞµĞ½ Ğ¿Ğ¾Ñ€Ğ¾Ğ³ no_speech_threshold Ğ´Ğ¾ 0.2
			result = model.transcribe(
				str(gap_audio_path),
				language="ru",
				temperature=0.0,
				beam_size=5,
				no_speech_threshold=0.2,  # Ğ‘Ñ‹Ğ»Ğ¾ 0.3
				compression_ratio_threshold=1.2
			)

			if result and 'segments' in result:
				for seg in result['segments']:
					text = seg['text'].strip()

					# ĞŸÑ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ³Ğ°Ğ»Ğ»ÑÑ†Ğ¸Ğ½Ğ°Ñ†Ğ¸Ğ¸
					if is_hallucination(text):
						continue

					# Adjust timing
					seg_start = gap_start + float(seg['start'])
					seg_end = gap_start + float(seg['end'])

					# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
					# ğŸ†• v16.8: GAP OVERLAP PROTECTION
					# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
					
					original_start = seg_start
					original_end = seg_end
					
					# 1. ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ overlap Ñ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ğ¼ GAP ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ¼
					if added_segments:
						last_gap = added_segments[-1]
						if seg_start < last_gap["end"] + 0.5:
							seg_start = last_gap["end"]
							print(f"     âš ï¸ GAP overlap Ñ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ğ¼ GAP, adjusted start: {seg_start:.2f}s")
					
					# 2. ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ overlap ÑĞ¾ ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğ¼ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ğ¼ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ¼
					next_existing = None
					for existing_seg in sorted(existing_segments, key=lambda x: x['start']):
						if existing_seg['start'] >= gap_end:
							next_existing = existing_seg
							break
					
					if next_existing and seg_end > next_existing["start"] - 0.5:
						seg_end = next_existing["start"]
						print(f"     âš ï¸ GAP overlap Ñ next existing, adjusted end: {seg_end:.2f}s")
					
					# 3. ĞŸÑ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğµ GAP Ğ¿Ğ¾ÑĞ»Ğµ Ğ¾Ğ±Ñ€ĞµĞ·ĞºĞ¸
					if seg_end - seg_start < 1.0:
						print(f"     âš ï¸ GAP too short after adjustment ({seg_end - seg_start:.2f}s), skipping")
						continue
					
					# 4. ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ adjustment ĞµÑĞ»Ğ¸ Ğ±Ñ‹Ğ»
					if seg_start != original_start or seg_end != original_end:
						print(f"     ğŸ”§ Adjusted: {original_start:.2f}-{original_end:.2f} â†’ {seg_start:.2f}-{seg_end:.2f}")

					# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
					# ğŸ†• v16.29: GAP HALLUCINATION FILTER (normalized, threshold=55%)
					# ğŸ†• v16.5: Ğ£ĞœĞĞĞ¯ ĞĞ¢Ğ Ğ˜Ğ‘Ğ£Ğ¦Ğ˜Ğ¯ GAP_FILLED
					# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
					
					final_speaker = detected_speaker
					
					# ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ğ¼ ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğ¹ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚ Ğ¿Ğ¾ÑĞ»Ğµ gap
					next_segment = None
					for existing_seg in sorted(existing_segments, key=lambda x: x['start']):
						if existing_seg['start'] >= gap_end:
							next_segment = existing_seg
							break
					
					# Ğ•ÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğ¹ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚ Ğ¸ ĞµĞ³Ğ¾ ÑĞ¿Ğ¸ĞºĞµÑ€ Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ°ĞµÑ‚ÑÑ
					if next_segment:
						next_speaker = next_segment.get('speaker')
						next_text = next_segment.get('text', '')
						
						if next_speaker and next_speaker != detected_speaker:
							# ğŸ†• v16.29: ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·ÑƒĞµĞ¼ Ñ‚ĞµĞºÑÑ‚Ñ‹
							gap_text_normalized = text.lower().strip()
							next_text_normalized = next_text.lower().strip()
							
							# Ğ‘ĞµÑ€Ñ‘Ğ¼ Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ N ÑĞ»Ğ¾Ğ² next_text (Ğ³Ğ´Ğµ N*2 = ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ÑĞ»Ğ¾Ğ² Ğ² gap)
							gap_words = gap_text_normalized.split()
							next_words = next_text_normalized.split()
							compare_words_count = len(gap_words) * 2  # Ğ’ 2 Ñ€Ğ°Ğ·Ğ° Ğ±Ğ¾Ğ»ÑŒÑˆĞµ Ğ´Ğ»Ñ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ°
							next_text_compare = ' '.join(next_words[:compare_words_count])
							
							# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾
							similarity = text_similarity(gap_text_normalized, next_text_compare)
							
							print(f"    ğŸ” Ğ¡Ñ…Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾ Ñ next [{next_speaker}]: {similarity:.1%} (words={len(gap_words)}â†’{compare_words_count})")
							
							# ğŸ†• v16.29: Ğ•ÑĞ»Ğ¸ ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾ >55% â†’ ÑÑ‚Ğ¾ Ğ³Ğ°Ğ»Ğ»ÑÑ†Ğ¸Ğ½Ğ°Ñ†Ğ¸Ñ!
							if similarity > 0.55:
								print(f"    âš ï¸ GAP ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ Ğ¿Ğ¾Ñ…Ğ¾Ğ¶ Ğ½Ğ° next ({similarity:.0%}) â†’ SKIP (hallucination)")
								continue  # ĞŸÑ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ ÑÑ‚Ğ¾Ñ‚ gap ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚!
							
							# Ğ•ÑĞ»Ğ¸ ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾ >50% â†’ Ğ¿ĞµÑ€ĞµĞ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ°
							if similarity > 0.50:
								final_speaker = next_speaker
								print(f"    ğŸ”„ GAP_FILLED â†’ {next_speaker} (ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾ {similarity:.1%})")
							else:
								print(f"    âœ… GAP_FILLED â†’ {detected_speaker} (Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ)")

					new_segment = {
						'start': seg_start,
						'end': seg_end,
						'start_hms': seconds_to_hms(seg_start),
						'end_hms': seconds_to_hms(seg_end),
						'text': text,
						'speaker': final_speaker,  # ğŸ†• v16.5: Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ final_speaker
						'raw_speaker_id': 'GAP_FILLED',
						'confidence': seg.get('avg_logprob', -1.0),
						'from_gap': True
					}

					added_segments.append(new_segment)
					print(f"    âœ… [{seconds_to_hms(seg_start)}] {text[:50]}...")

		except Exception as e:
			print(f"  âŒ Gap Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ Ğ½Ğµ ÑƒĞ´Ğ°Ğ»Ğ°ÑÑŒ: {e}")

		finally:
			# Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğ¹ Ñ„Ğ°Ğ¹Ğ»
			if gap_audio_path.exists():
				gap_audio_path.unlink()

	if added_segments:
		print(f"  âœ… Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ Ğ¸Ğ· gaps: {len(added_segments)} ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²")
	else:
		print(f"  âš ï¸ Gaps Ğ½Ğµ Ğ´Ğ°Ğ»Ğ¸ Ğ½Ğ¾Ğ²Ñ‹Ñ… ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²")

	return added_segments
