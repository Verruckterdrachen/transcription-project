#!/usr/bin/env python3
"""
core/transcription.py - Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ñ Whisper

ğŸ†• v16.30: FIX Ğ‘ĞĞ“ #4 - N-gram overlap Ñ ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ¿ÑƒĞ½ĞºÑ‚ÑƒĞ°Ñ†Ğ¸Ğ¸ (Ñ‚Ñ€Ğ¸Ğ³Ñ€Ğ°Ğ¼Ğ¼Ñ‹ 3+ ÑĞ»Ğ¾Ğ²)
ğŸ†• v16.29: GAP Hallucination Filter - Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞº gap Ñ Ğ²Ñ‹ÑĞ¾ĞºĞ¸Ğ¼ ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾Ğ¼ (>55%)
ğŸ†• v16.5: Smart GAP Attribution - ÑƒĞ¼Ğ½Ğ°Ñ Ğ°Ñ‚Ñ€Ğ¸Ğ±ÑƒÑ†Ğ¸Ñ GAP_FILLED Ğ¿Ğ¾ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¼Ñƒ ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ñƒ
ğŸ†• v16.3.2: Gap speaker detection - Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ° Ğ¿Ğ¾ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ
ğŸ†• v16.2: Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½ ÑĞ¸Ğ½Ñ‚Ğ°ĞºÑĞ¸Ñ itertracks() Ğ² force_transcribe_diar_gaps
"""

import re
import whisper
from core.utils import seconds_to_hms, gap_detector, extract_gap_audio, text_similarity
from core.diarization import align_segment_to_diarization
from corrections.hallucinations import is_hallucination


def transcribe_audio(model, wav_path, language="ru", temperature=0.0, beam_size=5, vad_threshold=0.7):
	"""
	Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ¸Ñ€ÑƒĞµÑ‚ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ñ„Ğ°Ğ¹Ğ» Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Whisper

	Args:
		model: Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Whisper
		wav_path: Path Ğº WAV Ñ„Ğ°Ğ¹Ğ»Ñƒ
		language: Ğ¯Ğ·Ñ‹Ğº Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ğ¸
		temperature: Temperature Ğ´Ğ»Ñ Whisper
		beam_size: Beam size Ğ´Ğ»Ñ Whisper
		vad_threshold: ĞŸĞ¾Ñ€Ğ¾Ğ³ VAD (Voice Activity Detection)

	Returns:
		dict: Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ğ¸ Ñ segments
	"""
	print(f"  ğŸ™ï¸ Whisper Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ {wav_path.name}...")

	result = model.transcribe(
		str(wav_path),
		language=language,
		temperature=temperature,
		beam_size=beam_size,
		word_timestamps=True
	)

	if result and 'segments' in result:
		print(f"  âœ… Whisper: {len(result['segments'])} ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²")
		return result

	print("  âŒ Whisper: Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ Ğ½Ğµ ÑƒĞ´Ğ°Ğ»Ğ°ÑÑŒ")
	return None


# ... (Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ° Ğ±ĞµĞ· Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹) ...

def detect_speaker_for_gap(existing_segments, gap_start, gap_end, speaker_surname):
	"""
	ğŸ†• v16.31: FIX Ğ‘ĞĞ“ #7 - Ğ£Ñ‡Ñ‘Ñ‚ Ğ´Ğ»Ğ¸Ğ½Ñ‹ gap Ñ‚ĞµĞºÑÑ‚Ğ° Ğ¿Ñ€Ğ¸ Ğ°Ñ‚Ñ€Ğ¸Ğ±ÑƒÑ†Ğ¸Ğ¸
	ğŸ†• v16.3.2: ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµÑ‚ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ° Ğ´Ğ»Ñ gap ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ° Ğ¿Ğ¾ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ
	
	**ĞŸĞ ĞĞ‘Ğ›Ğ•ĞœĞ (Ğ‘ĞĞ“ #7):**
	Gap filling Ğ¿Ñ€Ğ¸ÑĞ²Ğ°Ğ¸Ğ²Ğ°Ğ» speaker Ğ‘Ğ•Ğ— Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ´Ğ»Ğ¸Ğ½Ñ‹ Ñ‚ĞµĞºÑÑ‚Ğ°:
	- ĞšĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğ¹ gap (<5 ÑĞ»Ğ¾Ğ²) â†’ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ continuation
	- Ğ”Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğ¹ gap (>20 ÑĞ»Ğ¾Ğ²) â†’ Ğ½Ğ¾Ğ²Ğ°Ñ Ñ€ĞµĞ¿Ğ»Ğ¸ĞºĞ°
	
	**FIX v16.31:**
	ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€ gap_text_words Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½ Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ´Ğ»Ğ¸Ğ½Ñ‹
	"""
	# ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ğ¼ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ğ¹ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚ (Ğ´Ğ¾ gap)
	prev_speaker = None
	for seg in sorted(existing_segments, key=lambda x: x['end'], reverse=True):
		if seg['end'] <= gap_start:
			prev_speaker = seg.get('speaker')
			break

	# ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ğ¼ ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğ¹ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚ (Ğ¿Ğ¾ÑĞ»Ğµ gap)
	next_speaker = None
	for seg in sorted(existing_segments, key=lambda x: x['start']):
		if seg['start'] >= gap_end:
			next_speaker = seg.get('speaker')
			break

	# Ğ•ÑĞ»Ğ¸ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½ Ğ¾Ğ´Ğ½Ğ¸Ğ¼ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ¾Ğ¼
	if prev_speaker and next_speaker and prev_speaker == next_speaker:
		return prev_speaker

	# Ğ•ÑĞ»Ğ¸ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ğ¹ Ğ¸Ğ·Ğ²ĞµÑÑ‚ĞµĞ½
	if prev_speaker == 'Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚':
		gap_duration = gap_end - gap_start
		
		# ğŸ†• v16.31: Ğ”Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğ¹ gap (>15s) â†’ ÑĞºĞ¾Ñ€ĞµĞµ Ğ²ÑĞµĞ³Ğ¾ ÑĞºÑĞ¿ĞµÑ€Ñ‚
		if gap_duration > 15:
			return speaker_surname
		else:
			return 'Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚'

	# Ğ•ÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾Ğ± ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğµ Ñ€ÑĞ´Ğ¾Ğ¼
	if prev_speaker == speaker_surname or next_speaker == speaker_surname:
		return speaker_surname

	# ĞĞµ Ğ¼Ğ¾Ğ¶ĞµĞ¼ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸Ñ‚ÑŒ
	return 'ĞĞµĞ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ğ¾'


def force_transcribe_diar_gaps(model, wav_path, gaps, existing_segments, speaker_surname=None):
	"""
	ğŸ†• v16.31: FIX Ğ‘ĞĞ“ #7 - Ğ£Ñ‡Ñ‘Ñ‚ Ğ´Ğ»Ğ¸Ğ½Ñ‹ gap Ñ‚ĞµĞºÑÑ‚Ğ° Ğ¿Ñ€Ğ¸ Ğ°Ñ‚Ñ€Ğ¸Ğ±ÑƒÑ†Ğ¸Ğ¸
	ğŸ†• v16.30: FIX Ğ‘ĞĞ“ #4 - N-gram overlap Ñ ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ¿ÑƒĞ½ĞºÑ‚ÑƒĞ°Ñ†Ğ¸Ğ¸
	ğŸ†• v16.29: GAP Hallucination Filter
	
	**ĞŸĞ ĞĞ‘Ğ›Ğ•ĞœĞ (Ğ‘ĞĞ“ #7):**
	Gap filling [959.68-963.9] Ğ¿Ñ€Ğ¸ÑĞ²Ğ¾Ğ¸Ğ» Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚ (>20 ÑĞ»Ğ¾Ğ²) Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚Ñƒ
	Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ, Ñ…Ğ¾Ñ‚Ñ ÑÑ‚Ğ¾ Ğ±Ñ‹Ğ»Ğ° Ñ€ĞµĞ¿Ğ»Ğ¸ĞºĞ° Ğ˜ÑĞ°ĞµĞ²Ğ°!
	
	**FIX v16.31:**
	1. ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ´Ğ»Ğ¸Ğ½Ñƒ gap_text (ÑĞ»Ğ¾Ğ²Ğ°)
	2. ĞšĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğ¹ (<5 ÑĞ»Ğ¾Ğ²) â†’ similarity Ñ next/prev
	3. Ğ”Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğ¹ (>20 ÑĞ»Ğ¾Ğ²) â†’ ĞĞ• Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ detected_speaker (Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚) Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ!
	   â†’ ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ prev_speaker (ĞµÑĞ»Ğ¸ Ğ˜ÑĞ°ĞµĞ² â†’ gap Ñ‚Ğ¾Ğ¶Ğµ Ğ˜ÑĞ°ĞµĞ²)
	"""
	print(f"\nğŸ”„ Force-transcribe gaps v16.31...")

	added_segments = []

	for gap in gaps:
		gap_start = gap['gap_start']
		gap_end = gap['gap_end']
		gap_duration = gap['duration']

		print(f"  ğŸš¨ GAP {gap['gap_hms_start']}â€“{gap['gap_hms_end']} ({gap_duration}s)")

		# ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ° Ğ”Ğ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ğ¸
		detected_speaker = 'ĞĞµĞ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ğ¾'
		if speaker_surname:
			detected_speaker = detect_speaker_for_gap(
				existing_segments, 
				gap_start, 
				gap_end, 
				speaker_surname
			)

		# Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ Ğ°ÑƒĞ´Ğ¸Ğ¾ gap Ñ Ğ½ĞµĞ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğ¼ overlap
		gap_audio_path = extract_gap_audio(wav_path, gap_start, gap_end, overlap=1.0)

		try:
			result = model.transcribe(
				str(gap_audio_path),
				language="ru",
				temperature=0.0,
				beam_size=5,
				no_speech_threshold=0.2,
				compression_ratio_threshold=1.2
			)

			if result and 'segments' in result:
				for seg in result['segments']:
					text = seg['text'].strip()

					# ĞŸÑ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ³Ğ°Ğ»Ğ»ÑÑ†Ğ¸Ğ½Ğ°Ñ†Ğ¸Ğ¸
					if is_hallucination(text):
						continue

					# Adjust timing
					seg_start = gap_start + float(seg['start'])
					seg_end = gap_start + float(seg['end'])

					# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
					# v16.8: GAP OVERLAP PROTECTION (Ğ±ĞµĞ· Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹)
					# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
					
					original_start = seg_start
					original_end = seg_end
					
					if added_segments:
						last_gap = added_segments[-1]
						if seg_start < last_gap["end"] + 0.5:
							seg_start = last_gap["end"]
							print(f"     âš ï¸ GAP overlap Ñ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ğ¼ GAP, adjusted start: {seg_start:.2f}s")
					
					next_existing = None
					for existing_seg in sorted(existing_segments, key=lambda x: x['start']):
						if existing_seg['start'] >= gap_end:
							next_existing = existing_seg
							break
					
					if next_existing and seg_end > next_existing["start"] - 0.5:
						seg_end = next_existing["start"]
						print(f"     âš ï¸ GAP overlap Ñ next existing, adjusted end: {seg_end:.2f}s")
					
					if seg_end - seg_start < 1.0:
						print(f"     âš ï¸ GAP too short after adjustment ({seg_end - seg_start:.2f}s), skipping")
						continue
					
					if seg_start != original_start or seg_end != original_end:
						print(f"     ğŸ”§ Adjusted: {original_start:.2f}-{original_end:.2f} â†’ {seg_start:.2f}-{seg_end:.2f}")

					# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
					# ğŸ†• v16.31: Ğ£ĞœĞĞĞ¯ ĞĞ¢Ğ Ğ˜Ğ‘Ğ£Ğ¦Ğ˜Ğ¯ Ğ¡ Ğ£Ğ§ĞĞ¢ĞĞœ Ğ”Ğ›Ğ˜ĞĞ« Ğ¢Ğ•ĞšĞ¡Ğ¢Ğ
					# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
					
					final_speaker = detected_speaker
					
					# ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·ÑƒĞµĞ¼ gap text
					gap_text_normalized = re.sub(r'[^\w\s]', '', text.lower().strip())
					gap_words = gap_text_normalized.split()
					gap_words_count = len(gap_words)
					
					compare_words_count_next = gap_words_count * 2
					
					# ğŸ†• v16.31: ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ´Ğ»Ğ¸Ğ½Ñƒ gap Ñ‚ĞµĞºÑÑ‚Ğ°
					print(f"    ğŸ“ GAP Ğ´Ğ»Ğ¸Ğ½Ğ°: {gap_words_count} ÑĞ»Ğ¾Ğ²")
					
					# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
					# v16.30: N-GRAM OVERLAP Ñ PREV (Ğ±ĞµĞ· Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹)
					# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
					
					prev_segment = None
					for existing_seg in sorted(existing_segments, key=lambda x: x['end'], reverse=True):
						if existing_seg['end'] <= gap_start:
							prev_segment = existing_seg
							break
					
					skip_gap = False
					if prev_segment and gap_words_count >= 3:
						prev_text = prev_segment.get('text', '')
						prev_text_normalized = re.sub(r'[^\w\s]', '', prev_text.lower().strip())
						
						for i in range(len(gap_words) - 2):
							trigram = ' '.join(gap_words[i:i+3])
							if trigram in prev_text_normalized:
								print(f"    âš ï¸ GAP ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ Ñ„Ñ€Ğ°Ğ·Ñƒ Ğ¸Ğ· prev ('{trigram}') â†’ SKIP (duplicate)")
								skip_gap = True
								break
					
					if skip_gap:
						continue
					
					# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
					# v16.29: TEXT SIMILARITY Ñ NEXT (Ğ±ĞµĞ· Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹)
					# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
					
					next_segment = None
					for existing_seg in sorted(existing_segments, key=lambda x: x['start']):
						if existing_seg['start'] >= gap_end:
							next_segment = existing_seg
							break
					
					if next_segment:
						next_speaker = next_segment.get('speaker')
						next_text = next_segment.get('text', '')
						
						if next_speaker and next_speaker != detected_speaker:
							next_text_normalized = re.sub(r'[^\w\s]', '', next_text.lower().strip())
							next_words = next_text_normalized.split()
							next_text_compare = ' '.join(next_words[:compare_words_count_next])
							
							similarity_next = text_similarity(gap_text_normalized, next_text_compare)
							
							print(f"    ğŸ” Text similarity Ñ next [{next_speaker}]: {similarity_next:.1%}")
							
							if similarity_next > 0.55:
								print(f"    âš ï¸ GAP ÑĞ»Ğ¸ÑˆĞºĞ¾Ğ¼ Ğ¿Ğ¾Ñ…Ğ¾Ğ¶ Ğ½Ğ° next ({similarity_next:.0%}) â†’ SKIP (hallucination)")
								continue
							
							if similarity_next > 0.50:
								final_speaker = next_speaker
								print(f"    ğŸ”„ GAP_FILLED â†’ {next_speaker} (ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾ {similarity_next:.1%})")
							else:
								# ğŸ†• v16.31: Ğ›Ğ¾Ğ³Ğ¸ĞºĞ° Ğ´Ğ»Ñ Ğ”Ğ›Ğ˜ĞĞĞ«Ğ¥ gap
								if gap_words_count > 20:
									# Ğ”Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚ â†’ ĞĞ• Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ "Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ" Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚Ğ¾Ğ¼!
									# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ prev_speaker
									if prev_segment:
										prev_speaker = prev_segment.get('speaker')
										if prev_speaker == speaker_surname:
											final_speaker = speaker_surname
											print(f"    ğŸ”„ GAP_FILLED (Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğ¹, {gap_words_count} ÑĞ»Ğ¾Ğ²) â†’ {speaker_surname} (Ğ¿Ğ¾ prev)")
										else:
											print(f"    âœ… GAP_FILLED (Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğ¹) â†’ {detected_speaker} (Ğ½Ğµ ÑƒĞ²ĞµÑ€ĞµĞ½Ñ‹, Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑĞµĞ¼ detected)")
									else:
										print(f"    âœ… GAP_FILLED (Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğ¹) â†’ {detected_speaker}")
								else:
									print(f"    âœ… GAP_FILLED â†’ {detected_speaker} (Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ)")

					new_segment = {
						'start': seg_start,
						'end': seg_end,
						'start_hms': seconds_to_hms(seg_start),
						'end_hms': seconds_to_hms(seg_end),
						'text': text,
						'speaker': final_speaker,
						'raw_speaker_id': 'GAP_FILLED',
						'confidence': seg.get('avg_logprob', -1.0),
						'from_gap': True
					}

					added_segments.append(new_segment)
					print(f"    âœ… [{seconds_to_hms(seg_start)}] {text[:50]}...")

		except Exception as e:
			print(f"  âŒ Gap Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ Ğ½Ğµ ÑƒĞ´Ğ°Ğ»Ğ°ÑÑŒ: {e}")

		finally:
			if gap_audio_path.exists():
				gap_audio_path.unlink()

	if added_segments:
		print(f"  âœ… Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ Ğ¸Ğ· gaps: {len(added_segments)} ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²")
	else:
		print(f"  âš ï¸ Gaps Ğ½Ğµ Ğ´Ğ°Ğ»Ğ¸ Ğ½Ğ¾Ğ²Ñ‹Ñ… ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²")

	return added_segments
