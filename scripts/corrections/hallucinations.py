#!/usr/bin/env python3
"""
corrections/hallucinations.py - –£–¥–∞–ª–µ–Ω–∏–µ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π Whisper

üîß v16.28: clean_loops() –ù–ï —É–¥–∞–ª—è–µ—Ç - –∑–∞–º–µ–Ω—è–µ—Ç –Ω–∞ "..."
- –í–º–µ—Å—Ç–æ —É–¥–∞–ª–µ–Ω–∏—è repeating n-grams ‚Üí –∑–∞–º–µ–Ω–∞ –Ω–∞ "..."
- Threshold: 95% (–æ—á–µ–Ω—å —Å—Ç—Ä–æ–≥–æ!)
- Min n-gram size: 4 —Å–ª–æ–≤–∞ (–Ω–µ 2!)
- –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç, –ù–ï —Ç–µ—Ä—è–µ–º —Å–º—ã—Å–ª

üÜï v16.19: –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX - –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–µ–π + "–ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å–ª–µ–¥—É–µ—Ç"
- –î–µ—Ç–µ–∫—Ü–∏—è –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ—Ä–∞–∑ (similarity >95%)
- –£–¥–∞–ª–µ–Ω–∏–µ Whisper hallucination –≤ –∫–æ–Ω—Ü–µ —Ñ–∞–π–ª–∞ ("–ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å–ª–µ–¥—É–µ—Ç", "–°–ø–∞—Å–∏–±–æ –∑–∞ –≤–Ω–∏–º–∞–Ω–∏–µ")
- –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–µ–π —Å —Ä–∞–∑–Ω—ã–º —Ä–µ–≥–∏—Å—Ç—Ä–æ–º ("–ª–æ–≥–∏—á–Ω—ã–º –õ–æ–≥–∏—á–Ω—ã–º")
"""

import re
from difflib import SequenceMatcher


def is_hallucination(text):
    """
    ‚úÖ LEGACY FUNCTION (–¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å transcription.py)
    
    –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–µ–∫—Å—Ç –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–µ–π Whisper.
    
    –¢–∏–ø–∏—á–Ω—ã–µ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏:
    - –ü—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç
    - –¢–æ–ª—å–∫–æ –ø—Ä–æ–±–µ–ª—ã/–ø—É–Ω–∫—Ç—É–∞—Ü–∏—è
    - –ö–æ—Ä–æ—Ç–∫–∏–µ –±–µ—Å—Å–º—ã—Å–ª–µ–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã
    - –ü–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è —Å–∏–º–≤–æ–ª—ã
    
    Args:
        text: –¢–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
    
    Returns:
        bool: True –µ—Å–ª–∏ —ç—Ç–æ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏—è
    """
    if not text or not text.strip():
        return True
    
    # –£–±–∏—Ä–∞–µ–º –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é
    clean = re.sub(r'[^\w\s]', '', text)
    
    # –¢–æ–ª—å–∫–æ –ø—Ä–æ–±–µ–ª—ã
    if not clean.strip():
        return True
    
    # –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π (–º–µ–Ω—å—à–µ 3 —Å–∏–º–≤–æ–ª–æ–≤)
    if len(clean.strip()) < 3:
        return True
    
    # –ü–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è —Å–∏–º–≤–æ–ª—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä "–∞–∞–∞–∞–∞")
    if len(set(clean.lower())) < 3:
        return True
    
    return False


def clean_loops(text, is_gap_filled=False, debug=False):
    """
    üîß v16.28: –ó–ê–ú–ï–ù–Ø–ï–¢ hallucination loops –Ω–∞ "..." (–ù–ï —É–¥–∞–ª—è–µ—Ç!)
    
    v16.27 –ø—Ä–æ–±–ª–µ–º–∞: —É–¥–∞–ª–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ ‚Üí –ø–æ—Ç–µ—Ä—è —Å–º—ã—Å–ª–∞
    v16.28 —Ä–µ—à–µ–Ω–∏–µ: –∑–∞–º–µ–Ω–∞ –Ω–∞ "..." ‚Üí —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    
    Whisper –∏–Ω–æ–≥–¥–∞ —Å–æ–∑–¥–∞—ë—Ç –ø–µ—Ç–ª–∏ –ø—Ä–∏ force-transcribe gaps:
    "—É—á–∏—Ç—ã–≤–∞—Ç—å –±—ã–ª–∞ –Ω–µ–º–µ—Ü–∫–∞—è –∞—Ä—Ç–∏–ª–ª–µ—Ä–∏—è –≤–ø—Ä–∞–≤—å –¥–æ –µ—â–µ —Ñ–∞–∫—Ç–æ—Ä–æ–º
     –∫–æ—Ç–æ—Ä—ã–µ –Ω–∞–¥–æ —É—á–∏—Ç—ã–≤–∞—Ç—å —ç—Ç–æ –±—ã–ª–æ –Ω–µ–º–µ—Ü–∫–∞—è –≤–ø–ª–æ—Ç—å –¥–æ"
    
    –ë–´–õ–û (v16.27): "—É—á–∏—Ç—ã–≤–∞—Ç—å –±—ã–ª–∞ –Ω–µ–º–µ—Ü–∫–∞—è –∞—Ä—Ç–∏–ª–ª–µ—Ä–∏—è"  ‚ùå –ø–æ—Ç–µ—Ä—è —Ç–µ–∫—Å—Ç–∞!
    –°–¢–ê–õ–û (v16.28): "—É—á–∏—Ç—ã–≤–∞—Ç—å ... –Ω–µ–º–µ—Ü–∫–∞—è –∞—Ä—Ç–∏–ª–ª–µ—Ä–∏—è" ‚úÖ –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω!
    
    –ê–ª–≥–æ—Ä–∏—Ç–º:
    1. –†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —Å–ª–æ–≤–∞
    2. –°–æ–∑–¥–∞—ë—Ç n-–≥—Ä–∞–º–º—ã (4-8 —Å–ª–æ–≤, –Ω–µ 2!)
    3. –ò—â–µ—Ç –û–ß–ï–ù–¨ –ø–æ—Ö–æ–∂–∏–µ n-–≥—Ä–∞–º–º—ã (similarity >= 95%)
    4. –ó–∞–º–µ–Ω—è–µ—Ç –ø–æ–≤—Ç–æ—Ä—ã –Ω–∞ "..." (–ù–ï —É–¥–∞–ª—è–µ—Ç!)
    
    Args:
        text: –¢–µ–∫—Å—Ç –¥–ª—è –æ—á–∏—Å—Ç–∫–∏
        is_gap_filled: –≠—Ç–æ gap-filled —Å–µ–≥–º–µ–Ω—Ç (—Å—Ç—Ä–æ–∂–µ)
        debug: –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å debug output
    
    Returns:
        –¢–µ–∫—Å—Ç —Å "..." –≤–º–µ—Å—Ç–æ loops
    """
    if not text or len(text) < 30:
        return text
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º: –ø—É–Ω–∫—Ç—É–∞—Ü–∏—è ‚Üí –ø—Ä–æ–±–µ–ª—ã
    normalized = re.sub(r'[^\w\s]', ' ', text.lower())
    words = [w for w in normalized.split() if w]
    
    if len(words) < 8:
        return text  # –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π
    
    # –ò—â–µ–º repeating n-grams
    loop_positions = []  # [(start_word_idx, end_word_idx, ngram_text), ...]
    
    # üÜï v16.28: min_size=4 (–Ω–µ 2!), max_size=8
    for ngram_size in range(8, 3, -1):  # 8‚Üí4 (–Ω–µ 8‚Üí2!)
        if ngram_size > len(words) // 3:  # –ù–µ –±–æ–ª—å—à–µ 1/3 —Ç–µ–∫—Å—Ç–∞
            continue
        
        # üÜï v16.28: –°–¢–†–û–ì–ò–ô threshold 95% (–Ω–µ 75-85%!)
        threshold = 0.95
        
        # Gap-filled: threshold 97% (–µ—â—ë —Å—Ç—Ä–æ–∂–µ!)
        if is_gap_filled:
            threshold = 0.97
        
        # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É n-–≥—Ä–∞–º–º–∞–º–∏
        min_distance = max(ngram_size, 4)
        
        # –°–æ–∑–¥–∞—ë–º n-–≥—Ä–∞–º–º—ã
        ngrams = []
        for i in range(len(words) - ngram_size + 1):
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —É–∂–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ loops
            if any(start <= i < end for start, end, _ in loop_positions):
                continue
            
            ngram = ' '.join(words[i:i+ngram_size])
            ngrams.append((i, ngram))
        
        # –ò—â–µ–º –ø–æ–≤—Ç–æ—Ä—ã
        for idx1, (pos1, ngram1) in enumerate(ngrams):
            if any(start <= pos1 < end for start, end, _ in loop_positions):
                continue
            
            for pos2, ngram2 in ngrams[idx1+1:]:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ
                if pos2 - pos1 < min_distance:
                    continue
                
                # –£–∂–µ –Ω–∞–π–¥–µ–Ω–æ?
                if any(start <= pos2 < end for start, end, _ in loop_positions):
                    continue
                
                # Similarity
                similarity = SequenceMatcher(None, ngram1, ngram2).ratio()
                
                if similarity >= threshold:
                    if debug:
                        print(f"  üîç LOOP (n={ngram_size}, sim={similarity:.0%}): \"{ngram1}\" ‚âà \"{ngram2}\"")
                    
                    # üÜï v16.28: –ü–æ–º–µ—á–∞–µ–º –¥–ª—è –∑–∞–º–µ–Ω—ã –Ω–∞ "..."
                    loop_positions.append((pos1, pos1 + ngram_size, ngram1))
                    loop_positions.append((pos2, pos2 + ngram_size, ngram2))
                    break  # –ù–∞—à–ª–∏ loop –¥–ª—è —ç—Ç–æ–π n-–≥—Ä–∞–º–º—ã
    
    # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ loops ‚Üí –∑–∞–º–µ–Ω—è–µ–º –Ω–∞ "..."
    if loop_positions:
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ start position
        loop_positions.sort()
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –ø–µ—Ä–µ—Å–µ–∫–∞—é—â–∏–µ—Å—è –¥–∏–∞–ø–∞–∑–æ–Ω—ã
        merged_loops = []
        for start, end, ngram_text in loop_positions:
            if merged_loops and start < merged_loops[-1][1]:
                # –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ ‚Üí —Ä–∞—Å—à–∏—Ä—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π
                merged_loops[-1] = (merged_loops[-1][0], max(merged_loops[-1][1], end))
            else:
                merged_loops.append((start, end))
        
        # üÜï v16.28: –ó–∞–º–µ–Ω—è–µ–º loops –Ω–∞ "..."
        original_words = text.split()
        result_words = []
        norm_idx = 0
        last_was_ellipsis = False
        
        for orig_word in original_words:
            # –£–±–∏—Ä–∞–µ–º –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è
            word_clean = re.sub(r'[^\w]', '', orig_word.lower())
            
            if word_clean:  # –ù–µ –ø—É—Å—Ç–æ–µ —Å–ª–æ–≤–æ
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º: —ç—Ç–æ loop?
                is_in_loop = any(start <= norm_idx < end for start, end in merged_loops)
                
                if is_in_loop:
                    # –í—Å—Ç–∞–≤–ª—è–µ–º "..." —Ç–æ–ª—å–∫–æ –û–î–ò–ù —Ä–∞–∑ –Ω–∞ loop
                    if not last_was_ellipsis:
                        result_words.append("...")
                        last_was_ellipsis = True
                else:
                    result_words.append(orig_word)
                    last_was_ellipsis = False
                
                norm_idx += 1
            else:
                # –ü—É–Ω–∫—Ç—É–∞—Ü–∏—è –º–µ–∂–¥—É —Å–ª–æ–≤–∞–º–∏
                if result_words and not last_was_ellipsis:
                    result_words.append(orig_word)
        
        cleaned_text = ' '.join(result_words)
        
        # –û—á–∏—Å—Ç–∫–∞ –¥–≤–æ–π–Ω—ã—Ö –ø—Ä–æ–±–µ–ª–æ–≤
        cleaned_text = re.sub(r'\s+', ' ', cleaned_text).strip()
        
        if debug:
            print(f"  ‚úÖ Loops replaced with '...': {len(original_words)} ‚Üí {len(result_words)} —Å–ª–æ–≤")
        
        return cleaned_text
    
    return text


def is_duplicate_phrase(text, debug=False):
    """
    üÜï v16.19: –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã
    
    –ü—Ä–∏–º–µ—Ä—ã –¥—É–±–ª–µ–π:
    - "–Ω–∏—á–µ–≥–æ –Ω–µ –∑–Ω–∞–ª–∏. –Ω–∏—á–µ–≥–æ –Ω–µ –∑–Ω–∞–ª–∏."
    - "–ª–æ–≥–∏—á–Ω—ã–º –õ–æ–≥–∏—á–Ω—ã–º —Ä–µ—à–µ–Ω–∏–µ–º"
    - "–Ω–∞—á–∏–Ω–∞–µ—Ç –Ω–∞—Å—Ç—É–ø–∞—Ç—å –Ω–∞—á–∏–Ω–∞–µ—Ç –Ω–∞—Å—Ç—É–ø–∞—Ç—å"
    
    Args:
        text: –¢–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        debug: –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å debug output
    
    Returns:
        (has_duplicate, cleaned_text)
    """
    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
    sentences = re.split(r'([.!?]+)\s*', text)
    sentences = [s.strip() for s in sentences if s.strip() and s not in '.!?']
    
    if len(sentences) < 2:
        return False, text
    
    # –ò—â–µ–º —Å–º–µ–∂–Ω—ã–µ –¥—É–±–ª–∏
    cleaned_sentences = []
    skip_next = False
    duplicates_found = 0
    
    for i in range(len(sentences)):
        if skip_next:
            skip_next = False
            continue
        
        current = sentences[i]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–ª–µ–¥—É—é—â–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
        if i < len(sentences) - 1:
            next_sent = sentences[i + 1]
            
            # Similarity (–∏–≥–Ω–æ—Ä–∏—Ä—É—è —Ä–µ–≥–∏—Å—Ç—Ä)
            similarity = SequenceMatcher(
                None, 
                current.lower().strip(), 
                next_sent.lower().strip()
            ).ratio()
            
            if similarity > 0.95:  # 95% similarity = –¥—É–±–ª—å!
                if debug:
                    print(f"  üîç –î–£–ë–õ–¨ (similarity={similarity:.2%}): \"{current}\" ‚âà \"{next_sent}\"")
                
                # –ë–µ—Ä—ë–º –±–æ–ª–µ–µ –¥–ª–∏–Ω–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç
                if len(next_sent) > len(current):
                    cleaned_sentences.append(next_sent)
                else:
                    cleaned_sentences.append(current)
                
                skip_next = True
                duplicates_found += 1
                continue
        
        cleaned_sentences.append(current)
    
    if duplicates_found > 0:
        cleaned_text = '. '.join(cleaned_sentences) + '.'
        return True, cleaned_text
    
    return False, text


def remove_ending_hallucinations(text, debug=False):
    """
    üÜï v16.19: –£–¥–∞–ª—è–µ—Ç —Ç–∏–ø–∏—á–Ω—ã–µ Whisper hallucination –≤ –∫–æ–Ω—Ü–µ —Ç–µ–∫—Å—Ç–∞
    
    Whisper —á–∞—Å—Ç–æ –¥–æ–±–∞–≤–ª—è–µ—Ç –≤ –∫–æ–Ω—Ü–µ —Ñ–∞–π–ª–∞:
    - "–ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å–ª–µ–¥—É–µ—Ç"
    - "–°–ø–∞—Å–∏–±–æ –∑–∞ –≤–Ω–∏–º–∞–Ω–∏–µ"
    - "–î–æ –Ω–æ–≤—ã—Ö –≤—Å—Ç—Ä–µ—á"
    - "–ü–æ–¥–ø–∏—Å—ã–≤–∞–π—Ç–µ—Å—å –Ω–∞ –Ω–∞—à –∫–∞–Ω–∞–ª"
    
    Args:
        text: –¢–µ–∫—Å—Ç —Å–µ–≥–º–µ–Ω—Ç–∞
        debug: –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å debug output
    
    Returns:
        –û—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
    """
    hallucination_patterns = [
        r'–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ\s+—Å–ª–µ–¥—É–µ—Ç[.!?]*\s*$',
        r'—Å–ø–∞—Å–∏–±–æ\s+–∑–∞\s+–≤–Ω–∏–º–∞–Ω–∏–µ[.!?]*\s*$',
        r'–¥–æ\s+–Ω–æ–≤—ã—Ö\s+–≤—Å—Ç—Ä–µ—á[.!?]*\s*$',
        r'–ø–æ–¥–ø–∏—Å—ã–≤–∞–π—Ç–µ—Å—å\s+–Ω–∞\s+–Ω–∞—à\s+–∫–∞–Ω–∞–ª[.!?]*\s*$',
        r'—Å—Ç–∞–≤—å—Ç–µ\s+–ª–∞–π–∫–∏[.!?]*\s*$',
    ]
    
    text_lower = text.lower()
    
    for pattern in hallucination_patterns:
        if re.search(pattern, text_lower):
            cleaned = re.sub(pattern, '', text, flags=re.IGNORECASE).strip()
            
            if debug:
                removed = text[len(cleaned):].strip()
                print(f"  üóëÔ∏è HALLUCINATION: —É–¥–∞–ª–µ–Ω–∞ —Ñ—Ä–∞–∑–∞ \"{removed}\"")
            
            return cleaned
    
    return text


def clean_hallucinations_from_text(text, speaker=None, is_gap_filled=False, debug=False):
    """
    üîß v16.28: –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –æ—Ç –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π
    
    –í—ã–ø–æ–ª–Ω—è–µ—Ç:
    1. üîß –ó–∞–º–µ–Ω–∞ hallucination loops –Ω–∞ "..." (–ù–ï —É–¥–∞–ª–µ–Ω–∏–µ!)
    2. –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ—Ä–∞–∑
    3. –£–¥–∞–ª–µ–Ω–∏–µ ending hallucinations
    4. –û—á–∏—Å—Ç–∫–∞ multiple –ø—Ä–æ–±–µ–ª–æ–≤ –∏ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏
    
    Args:
        text: –¢–µ–∫—Å—Ç –¥–ª—è –æ—á–∏—Å—Ç–∫–∏
        speaker: –°–ø–∏–∫–µ—Ä (–¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)
        is_gap_filled: –≠—Ç–æ gap-filled —Å–µ–≥–º–µ–Ω—Ç (—Å—Ç—Ä–æ–∂–µ)
        debug: –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å debug output
    
    Returns:
        –û—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
    """
    if not text or not text.strip():
        return text
    
    original_text = text
    
    # 1. üîß v16.28: –ó–∞–º–µ–Ω–∞ hallucination loops –Ω–∞ "..."
    text = clean_loops(text, is_gap_filled=is_gap_filled, debug=debug)
    
    # 2. –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–µ–π
    has_dupl, text = is_duplicate_phrase(text, debug=debug)
    
    # 3. –£–¥–∞–ª–µ–Ω–∏–µ ending hallucinations
    text = remove_ending_hallucinations(text, debug=debug)
    
    # 4. –û—á–∏—Å—Ç–∫–∞ –ø—Ä–æ–±–µ–ª–æ–≤ –∏ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏
    text = re.sub(r'\s+', ' ', text)  # Multiple spaces ‚Üí one
    text = re.sub(r'([.!?]){2,}', r'\1', text)  # Multiple punctuation ‚Üí one
    text = text.strip()
    
    if debug and text != original_text:
        print(f"  ‚úÖ –û—á–∏—â–µ–Ω–æ: {len(original_text)} ‚Üí {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
    
    return text


def filter_hallucination_segments(segments, debug=True):
    """
    üîß v16.28: –§–∏–ª—å—Ç—Ä—É–µ—Ç —Å–µ–≥–º–µ–Ω—Ç—ã –æ—Ç –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π
    
    –ü—Ä–∏–º–µ–Ω—è–µ—Ç clean_hallucinations_from_text() –∫ –∫–∞–∂–¥–æ–º—É —Å–µ–≥–º–µ–Ω—Ç—É.
    –£–¥–∞–ª—è–µ—Ç —Å–µ–≥–º–µ–Ω—Ç—ã, —Å—Ç–∞–≤—à–∏–µ –ø—É—Å—Ç—ã–º–∏ –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏.
    –ü–µ—Ä–µ–¥–∞—ë—Ç is_gap_filled —Ñ–ª–∞–≥ –¥–ª—è gap-filled —Å–µ–≥–º–µ–Ω—Ç–æ–≤.
    
    Args:
        segments: –°–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
        debug: –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å debug output
    
    Returns:
        –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Å–µ–≥–º–µ–Ω—Ç–æ–≤
    """
    if debug:
        print(f"\nüßπ –û—á–∏—Å—Ç–∫–∞ hallucinations –∏–∑ {len(segments)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤...")
    
    cleaned_segments = []
    removed_count = 0
    
    for seg in segments:
        text = seg.get('text', '')
        speaker = seg.get('speaker', '')
        is_gap_filled = seg.get('source') == 'GAP_FILLED'
        
        cleaned_text = clean_hallucinations_from_text(
            text, speaker, is_gap_filled=is_gap_filled, debug=debug
        )
        
        if cleaned_text:
            seg['text'] = cleaned_text
            cleaned_segments.append(seg)
        else:
            removed_count += 1
            if debug:
                print(f"  üóëÔ∏è –£–¥–∞–ª—ë–Ω –ø—É—Å—Ç–æ–π —Å–µ–≥–º–µ–Ω—Ç: {seg.get('time', '???')} ({speaker})")
    
    if debug:
        print(f"‚úÖ –û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(cleaned_segments)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤ (—É–¥–∞–ª–µ–Ω–æ {removed_count})")
    
    return cleaned_segments
