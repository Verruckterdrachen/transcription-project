#!/usr/bin/env python3
"""
corrections/boundary_fixer.py - Boundary correction v16.43

üî• v16.43: FIX –ë–ê–ì #13 - Journalist \"–≤–æ–ø—Ä–æ—Å\" pattern (context check)
üî• v16.42: FIX –ë–ê–ì #13 - Journalist \"–≤–æ–ø—Ä–æ—Å\" pattern (–±–µ–∑ \\b –≤ –∫–æ–Ω—Ü–µ)
üî• v16.41: FIX –ë–ê–ì #12, #13 - Split regex + journalist \"–≤–æ–ø—Ä–æ—Å\"
"""

import re
from difflib import SequenceMatcher
from core.utils import seconds_to_hms


def is_journalist_phrase(text):
    """
    üÜï v16.43: FIX –ë–ê–ì #13 - Context check –¥–ª—è \"–≤–æ–ø—Ä–æ—Å\"
    
    **–ü–†–û–ë–õ–ï–ú–ê v16.42:**
    Pattern r'\\b–≤–æ–ø—Ä–æ—Å' –º–∞—Ç—á–∏–ª –í–°–ï —Ñ–æ—Ä–º—ã \"–≤–æ–ø—Ä–æ—Å\":
    - \"–î—Ä—É–≥–æ–π –≤–æ–ø—Ä–æ—Å, —á—Ç–æ –ø—Ä–æ–≤–æ–¥–∏–≤—à–∏–µ—Å—è...\" ‚Üí match! ‚ùå
    - \"–î–≤–∞ –≤–æ–ø—Ä–æ—Å–∞ –∫ –≤–∞–º\" ‚Üí match! ‚úÖ
    
    \"–î—Ä—É–≥–æ–π –≤–æ–ø—Ä–æ—Å, —á—Ç–æ...\" - —ç—Ç–æ –í–í–û–î–ù–ê–Ø –§–†–ê–ó–ê —Å–ø–∏–∫–µ—Ä–∞, –ù–ï –≤–æ–ø—Ä–æ—Å –∂—É—Ä–Ω–∞–ª–∏—Å—Ç–∞!
    
    **FIX v16.43:**
    –î–æ–±–∞–≤–ª–µ–Ω context check:
    - –ï—Å–ª–∏ \"–≤–æ–ø—Ä–æ—Å\" –≤ –Ω–∞—á–∞–ª–µ (–ø–µ—Ä–≤—ã–µ 2 —Å–ª–æ–≤–∞) ‚Üí –∂—É—Ä–Ω–∞–ª–∏—Å—Ç ‚úÖ
    - –ï—Å–ª–∏ \"–≤–æ–ø—Ä–æ—Å\" + \"—á—Ç–æ/–∫–∞–∫/–∫–æ–≥–¥–∞/–ø–æ—á–µ–º—É\" ‚Üí –≤–≤–æ–¥–Ω–∞—è —Ñ—Ä–∞–∑–∞, –ù–ï –∂—É—Ä–Ω–∞–ª–∏—Å—Ç ‚ùå
    - –ò–Ω–∞—á–µ ‚Üí –∂—É—Ä–Ω–∞–ª–∏—Å—Ç ‚úÖ
    
    **–ü—Ä–∏–º–µ—Ä—ã:**
    - \"–î—Ä—É–≥–æ–π –≤–æ–ø—Ä–æ—Å, —á—Ç–æ –ø—Ä–æ–≤–æ–¥–∏–≤—à–∏–µ—Å—è...\" ‚Üí –ù–ï –∂—É—Ä–Ω–∞–ª–∏—Å—Ç (–≤–≤–æ–¥–Ω–∞—è)
    - \"–í–æ–ø—Ä–æ—Å –∫ –≤–∞–º\" ‚Üí –∂—É—Ä–Ω–∞–ª–∏—Å—Ç
    - \"–î–≤–∞ –≤–æ–ø—Ä–æ—Å–∞\" ‚Üí –∂—É—Ä–Ω–∞–ª–∏—Å—Ç
    - \"–ê –≤–æ–ø—Ä–æ—Å —Ç–∞–∫–æ–π\" ‚Üí –∂—É—Ä–Ω–∞–ª–∏—Å—Ç
    """
    text_lower = text.lower()
    
    # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª—è \"–≤–æ–ø—Ä–æ—Å\"
    if '–≤–æ–ø—Ä–æ—Å' in text_lower:
        # –ï—Å–ª–∏ \"–≤–æ–ø—Ä–æ—Å\" + —Å–æ—é–∑ \"—á—Ç–æ/–∫–∞–∫/–∫–æ–≥–¥–∞/–ø–æ—á–µ–º—É\" ‚Üí —ç—Ç–æ –≤–≤–æ–¥–Ω–∞—è —Ñ—Ä–∞–∑–∞
        if re.search(r'\\b–≤–æ–ø—Ä–æ—Å[–∞-—è]*[,\\s]+(—á—Ç–æ|–∫–∞–∫|–∫–æ–≥–¥–∞|–ø–æ—á–µ–º—É)\\b', text_lower):
            # \"–î—Ä—É–≥–æ–π –≤–æ–ø—Ä–æ—Å, —á—Ç–æ...\" ‚Üí –ù–ï –∂—É—Ä–Ω–∞–ª–∏—Å—Ç
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–∑–∏—Ü–∏—é \"–≤–æ–ø—Ä–æ—Å\" –≤ —Ç–µ–∫—Å—Ç–µ
        words = text_lower.split()
        for i, word in enumerate(words):
            if '–≤–æ–ø—Ä–æ—Å' in word:
                # –ï—Å–ª–∏ \"–≤–æ–ø—Ä–æ—Å\" –≤ –ø–µ—Ä–≤—ã—Ö 2 —Å–ª–æ–≤–∞—Ö ‚Üí –∂—É—Ä–Ω–∞–ª–∏—Å—Ç
                # \"–í–æ–ø—Ä–æ—Å –∫ –≤–∞–º\", \"–î–≤–∞ –≤–æ–ø—Ä–æ—Å–∞\"
                if i < 2:
                    return True
                # –ï—Å–ª–∏ –¥–∞–ª—å—à–µ ‚Üí –ø—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
                # \"–ê –≤–æ–ø—Ä–æ—Å —Ç–∞–∫–æ–π\" (i=1) ‚Üí –∂—É—Ä–Ω–∞–ª–∏—Å—Ç
                # \"–î—Ä—É–≥–æ–π –≤–æ–ø—Ä–æ—Å, —á—Ç–æ\" (i=1, –Ω–æ –µ—Å—Ç—å —Å–æ—é–∑) ‚Üí —É–∂–µ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ –≤—ã—à–µ
                return True
    
    journalist_markers = [
        r'\\b–≤—ã\\s+(–º–æ–∂–µ—Ç–µ|–º–æ–≥–ª–∏|–¥–æ–ª–∂–Ω—ã)?',
        r'\\b—Ä–∞—Å—Å–∫–∞–∂–∏—Ç–µ\\b',
        r'\\b–æ–±—ä—è—Å–Ω–∏—Ç–µ\\b',
        r'\\b–∫–∞–∫\\s+–≤—ã\\b',
        r'\\b–ø–æ—á–µ–º—É\\s+–≤—ã\\b',
        r'\\b—á—Ç–æ\\s+–≤—ã\\b',
        r'\\b–¥–∞–≤–∞–π—Ç–µ\\b',
        r'\\b—Å–º–æ—Ç—Ä–∏–º\\b',
    ]
    
    for marker in journalist_markers:
        if re.search(marker, text_lower):
            return True
    return False


def is_expert_phrase(text, speaker_surname):
    """
    v16.16: –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ—Ä–∞–∑–∞ —ç–∫—Å–ø–µ—Ä—Ç–Ω–æ–π
    
    üî• v16.16: –î–æ–±–∞–≤–ª–µ–Ω \\b (word boundary) –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ —Ü–µ–ª—ã—Ö —Å–ª–æ–≤
    """
    if not speaker_surname:
        return False
    
    text_lower = text.lower()
    surname_lower = speaker_surname.lower()
    
    expert_markers = [
        surname_lower,
        r'\\b—è\\s+(—Å—á–∏—Ç–∞—é|–¥—É–º–∞—é|–ø–æ–ª–∞–≥–∞—é)\\b',
        r'\\b–Ω–∞\\s+–º–æ–π\\s+–≤–∑–≥–ª—è–¥\\b',
        r'\\b–ø–æ\\s+–º–æ–µ–º—É\\s+–º–Ω–µ–Ω–∏—é\\b',
    ]
    
    for marker in expert_markers:
        if re.search(marker, text_lower):
            return True
    return False


def detect_continuation_phrase(current_text, previous_texts, threshold=0.90):
    """
    üîß v16.19: –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX –ë–ê–ì #3 - –ü–æ–≤—ã—à–µ–Ω –ø–æ—Ä–æ–≥ similarity —Å 80% –¥–æ 90%
    """
    if not previous_texts:
        return False, 0.0, None
    
    current_lower = current_text.lower().strip()
    
    for prev_text in previous_texts[-3:]:
        prev_lower = prev_text.lower().strip()
        
        similarity = SequenceMatcher(None, current_lower, prev_lower).ratio()
        
        if similarity >= threshold:
            return True, similarity, prev_text
    
    return False, 0.0, None


def is_continuation_phrase(text):
    """
    üÜï v16.39: FIX –ë–ê–ì #10 - –£—á–∏—Ç—ã–≤–∞–µ–º timestamps –≤ –Ω–∞—á–∞–ª–µ —Ç–µ–∫—Å—Ç–∞
    """
    text_lower = text.lower().strip()
    
    # üÜï v16.39: –£–¥–∞–ª—è–µ–º timestamp –∏–∑ –Ω–∞—á–∞–ª–∞ —Ç–µ–∫—Å—Ç–∞
    text_cleaned = re.sub(r'^\\s*\\d{2}:\\d{2}:\\d{2}\\s+', '', text_lower)
    
    continuation_patterns = [
        r'^—Ç–æ\\s+–µ—Å—Ç—å\\b',
        r'^–≤\\s+—á–∞—Å—Ç–Ω–æ—Å—Ç–∏\\b',
        r'^–∫—Ä–æ–º–µ\\s+—Ç–æ–≥–æ\\b',
        r'^—Ç–∞–∫–∂–µ\\b',
        r'^–∏–Ω—ã–º–∏\\s+—Å–ª–æ–≤–∞–º–∏\\b',
        r'^–¥—Ä—É–≥–∏–º–∏\\s+—Å–ª–æ–≤–∞–º–∏\\b',
        r'^–±–æ–ª–µ–µ\\s+—Ç–æ–≥–æ\\b',
        r'^–ø–æ–º–∏–º–æ\\s+—ç—Ç–æ–≥–æ\\b',
        r'^–ø—Ä–∏\\s+—ç—Ç–æ–º\\b',
        r'^–æ–¥–Ω–∞–∫–æ\\b',
        r'^—Ç–µ–º\\s+–Ω–µ\\s+–º–µ–Ω–µ–µ\\b',
        r'^–≤–ø—Ä–æ—á–µ–º\\b',
        r'^–Ω–µ—Å–º–æ—Ç—Ä—è\\b',
        r'^—Ö–æ—Ç—è\\b',
    ]
    
    for pattern in continuation_patterns:
        if re.search(pattern, text_cleaned):
            return True
    
    return False


def is_question_announcement(text):
    """
    üÜï v16.4: –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–µ–∫—Å—Ç –∞–Ω–æ–Ω—Å–æ–º –≤–æ–ø—Ä–æ—Å–∞
    """
    text_lower = text.lower()
    
    announcement_patterns = [
        r'—Å–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å\\s+(–ø—Ä–æ|–æ|–æ–±)',
        r'–µ—â–µ –≤–æ–ø—Ä–æ—Å\\s+(–ø—Ä–æ|–æ|–æ–±)',
        r'–¥—Ä—É–≥–æ–π –≤–æ–ø—Ä–æ—Å\\s+(–ø—Ä–æ|–æ|–æ–±)',
    ]
    
    for pattern in announcement_patterns:
        if re.search(pattern, text_lower):
            word_count = len(text.split())
            if word_count < 20:
                return True
    return False


def boundary_correction_raw(segments_raw, speaker_surname, speaker_roles):
    """
    üÜï v16.41: FIX –ë–ê–ì #12 - Split regex \\s* (–Ω–æ–ª—å –∏–ª–∏ –±–æ–ª—å—à–µ –ø—Ä–æ–±–µ–ª–æ–≤)
    v16.3.2: Boundary correction –º–µ–∂–¥—É —Å–ø–∏–∫–µ—Ä–∞–º–∏
    """
    if len(segments_raw) < 2:
        return segments_raw
    
    corrections = 0
    i = 0
    
    while i < len(segments_raw) - 1:
        current = segments_raw[i]
        next_seg = segments_raw[i + 1]
        
        current_speaker = current.get('speaker')
        next_speaker = next_seg.get('speaker')
        
        if current_speaker == next_speaker:
            i += 1
            continue
        
        current_text = current.get('text', '')
        sentences = re.split(r'[.!?]+\\s*', current_text)
        
        if len(sentences) < 2:
            i += 1
            continue
        
        last_sentence = sentences[-1].strip()
        word_count = len(last_sentence.split())
        
        if word_count > 10:
            i += 1
            continue
        
        current_end = current.get('end', 0)
        next_start = next_seg.get('start', 0)
        pause = next_start - current_end
        
        if pause > 0.5:
            i += 1
            continue
        
        is_journalist_text = is_journalist_phrase(last_sentence)
        is_expert_text = is_expert_phrase(last_sentence, speaker_surname)
        
        if is_journalist_text and next_speaker != "–ñ—É—Ä–Ω–∞–ª–∏—Å—Ç":
            i += 1
            continue
        
        if is_expert_text and next_speaker == "–ñ—É—Ä–Ω–∞–ª–∏—Å—Ç":
            i += 1
            continue
        
        remaining_text = '. '.join(sentences[:-1])
        if remaining_text:
            remaining_text = remaining_text.strip() + '.'
            current['text'] = remaining_text
        
        next_seg_text = f"{last_sentence} {next_seg.get('text', '')}"
        next_seg['text'] = next_seg_text.strip()
        
        print(f"  ‚úÇÔ∏è BOUNDARY FIX: {next_seg.get('start_hms', '???')} –ø–µ—Ä–µ–Ω–æ—Å ‚Üí {next_speaker}")
        print(f"     \\\"{last_sentence}\\\"")
        
        corrections += 1
        i += 1
    
    if corrections > 0:
        print(f"‚úÖ Boundary correction: {corrections}")
    
    return segments_raw


def split_mixed_speaker_segments(segments_merged, speaker_surname, speaker_roles, debug=True):
    """
    üÜï v16.43: FIX –ë–ê–ì #13 - Improved journalist \"–≤–æ–ø—Ä–æ—Å\" detection
    üÜï v16.41: FIX –ë–ê–ì #12 - Split regex \\s* (–Ω–æ–ª—å –∏–ª–∏ –±–æ–ª—å—à–µ –ø—Ä–æ–±–µ–ª–æ–≤)
    üî• v16.37: –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô FIX –ë–ê–ì #8.1 - –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç continuation –ü–ï–†–ï–î journalist markers
    """
    print("\\n‚úÇÔ∏è –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ mixed-speaker —Å–µ–≥–º–µ–Ω—Ç–æ–≤ (v16.43: FIX journalist detection)...")
    
    reverse_roles = {}
    
    for raw_id, role in speaker_roles.items():
        reverse_roles[role] = raw_id
    
    if speaker_surname:
        main_speaker_id = None
        for raw_id, role in speaker_roles.items():
            if role not in ("–ñ—É—Ä–Ω–∞–ª–∏—Å—Ç", "–û–ø–µ—Ä–∞—Ç–æ—Ä"):
                main_speaker_id = raw_id
                break
        
        if main_speaker_id:
            reverse_roles[speaker_surname] = main_speaker_id
            print(f"  üîó –ú–∞–ø–ø–∏–Ω–≥: \\\"{speaker_surname}\\\" ‚Üí {main_speaker_id}")
    
    print(f"  üìã Reverse roles: {reverse_roles}")
    
    result = []
    splitcount = 0
    continuation_fixed = 0
    
    for seg_idx, seg in enumerate(segments_merged):
        speaker = seg.get('speaker')
        text = seg.get('text', '')
        start = seg.get('start', 0)
        end = seg.get('end', 0)
        duration = end - start
        
        if is_question_announcement(text):
            result.append(seg)
            continue
        
        sentences = re.split(r'[.!?]+\\s*', text)
        sentences = [s.strip() for s in sentences if s.strip()]
        
        if len(sentences) < 2:
            result.append(seg)
            continue
        
        if debug and len(sentences) >= 2:
            print(f"\\n  üîç –ê–ù–ê–õ–ò–ó –°–ï–ì–ú–ï–ù–¢–ê: {seconds_to_hms(start)} ({speaker}) ‚Äî {len(sentences)} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π")
        
        original_speaker = speaker
        current_group = []
        current_speaker = speaker
        
        total_words = sum(len(s.split()) for s in sentences)
        current_time = start
        
        for sent_idx, sentence in enumerate(sentences):
            sentence = sentence.strip()
            if not sentence:
                continue
            
            is_journalist_sent = is_journalist_phrase(sentence)
            is_expert_sent = is_expert_phrase(sentence, speaker_surname)
            is_continuation = is_continuation_phrase(sentence)
            
            if debug:
                print(f"    [{sent_idx+1}] \\\"{sentence[:60]}...\\\"")
                print(f"        Journalist={is_journalist_sent} | Expert={is_expert_sent} | Continuation={is_continuation}")
            
            sentence_speaker = None
            reason = ""
            
            if is_continuation:
                current_group_words = sum(len(s.split()) for s in current_group)
                
                if current_group_words > 80:
                    sentence_speaker = current_speaker
                    reason = f"continuation + context (>{current_group_words} —Å–ª–æ–≤)"
                    if debug:
                        print(f"        ‚Üí {sentence_speaker} ({reason})")
                    continuation_fixed += 1
                else:
                    sentence_speaker = current_speaker
                    reason = f"continuation + inherit ({current_group_words} —Å–ª–æ–≤)"
            
            elif is_journalist_sent:
                sentence_speaker = "–ñ—É—Ä–Ω–∞–ª–∏—Å—Ç"
                reason = "is_journalist_phrase=True"
            
            elif is_expert_sent:
                sentence_speaker = speaker_surname
                reason = "is_expert_phrase=True"
            
            else:
                sentence_speaker = original_speaker
                reason = "neutral (return to original)"
            
            if debug:
                print(f"        ‚Üí SPEAKER: {sentence_speaker} ({reason})")
            
            if sentence_speaker != current_speaker and current_group:
                if debug:
                    print(f"        ‚ö†Ô∏è –°–ú–ï–ù–ê –°–ü–ò–ö–ï–†–ê: {current_speaker} ‚Üí {sentence_speaker}")
                
                group_text = '. '.join(current_group) + '.'
                group_words = len(group_text.split())
                group_duration = (group_words / total_words) * duration if total_words > 0 else 0
                group_end = current_time + group_duration
                
                newseg = seg.copy()
                newseg['text'] = group_text
                newseg['speaker'] = current_speaker
                newseg['start'] = current_time
                newseg['end'] = group_end
                newseg['time'] = seconds_to_hms(current_time)
                newseg['raw_speaker_id'] = reverse_roles.get(
                    current_speaker, 
                    seg.get('raw_speaker_id')
                )
                
                result.append(newseg)
                splitcount += 1
                
                print(f"  ‚úÇÔ∏è SPLIT: {newseg['time']} ({current_speaker}) \\\"{group_text[:50]}...\\\"")
                
                current_group = []
                current_time = group_end
                current_speaker = sentence_speaker
            
            current_group.append(sentence)
        
        if current_group:
            group_text = '. '.join(current_group) + '.'
            
            newseg = seg.copy()
            newseg['text'] = group_text
            newseg['speaker'] = current_speaker
            newseg['start'] = current_time
            newseg['end'] = end
            newseg['time'] = seconds_to_hms(current_time)
            newseg['raw_speaker_id'] = reverse_roles.get(
                current_speaker,
                seg.get('raw_speaker_id')
            )
            
            result.append(newseg)
    
    if splitcount > 0:
        print(f"‚úÖ –†–∞–∑–¥–µ–ª–µ–Ω–æ: {splitcount} mixed —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
    else:
        print(f"‚úÖ Mixed —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
    
    if continuation_fixed > 0:
        print(f"‚úÖ Continuation phrases –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: {continuation_fixed}")
    
    return result
