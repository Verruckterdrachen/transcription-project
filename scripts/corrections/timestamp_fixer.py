#!/usr/bin/env python3
"""
corrections/timestamp_fixer.py - Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ timestamp

ğŸ†• v17.14: FIX BAG_D â€” gap_fixer_v2: Ğ¿Ğ¾ÑÑ‚-Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ´ Ğ¿Ğ¾ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ¾Ğ¼Ñƒ Ñ‚ĞµĞºÑÑ‚Ñƒ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ°.
           ĞŸÑ€Ğ¸ gaps > 45s (Ğ´Ğ»Ğ¸Ğ½Ğ½Ğ¾Ğµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ, Ğ½ĞµÑ‚ Ñ‚Ğ¾Ñ‡ĞºĞ¸ Ğ² Ğ½ÑƒĞ¶Ğ½Ğ¾Ğ¼ Ğ¼ĞµÑÑ‚Ğµ)
           Ğ²ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ inject Ñ‡ĞµÑ€ĞµĞ· word-level walk + _get_real_time_for_word().
           Ğ˜Ğ´ĞµĞ¼Ğ¿Ğ¾Ñ‚ĞµĞ½Ñ‚ĞµĞ½: Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€Ğ½Ñ‹Ğ¹ Ğ²Ñ‹Ğ·Ğ¾Ğ² â†’ 0 inject ĞµÑĞ»Ğ¸ gaps ÑƒĞ¶Ğµ â‰¤ 45s.
ğŸ†• v17.11: FIX BAG_F â€” guard Ğ¿Ñ€Ğ¾Ñ‚Ğ¸Ğ² scale-Ğ°Ğ½Ğ¾Ğ¼Ğ°Ğ»Ğ¸Ğ¸ Ğ¿Ğ¾ÑĞ»Ğµ split
ğŸ†• v17.10: Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ A â€” Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ğµ timestamp Ñ‡ĞµÑ€ĞµĞ· sub_segments Ğ¸Ğ· merge_replicas
ğŸ†• v16.28: FIX Ğ‘ĞĞ“ #3 - ĞŸĞ¾Ñ‚ĞµÑ€Ñ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ĞµĞ³Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ
ğŸ†• v16.22: FIX Ğ‘ĞĞ“ #1 - Ğ”ÑƒĞ±Ğ»Ğ¸Ñ€ÑƒÑÑ‰Ğ¸ĞµÑÑ timestamp
ğŸ†• v16.22: FIX Ğ‘ĞĞ“ #2 - Timestamp Ğ½Ğ°Ğ·Ğ°Ğ´
ğŸ†• v16.19: ĞšĞ Ğ˜Ğ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ™ FIX - Timestamp injection Ğ² Ğ±Ğ»Ğ¾ĞºĞ¸ >30 ÑĞµĞº
"""

import re
from core.utils import seconds_to_hms


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ†• v17.10: Helper â€” Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ²Ñ€ĞµĞ¼Ñ Ñ‡ĞµÑ€ĞµĞ· sub_segments
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _get_real_time_for_word(word_idx, total_words_post, seg_start, seg_end,
                             sub_segments, total_pre_words, debug=False):
    """
    ğŸ†• v17.10: Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµÑ‚ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ²Ñ€ĞµĞ¼Ñ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ word_idx.

    ĞœĞ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ñ Ğ¸Ğ· post-clean Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²Ğ° Ğ² pre-clean,
    Ğ·Ğ°Ñ‚ĞµĞ¼ Ğ¸Ñ‰ĞµÑ‚ Ğ½ÑƒĞ¶Ğ½Ñ‹Ğ¹ sub_segment Ğ¸ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ¿Ğ¾Ğ»Ğ¸Ñ€ÑƒĞµÑ‚ Ğ²Ğ½ÑƒÑ‚Ñ€Ğ¸ Ğ½ĞµĞ³Ğ¾.

    Args:
        word_idx:           ĞŸĞ¾Ğ·Ğ¸Ñ†Ğ¸Ñ Ğ¿ĞµÑ€Ğ²Ğ¾Ğ³Ğ¾ ÑĞ»Ğ¾Ğ²Ğ° Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ (post-clean)
        total_words_post:   Ğ’ÑĞµĞ³Ğ¾ ÑĞ»Ğ¾Ğ² Ğ² merged Ñ‚ĞµĞºÑÑ‚Ğµ (post-clean)
        seg_start:          seg['start'] â€” fallback Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ¾
        seg_end:            seg['end']   â€” fallback ĞºĞ¾Ğ½ĞµÑ†
        sub_segments:       [{'start', 'end', 'words'}, ...] Ğ¸Ğ· merge_replicas
        total_pre_words:    Ğ¡ÑƒĞ¼Ğ¼Ğ° words Ğ¸Ğ· sub_segments (pre-clean)
        debug:              ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°Ñ‚ÑŒ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ debug lookup

    Returns:
        float: Ğ’Ñ€ĞµĞ¼Ñ Ğ² ÑĞµĞºÑƒĞ½Ğ´Ğ°Ñ…
    """
    duration = seg_end - seg_start

    # Fallback: Ğ½ĞµÑ‚ sub_segments â†’ ÑÑ‚Ğ°Ñ€Ğ°Ñ Ğ»Ğ¸Ğ½ĞµĞ¹Ğ½Ğ°Ñ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ¿Ğ¾Ğ»ÑÑ†Ğ¸Ñ
    if not sub_segments or total_pre_words == 0 or total_words_post == 0:
        return seg_start + (word_idx / total_words_post) * duration

    # ĞœĞ°ÑÑˆÑ‚Ğ°Ğ±: post-clean â†’ pre-clean
    scale = total_pre_words / total_words_post
    scaled_idx = word_idx * scale

    cumulative = 0
    for sub in sub_segments:
        sub_words = max(sub.get('words', 1), 1)
        if scaled_idx <= cumulative + sub_words:
            fraction = (scaled_idx - cumulative) / sub_words
            real_time = sub['start'] + fraction * (sub['end'] - sub['start'])
            if debug:
                print(f"      ğŸ” word_idx={word_idx} â†’ scaled={scaled_idx:.1f} â†’ "
                      f"sub [{seconds_to_hms(sub['start'])}-{seconds_to_hms(sub['end'])}] "
                      f"words={sub_words} frac={fraction:.2f} â†’ {seconds_to_hms(real_time)}")
            return real_time
        cumulative += sub_words

    return sub_segments[-1]['end']


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ†• v17.14: gap_fixer_v2 â€” Ğ¿Ğ¾ÑÑ‚-Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ´ Ğ´Ğ»Ñ BAG_D
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def gap_fixer_v2(seg_text, seg_start, seg_end, sub_segments, total_pre,
                 interval=30.0, threshold=45.0, lookahead=12, debug=True):
    """
    ğŸ†• v17.14: FIX BAG_D â€” Ğ¿Ğ¾ÑÑ‚-Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ´ Ğ¿Ğ¾ Ñ‚ĞµĞºÑÑ‚Ñƒ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ°.

    ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°: Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ (>30s, Ğ½ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ¼ĞµĞ¶ÑƒÑ‚Ğ¾Ñ‡Ğ½Ñ‹Ñ… Ñ‚Ğ¾Ñ‡ĞµĞº) Ğ¿Ğ¾Ğ»Ğ½Ğ¾ÑÑ‚ÑŒÑ
    Ğ¿Ğ¾Ğ³Ğ»Ğ¾Ñ‰Ğ°ÑÑ‚ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ²Ğ°Ğ» â€” Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ´ inject Ğ½Ğµ Ğ²ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚.
    Ğ ĞµÑˆĞµĞ½Ğ¸Ğµ: Ğ¿Ğ¾ÑĞ»Ğµ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ´Ğ° â€” Ğ´Ğ¾Ğ¿. Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ´ Ğ¿Ğ¾ Ñ‚Ğ¾ĞºĞµĞ½Ğ°Ğ¼ Ñ‚ĞµĞºÑÑ‚Ğ°,
    Ğ¿Ğ¾Ğ¸ÑĞº gaps > threshold, word-level walk Ñ lookahead Ğ´Ğ¾ Ñ‚Ğ¾Ñ‡ĞºĞ¸.

    Ğ˜Ğ´ĞµĞ¼Ğ¿Ğ¾Ñ‚ĞµĞ½Ñ‚ĞµĞ½: Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€Ğ½Ñ‹Ğ¹ Ğ²Ñ‹Ğ·Ğ¾Ğ² Ğ¿Ñ€Ğ¸ gaps â‰¤ threshold â†’ 0 inject.

    Args:
        seg_text:     Ñ‚ĞµĞºÑÑ‚ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ° Ğ¿Ğ¾ÑĞ»Ğµ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ´Ğ° (ÑƒĞ¶Ğµ Ñ ts)
        seg_start:    float â€” Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ¾ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ° (ÑĞµĞº)
        seg_end:      float â€” ĞºĞ¾Ğ½ĞµÑ† ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ° (ÑĞµĞº)
        sub_segments: list[{start,end,words}] Ğ¸Ğ· merge_replicas
        total_pre:    int â€” ÑÑƒĞ¼Ğ¼Ğ° words Ğ¸Ğ· sub_segments
        interval:     Ğ¿Ğ¾Ñ€Ğ¾Ğ³ Ğ²ÑÑ‚Ğ°Ğ²ĞºĞ¸ Ğ²Ğ½ÑƒÑ‚Ñ€Ğ¸ gap (ÑĞµĞº), default 30.0
        threshold:    Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ gap Ğ´Ğ»Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ (ÑĞµĞº), default 45.0
        lookahead:    Ğ¼Ğ°ĞºÑ. ÑĞ»Ğ¾Ğ² Ğ²Ğ¿ĞµÑ€Ñ‘Ğ´ Ğ² Ğ¿Ğ¾Ğ¸ÑĞºĞµ ĞºĞ¾Ğ½Ñ†Ğ° Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ, default 12
        debug:        Ğ²Ñ‹Ğ²Ğ¾Ğ´ Ğ¾Ñ‚Ğ»Ğ°Ğ´ĞºĞ¸

    Returns:
        new_text: str â€” Ñ‚ĞµĞºÑÑ‚ Ñ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ ts
        log:      list[dict] â€” Ğ´ĞµÑ‚Ğ°Ğ»Ğ¸ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ inject
    """
    duration = seg_end - seg_start

    # â”€â”€ Ğ¢Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ: ÑĞ»Ğ¾Ğ²Ğ° + ts-Ğ¼ĞµÑ‚ĞºĞ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    token_pattern = re.compile(r'(\b\d{2}:\d{2}:\d{2}\b|\S+)')
    raw_tokens = token_pattern.findall(seg_text)

    tokens      = []
    word_to_tok = []   # word_idx â†’ token_idx
    tok_is_ts   = []

    for tok in raw_tokens:
        is_ts = bool(re.match(r'^\d{2}:\d{2}:\d{2}$', tok))
        tokens.append(tok)
        tok_is_ts.append(is_ts)
        if not is_ts:
            word_to_tok.append(len(tokens) - 1)

    words_total = len(word_to_tok)

    if debug:
        print(f"     ğŸ”§ gap_fixer_v2 [{seconds_to_hms(seg_start)}â€“{seconds_to_hms(seg_end)}] "
              f"dur={duration:.0f}s words={words_total} threshold={threshold}s")

    # â”€â”€ ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ğ¼ existing ts â†’ anchors â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    all_ts_sec = sorted(set(
        int(tok.split(':')[0]) * 3600 + int(tok.split(':')[1]) * 60 + int(tok.split(':')[2])
        for tok, is_t in zip(tokens, tok_is_ts) if is_t
    ))
    anchors = sorted(set(all_ts_sec + [int(seg_start)]))

    gaps_to_fix = []
    for i in range(1, len(anchors)):
        gap_sec = anchors[i] - anchors[i - 1]
        if gap_sec > threshold:
            gaps_to_fix.append((anchors[i - 1], anchors[i], gap_sec))
            if debug:
                print(f"       GAP: {seconds_to_hms(anchors[i-1])} â†’ "
                      f"{seconds_to_hms(anchors[i])} = {gap_sec}s âŒ")

    if not gaps_to_fix:
        if debug:
            print(f"       gaps > {threshold}s Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ âœ…")
        return seg_text, []

    # â”€â”€ ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼ ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¹ gap â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    inserts = []  # (token_idx, ts_str) â€” Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑĞµĞ¼ Ğ¿Ğ¾ÑĞ»Ğµ Ğ²ÑĞµÑ… gaps
    log     = []

    for gap_start_sec, gap_end_sec, gap_dur in gaps_to_fix:
        w_start = round((gap_start_sec - seg_start) / duration * words_total)
        w_end   = round((gap_end_sec   - seg_start) / duration * words_total)
        w_start = max(0, min(w_start, words_total - 1))
        w_end   = max(0, min(w_end,   words_total))
        gap_len = w_end - w_start

        if gap_len <= 0:
            continue

        last_t = float(gap_start_sec)
        i      = 0

        while i < gap_len:
            est_t = gap_start_sec + (i / gap_len) * gap_dur

            if est_t - last_t >= interval:
                inject_at      = i
                found_sent_end = False
                for look in range(min(lookahead, gap_len - i)):
                    w_abs = w_start + i + look
                    if w_abs < words_total:
                        tok = tokens[word_to_tok[w_abs]]
                        if re.search(r'[.!?]$', tok):
                            inject_at      = i + look + 1
                            found_sent_end = True
                            break

                inject_at    = min(inject_at, gap_len - 1)
                abs_word_idx = min(w_start + inject_at, words_total - 1)
                tok_idx      = word_to_tok[abs_word_idx]

                est_inj_t = gap_start_sec + (inject_at / gap_len) * gap_dur
                real_t    = _get_real_time_for_word(
                    abs_word_idx, words_total,
                    seg_start, seg_end,
                    sub_segments, total_pre, debug=False
                )
                delta    = real_t - est_inj_t
                gap_from = real_t - last_t

                ctx_lo  = max(0, abs_word_idx - 2)
                ctx_hi  = min(words_total, abs_word_idx + 3)
                ctx     = ' '.join(tokens[word_to_tok[j]] for j in range(ctx_lo, ctx_hi))

                warn = "âœ…" if gap_from <= 35 else ("âš ï¸" if gap_from <= 45 else "âŒ")
                method = "REAL" if sub_segments else "ESTIMATED"
                if debug:
                    print(f"       inject={seconds_to_hms(real_t)} Î”={delta:+.1f}s "
                          f"gap_from={gap_from:.0f}s {warn} [{method}] "
                          f"sent_end={found_sent_end}")
                    print(f"       Â«...{ctx}...Â»")

                inserts.append((tok_idx, seconds_to_hms(real_t)))
                log.append({
                    "real_t":   real_t,
                    "delta":    round(delta, 1),
                    "gap_from": round(gap_from, 1),
                    "ctx":      ctx,
                    "method":   method,
                })
                last_t = real_t
                i = inject_at + 1
                continue
            i += 1

    if not inserts:
        return seg_text, log

    # â”€â”€ Ğ’ÑÑ‚Ğ°Ğ²Ğ»ÑĞµĞ¼ ts Ğ² Ñ‚Ğ¾ĞºĞµĞ½Ñ‹ (ÑĞ¿Ñ€Ğ°Ğ²Ğ° Ğ½Ğ°Ğ»ĞµĞ²Ğ¾ â†’ Ğ½Ğµ ÑĞ´Ğ²Ğ¸Ğ³Ğ°ĞµĞ¼ Ğ¸Ğ½Ğ´ĞµĞºÑÑ‹) â”€â”€â”€â”€â”€â”€
    result = list(tokens)
    for tok_idx, ts_str in sorted(inserts, key=lambda x: -x[0]):
        result.insert(tok_idx + 1, ts_str)

    return ' '.join(result), log


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def find_existing_timestamps(text):
    """
    ğŸ†• v17.13: ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ²ÑĞµ ÑƒĞ¶Ğµ Ğ²ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ğµ timestamp Ğ² Ñ‚ĞµĞºÑÑ‚Ğµ.
    Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ ÑĞ¿Ğ¸ÑĞ¾Ğº {'ts': '00:32:59', 'sec': 1979, 'pos': 42}
    """
    pattern = r'\b(\d{2}:\d{2}:\d{2})\b'
    found = []
    for m in re.finditer(pattern, text):
        h, mn, s = m.group(1).split(':')
        found.append({
            'ts':  m.group(1),
            'sec': int(h) * 3600 + int(mn) * 60 + int(s),
            'pos': m.start()
        })
    return found

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def insert_intermediate_timestamps(segments, interval=30.0, debug=True):
    """
    ğŸ†• v17.14: FIX BAG_D â€” gap_fixer_v2 Ğ¿Ğ¾ÑÑ‚-Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ´ Ğ¿Ğ¾ÑĞ»Ğµ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ³Ğ¾ inject.
    ğŸ†• v17.13: FIX Ğ‘ĞĞ“ â€” Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€Ğ½Ñ‹Ğ¹ Ğ²Ñ‹Ğ·Ğ¾Ğ² Ğ¿Ğ¾ÑĞ»Ğµ auto_merge.
               SKIP Ğ±Ğ»Ğ¾ĞºĞ¾Ğ² Ñƒ ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ñ… Ñ…Ğ²Ğ¾ÑÑ‚ (end - last_existing_ts) â‰¤ interval*1.5.
               Ğ¢Ñ€Ğ¾Ğ³Ğ°ĞµĞ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ±Ğ»Ğ¾ĞºĞ¸ Ñ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾ Ğ½ĞµĞ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ½Ñ‹Ğ¼ Ñ…Ğ²Ğ¾ÑÑ‚Ğ¾Ğ¼ > 45s.
               existing ts Ğ² Ñ‚ĞµĞºÑÑ‚Ğµ Ğ½Ğµ Ğ¿ĞµÑ€ĞµÑÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ¸ Ğ½Ğµ Ğ²Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼.
    ğŸ†• v17.12: FIX Ğ‘ĞĞ“ â€” fallback inject Ğ¿ĞµÑ€ĞµĞ´ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğ¼ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸ĞµĞ¼
    ğŸ†• v17.11: FIX BAG_F â€” guard Ğ¿Ñ€Ğ¾Ñ‚Ğ¸Ğ² scale-Ğ°Ğ½Ğ¾Ğ¼Ğ°Ğ»Ğ¸Ğ¸ Ğ¿Ğ¾ÑĞ»Ğµ split
    ğŸ†• v17.10: Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ A â€” Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ğµ timestamp Ñ‡ĞµÑ€ĞµĞ· sub_segments Ğ¸Ğ· merge_replicas
    ğŸ†• v16.28: FIX Ğ‘ĞĞ“ #3 - ĞŸĞ¾Ñ‚ĞµÑ€Ñ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ĞµĞ³Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ
    ğŸ†• v16.22: FIX Ğ‘ĞĞ“ #1 - Ğ”ÑƒĞ±Ğ»Ğ¸Ñ€ÑƒÑÑ‰Ğ¸ĞµÑÑ timestamp
    ğŸ†• v16.22: FIX Ğ‘ĞĞ“ #2 - Timestamp Ğ½Ğ°Ğ·Ğ°Ğ´
    ğŸ†• v16.19: ĞšĞ Ğ˜Ğ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ™ FĞ˜X - Timestamp injection Ğ² Ğ±Ğ»Ğ¾ĞºĞ¸ >30 ÑĞµĞº
    """
    if debug:
        print(f"\nğŸ•’ Ğ’ÑÑ‚Ğ°Ğ²ĞºĞ° Ğ¿Ñ€Ğ¾Ğ¼ĞµĞ¶ÑƒÑ‚Ğ¾Ñ‡Ğ½Ñ‹Ñ… timestamp (interval={interval}s, mode=v17.14)...")

    injection_count    = 0
    skipped_duplicates = 0
    total_delta        = 0.0
    delta_count        = 0

    for seg_idx, seg in enumerate(segments):
        start    = seg.get('start', 0)
        end      = seg.get('end',   0)
        duration = end - start

        if duration <= interval:
            if debug and duration > 25:
                print(f"  â„¹ï¸  SHORT SKIP: [{seg.get('time','???')}] Ğ´Ğ»Ğ¸Ñ‚={duration:.0f}s â‰¤ {interval}s")
            continue

        text = seg.get('text', '')

        # ğŸ†• v17.13: ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ğ¼ existing timestamp Ğ¾Ñ‚ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰ĞµĞ³Ğ¾ Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ´Ğ°
        existing_ts   = find_existing_timestamps(text)
        existing_secs = [e['sec'] for e in existing_ts]

        # ğŸ†• v17.13: SKIP ĞµÑĞ»Ğ¸ Ñ…Ğ²Ğ¾ÑÑ‚ ÑƒĞ¶Ğµ Ğ¿Ğ¾ĞºÑ€Ñ‹Ñ‚ â€” Ğ½Ğµ Ñ‚Ñ€Ğ¾Ğ³Ğ°ĞµĞ¼ Ğ±Ğ»Ğ¾Ğº Ğ²Ğ¾Ğ¾Ğ±Ñ‰Ğµ
        if existing_secs:
            tail = end - max(existing_secs)
            if tail <= interval * 1.5:
                if debug:
                    print(f"  âœ… SKIP (covered): [{seg.get('time','???')}] "
                          f"Ñ…Ğ²Ğ¾ÑÑ‚={tail:.0f}s â‰¤ {interval * 1.5:.0f}s")
                continue

        # Ğ”Ğ»Ñ Ğ¿Ğ¾Ğ´ÑÑ‡Ñ‘Ñ‚Ğ° ÑĞ»Ğ¾Ğ² Ğ¸ split â€” ÑƒĞ±Ğ¸Ñ€Ğ°ĞµĞ¼ existing ts Ğ¸Ğ· Ñ‚ĞµĞºÑÑ‚Ğ°
        clean_text = re.sub(r'\s*\b\d{2}:\d{2}:\d{2}\b\s*', ' ', text).strip()

        sub_segments    = seg.get('sub_segments', [])
        total_pre_words = sum(s.get('words', 0) for s in sub_segments)
        has_real_data   = bool(sub_segments) and total_pre_words > 0

        sentences = re.split(r'([.!?]+)\s+', clean_text)
        sentences = [''.join(sentences[i:i+2]).strip()
                     for i in range(0, len(sentences), 2)]
        sentences = [s for s in sentences if s]

        if len(sentences) < 2:
            if debug:
                snippet = clean_text[:120].replace('\n', ' ')
                print(f"  âš ï¸  BAG_D SKIP: Ğ±Ğ»Ğ¾Ğº [{seg.get('time','???')}â€“{seconds_to_hms(end)}] "
                      f"Ğ´Ğ»Ğ¸Ñ‚={duration:.0f}s â€” sentences<2, Ñ‚Ğ°Ğ¹Ğ¼ĞºĞ¾Ğ´ ĞĞ• Ğ²ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½")
                print(f"      Ğ¢ĞµĞºÑÑ‚ (Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ¾): '{snippet}...'")
                punct_count = len(re.findall(r'[.!?]', clean_text))
                print(f"      Ğ—Ğ½Ğ°ĞºĞ¾Ğ² Ğ¿ÑƒĞ½ĞºÑ‚ÑƒĞ°Ñ†Ğ¸Ğ¸ [.!?]: {punct_count} | "
                      f"Ğ¡Ğ»Ğ¾Ğ²: {len(clean_text.split())} | "
                      f"Ğ¡Ğ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²: {len(clean_text)}")
            # ğŸ†• v17.14: sentences<2 â€” Ğ²ÑÑ‘ Ñ€Ğ°Ğ²Ğ½Ğ¾ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ gap_fixer_v2
            seg['text'], _gap_log = gap_fixer_v2(
                text, start, end,
                sub_segments, total_pre_words,
                interval=interval, threshold=45.0,
                lookahead=12, debug=debug
            )
            if _gap_log:
                injection_count += len(_gap_log)
                if debug:
                    print(f"     ğŸ”§ gap_fixer_v2 (sentences<2): +{len(_gap_log)} inject(s)")
            continue

        words_total = len(clean_text.split())

        _SCALE_ANOMALY_THRESHOLD = 1.8
        if has_real_data and words_total > 0:
            _scale = total_pre_words / words_total
            if _scale > _SCALE_ANOMALY_THRESHOLD:
                if debug:
                    print(f"  âš ï¸  BAG_F GUARD [{seg.get('time', '???')}] "
                          f"{seg.get('speaker', '?')}: "
                          f"scale={_scale:.3f} > {_SCALE_ANOMALY_THRESHOLD} "
                          f"(pre={total_pre_words} / post={words_total}) "
                          f"â€” sub_segments Ğ¾Ñ‚ Ñ€Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»Ñ Ğ¿Ğ¾ÑĞ»Ğµ split, fallback ESTIMATED")
                sub_segments    = []
                total_pre_words = 0
                has_real_data   = False

        if debug:
            mode = "ğŸ¯ REAL (sub_segments)" if has_real_data else "ğŸ“ ESTIMATED (word proportion)"
            print(f"\n  â”€â”€ Ğ¡ĞµĞ³Ğ¼ĞµĞ½Ñ‚ [{seg.get('time','???')}] {seg.get('speaker')} â”€â”€")
            print(f"     Ğ´Ğ»Ğ¸Ñ‚={duration:.1f}s | ÑĞ»Ğ¾Ğ²(post)={words_total} | Ñ€ĞµĞ¶Ğ¸Ğ¼={mode}")
            if has_real_data:
                print(f"     sub_segments: {len(sub_segments)} ÑˆÑ‚ | "
                      f"words(pre-clean)={total_pre_words} | "
                      f"scale={total_pre_words/words_total:.3f}")
                for si, sub in enumerate(sub_segments):
                    print(f"       sub[{si}]: [{seconds_to_hms(sub['start'])}-"
                          f"{seconds_to_hms(sub['end'])}] words={sub['words']}")
            if existing_secs:
                print(f"     existing ts: {[e['ts'] for e in existing_ts]} "
                      f"(Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ´, Ñ…Ğ²Ğ¾ÑÑ‚ > {interval * 1.5:.0f}s)")

        new_text_parts   = []
        current_word_idx = 0

        # ğŸ†• v17.13: ÑÑ‚Ğ°Ñ€Ñ‚ÑƒĞµĞ¼ Ğ¾Ñ‚ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ĞµĞ³Ğ¾ existing ts
        last_inject_time  = max(existing_secs) if existing_secs else start
        all_inject_times  = list(existing_secs)
        injected_this_seg = len(existing_secs) > 0

        def _already_covered(t, window=8.0):
            return any(abs(ts - t) <= window for ts in all_inject_times)

        for sent_idx, sent in enumerate(sentences):
            sent_words = len(sent.split())
            is_last    = (sent_idx == len(sentences) - 1)

            current_time   = (start + (current_word_idx / words_total) * duration
                               if words_total > 0 else start)
            gap_since_last = current_time - last_inject_time

            should_inject_main = (
                gap_since_last >= interval
                and not is_last
            )
            # Fallback: Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ĞµĞµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ, Ñ…Ğ²Ğ¾ÑÑ‚ > interval/2
            should_inject_fallback = (
                is_last
                and gap_since_last >= interval / 2
                and (end - current_time) > 15.0  # guard: Ğ½Ğµ ÑÑ‚Ğ°Ğ²Ğ¸Ñ‚ÑŒ TS Ğ² Ñ…Ğ²Ğ¾ÑÑ‚ <15s
            )

            if should_inject_main or should_inject_fallback:
                if _already_covered(current_time):
                    if debug:
                        nearest = min(all_inject_times, key=lambda t: abs(t - current_time))
                        print(f"     â­ï¸ Ğ´ÑƒĞ±Ğ»ÑŒ: {seconds_to_hms(current_time)} "
                              f"(Î”={abs(nearest - current_time):.1f}s Ğ¾Ñ‚ {seconds_to_hms(nearest)})")
                    skipped_duplicates += 1
                else:
                    real_time = _get_real_time_for_word(
                        current_word_idx, words_total, start, end,
                        sub_segments, total_pre_words, debug=False
                    )
                    timestamp_str = f" {seconds_to_hms(real_time)} "
                    new_text_parts.append(timestamp_str)

                    all_inject_times.append(real_time)
                    last_inject_time  = real_time
                    injected_this_seg = True
                    injection_count  += 1

                    if debug:
                        delta  = real_time - current_time
                        method = "REAL âœ…    " if has_real_data else "ESTIMATED âš ï¸"
                        tag    = " [FALLBACK]" if should_inject_fallback else ""
                        print(f"     ğŸ“Œ [{method}]{tag} inject={seconds_to_hms(real_time).strip()} "
                              f"| Î”={delta:+.1f}s "
                              f"| word#{current_word_idx}/{words_total} "
                              f"| gap={gap_since_last:.1f}s")
                        print(f"        â†³ '{sent[:60]}...'")
                        if has_real_data:
                            total_delta += abs(delta)
                            delta_count += 1

            new_text_parts.append(sent)
            current_word_idx += sent_words

        # ğŸ†• v17.13: existing ts Ğ² Ñ…Ğ²Ğ¾ÑÑ‚Ğµ (Ğ¿Ğ¾ÑĞ»Ğµ Ğ²ÑĞµÑ… Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹) â€” ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼
        final_word_time = (start + (current_word_idx / words_total) * duration
                           if words_total > 0 else end)
        for ets in sorted(existing_ts, key=lambda x: x['sec']):
            if ets['sec'] > final_word_time:
                new_text_parts.append(f" {ets['ts']} ")

        seg['text'] = ' '.join(new_text_parts)

        # ğŸ†• v17.14: FIX BAG_D â€” gap_fixer_v2 Ğ¿Ğ¾ÑÑ‚-Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ´
        seg['text'], _gap_log = gap_fixer_v2(
            seg['text'], start, end,
            sub_segments, total_pre_words,
            interval=interval, threshold=45.0,
            lookahead=12, debug=debug
        )
        if _gap_log:
            injection_count += len(_gap_log)
            if debug:
                print(f"     ğŸ”§ gap_fixer_v2: +{len(_gap_log)} inject(s)")

    if debug:
        print(f"\n{'â”€'*60}")
        print(f"âœ… Ğ’ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ timestamp : {injection_count}")
        if skipped_duplicates:
            print(f"â­ï¸ ĞŸÑ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½Ğ¾ Ğ´ÑƒĞ±Ğ»ĞµĞ¹   : {skipped_duplicates}")
        if delta_count > 0:
            print(f"ğŸ“Š Ğ¡Ñ€ĞµĞ´Ğ½Ğ¸Ğ¹ |Î”| (REAL) : {total_delta/delta_count:.1f}s "
                  f"Ğ¿Ğ¾ {delta_count} Ğ¸Ğ½Ğ¶ĞµĞºÑ†Ğ¸ÑĞ¼")
        if injection_count == 0 and skipped_duplicates == 0:
            print(f"âœ… Ğ‘Ğ»Ğ¾ĞºĞ¾Ğ² >30s Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾")

    return segments

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def correct_timestamp_drift(segments, debug=True):
    """
    ğŸ†• v16.22: FIX Ğ‘ĞĞ“ #2 - Timestamp Ğ½Ğ°Ğ·Ğ°Ğ´
    ğŸ†• v16.19: Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ÑĞµÑ‚ ÑĞ´Ğ²Ğ¸Ğ³ timestamp Ğ¿Ğ¾ÑĞ»Ğµ gap filling
    """
    if debug:
        print(f"\nğŸ”§ Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ ÑĞ´Ğ²Ğ¸Ğ³Ğ° timestamp Ğ¿Ğ¾ÑĞ»Ğµ gap filling...")

    corrections      = 0
    skipped_backward = 0

    for i in range(1, len(segments)):
        prev_seg    = segments[i - 1]
        current_seg = segments[i]

        prev_end      = prev_seg.get('end',   0)
        current_start = current_seg.get('start', 0)

        gap = current_start - prev_end

        if -10.0 <= gap <= 0.5:
            old_start = current_start
            new_start = prev_end

            if new_start >= old_start:
                current_seg['start'] = new_start
                current_seg['time']  = seconds_to_hms(new_start)

                if debug and abs(old_start - new_start) > 1.0:
                    print(f"  â±ï¸ {seconds_to_hms(old_start)} â†’ "
                          f"{seconds_to_hms(new_start)} "
                          f"(ÑĞ´Ğ²Ğ¸Ğ³ {new_start - old_start:+.1f}s)")

                corrections += 1
            else:
                if debug:
                    print(f"  â­ï¸ ĞŸĞ ĞĞŸĞ£Ğ¡ĞšĞĞ•Ğœ: {seconds_to_hms(old_start)} â†’ "
                          f"{seconds_to_hms(new_start)} "
                          f"(ÑĞ´Ğ²Ğ¸Ğ³ Ğ½Ğ°Ğ·Ğ°Ğ´ {new_start - old_start:.1f}s)")
                skipped_backward += 1

    if debug:
        if corrections:
            print(f"âœ… Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ timestamp: {corrections}")
        if skipped_backward:
            print(f"â­ï¸ ĞŸÑ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½Ğ¾ (Ğ½Ğ°Ğ·Ğ°Ğ´): {skipped_backward}")
        if corrections == 0 and skipped_backward == 0:
            print(f"âœ… Ğ¡Ğ´Ğ²Ğ¸Ğ³Ğ¾Ğ² Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾")

    return segments
