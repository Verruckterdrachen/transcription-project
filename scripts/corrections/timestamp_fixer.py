#!/usr/bin/env python3
"""
corrections/timestamp_fixer.py - Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ timestamp

ğŸ†• v17.17: FIX BAG_D_v2 â€” insert_intermediate_timestamps Ğ·Ğ°Ğ¼ĞµĞ½ĞµĞ½Ğ° Ğ½Ğ°
           run_insert Ğ¸Ğ· ÑĞ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ğ¸ sim_bugH_fallback_inject_23_07.py (ALL GREEN).
           Ğ›Ğ¾Ğ³Ğ¸ĞºĞ°: ts Ğ²ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ÑÑ ĞŸĞ•Ğ Ğ•Ğ” Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸ĞµĞ¼ Ğ¿Ğ¾ w_idx Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ
           (Ğ½Ğµ ĞºĞ¾Ğ½Ñ†Ğ°), Ğ±ĞµĞ· Ğ±Ğ»Ğ¾ĞºĞ° Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚Ğ° existing_ts, gap_fixer_v2 Ğ¸Ğ´Ñ‘Ñ‚ Ğ¿Ğ¾ÑĞ»Ğµ.
ğŸ†• v17.16: FIX BAG_G â€” gap_fixer_v2: break Ğ¿Ğ¾ÑĞ»Ğµ SKIP ĞºĞ¾Ğ³Ğ´Ğ°
           real_t >= gap_end_sec - MIN_NEIGHBOR_GAP (Ğ±ĞµÑĞºĞ¾Ğ½ĞµÑ‡Ğ½Ñ‹Ğ¹ Ñ†Ğ¸ĞºĞ»).
ğŸ†• v17.15: FIX Ğ‘ĞĞ“ A+B â€” gap_fixer_v2: next-neighbor guard.
           ĞŸÑ€Ğ¾Ğ¿ÑƒÑĞº inject ĞµÑĞ»Ğ¸ Ñ€Ğ°ÑÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ´Ğ¾ ÑĞ»ĞµĞ´ÑƒÑÑ‰ĞµĞ³Ğ¾ ÑĞºĞ¾Ñ€Ñ < 25s.
ğŸ†• v17.14: FIX BAG_D â€” gap_fixer_v2: Ğ¿Ğ¾ÑÑ‚-Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ´ Ğ¿Ğ¾ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ¾Ğ¼Ñƒ Ñ‚ĞµĞºÑÑ‚Ñƒ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ°.
ğŸ†• v17.11: FIX BAG_F â€” guard Ğ¿Ñ€Ğ¾Ñ‚Ğ¸Ğ² scale-Ğ°Ğ½Ğ¾Ğ¼Ğ°Ğ»Ğ¸Ğ¸ Ğ¿Ğ¾ÑĞ»Ğµ split
ğŸ†• v17.10: Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ A â€” Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ğµ timestamp Ñ‡ĞµÑ€ĞµĞ· sub_segments Ğ¸Ğ· merge_replicas
ğŸ†• v16.28: FIX Ğ‘ĞĞ“ #3 - ĞŸĞ¾Ñ‚ĞµÑ€Ñ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ĞµĞ³Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ
ğŸ†• v16.22: FIX Ğ‘ĞĞ“ #1 - Ğ”ÑƒĞ±Ğ»Ğ¸Ñ€ÑƒÑÑ‰Ğ¸ĞµÑÑ timestamp
ğŸ†• v16.22: FIX Ğ‘ĞĞ“ #2 - Timestamp Ğ½Ğ°Ğ·Ğ°Ğ´
ğŸ†• v16.19: ĞšĞ Ğ˜Ğ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ™ FIX - Timestamp injection Ğ² Ğ±Ğ»Ğ¾ĞºĞ¸ >30 ÑĞµĞº
"""

import re
from core.utils import seconds_to_hms


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ†• v17.10: Helper â€” Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ²Ñ€ĞµĞ¼Ñ Ñ‡ĞµÑ€ĞµĞ· sub_segments
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _get_real_time_for_word(word_idx, total_words_post, seg_start, seg_end,
                             sub_segments, total_pre_words, debug=False):
    """
    Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµÑ‚ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ²Ñ€ĞµĞ¼Ñ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ word_idx.
    ĞœĞ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ñ Ğ¸Ğ· post-clean Ğ² pre-clean,
    Ğ·Ğ°Ñ‚ĞµĞ¼ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ¿Ğ¾Ğ»Ğ¸Ñ€ÑƒĞµÑ‚ Ğ²Ğ½ÑƒÑ‚Ñ€Ğ¸ sub_segment.
    """
    duration = seg_end - seg_start

    if not sub_segments or total_pre_words == 0 or total_words_post == 0:
        return seg_start + (word_idx / total_words_post) * duration

    scale      = total_pre_words / total_words_post
    scaled_idx = word_idx * scale
    cumulative = 0

    for sub in sub_segments:
        sub_words = max(sub.get('words', 1), 1)
        if scaled_idx <= cumulative + sub_words:
            fraction  = (scaled_idx - cumulative) / sub_words
            real_time = sub['start'] + fraction * (sub['end'] - sub['start'])
            if debug:
                print(f"      ğŸ” word_idx={word_idx} â†’ scaled={scaled_idx:.1f} â†’ "
                      f"sub [{seconds_to_hms(sub['start'])}-{seconds_to_hms(sub['end'])}] "
                      f"words={sub_words} frac={fraction:.2f} â†’ {seconds_to_hms(real_time)}")
            return real_time
        cumulative += sub_words

    return sub_segments[-1]['end']


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ†• v17.16: gap_fixer_v2
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def gap_fixer_v2(seg_text, seg_start, seg_end, sub_segments, total_pre,
                 interval=30.0, threshold=45.0, lookahead=12, debug=True):
    """
    ĞŸĞ¾ÑÑ‚-Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ´: Ğ½Ğ°Ñ…Ğ¾Ğ´Ğ¸Ñ‚ gaps > threshold Ğ¸ Ğ²ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ ts Ğ¿Ğ¾ lookahead Ğº Ñ‚Ğ¾Ñ‡ĞºĞµ.
    Ğ˜Ğ´ĞµĞ¼Ğ¿Ğ¾Ñ‚ĞµĞ½Ñ‚ĞµĞ½: Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€Ğ½Ñ‹Ğ¹ Ğ²Ñ‹Ğ·Ğ¾Ğ² Ğ¿Ñ€Ğ¸ gaps â‰¤ threshold â†’ 0 inject.
    """
    MIN_NEIGHBOR_GAP = 25.0

    duration      = seg_end - seg_start
    token_pattern = re.compile(r'(\b\d{2}:\d{2}:\d{2}\b|\S+)')
    raw_tokens    = token_pattern.findall(seg_text)

    tokens      = []
    word_to_tok = []
    tok_is_ts   = []

    for tok in raw_tokens:
        is_ts = bool(re.match(r'^\d{2}:\d{2}:\d{2}$', tok))
        tokens.append(tok)
        tok_is_ts.append(is_ts)
        if not is_ts:
            word_to_tok.append(len(tokens) - 1)

    words_total = len(word_to_tok)

    if debug:
        print(f"     ğŸ”§ gap_fixer_v2 [{seconds_to_hms(seg_start)}â€“{seconds_to_hms(seg_end)}] "
              f"dur={duration:.0f}s words={words_total} threshold={threshold}s")

    all_ts_sec = sorted(set(
        int(tok.split(':')[0]) * 3600 + int(tok.split(':')[1]) * 60 + int(tok.split(':')[2])
        for tok, is_t in zip(tokens, tok_is_ts) if is_t
    ))
    anchors     = sorted(set(all_ts_sec + [int(seg_start)]))
    gaps_to_fix = []

    for i in range(1, len(anchors)):
        gap_sec = anchors[i] - anchors[i - 1]
        if gap_sec > threshold:
            gaps_to_fix.append((anchors[i - 1], anchors[i], gap_sec))
            if debug:
                print(f"       GAP: {seconds_to_hms(anchors[i-1])} â†’ "
                      f"{seconds_to_hms(anchors[i])} = {gap_sec}s âŒ")

    if not gaps_to_fix:
        if debug:
            print(f"       gaps > {threshold}s Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ âœ…")
        return seg_text, []

    inserts = []
    log     = []

    for gap_start_sec, gap_end_sec, gap_dur in gaps_to_fix:
        w_start = round((gap_start_sec - seg_start) / duration * words_total)
        w_end   = round((gap_end_sec   - seg_start) / duration * words_total)
        w_start = max(0, min(w_start, words_total - 1))
        w_end   = max(0, min(w_end,   words_total))
        gap_len = w_end - w_start

        if gap_len <= 0:
            continue

        last_t = float(gap_start_sec)
        i      = 0

        while i < gap_len:
            est_t = gap_start_sec + (i / gap_len) * gap_dur

            if est_t - last_t >= interval:
                inject_at      = i
                found_sent_end = False

                for look in range(min(lookahead, gap_len - i)):
                    w_abs = w_start + i + look
                    if w_abs < words_total:
                        tok = tokens[word_to_tok[w_abs]]
                        if re.search(r'[.!?]$', tok):
                            inject_at      = i + look + 1
                            found_sent_end = True
                            break

                inject_at    = min(inject_at, gap_len - 1)
                abs_word_idx = min(w_start + inject_at, words_total - 1)
                tok_idx      = word_to_tok[abs_word_idx]

                est_inj_t    = gap_start_sec + (inject_at / gap_len) * gap_dur
                real_t       = _get_real_time_for_word(
                    abs_word_idx, words_total,
                    seg_start, seg_end,
                    sub_segments, total_pre, debug=False
                )
                delta        = real_t - est_inj_t
                gap_from     = real_t - last_t
                dist_to_next = gap_end_sec - real_t

                if dist_to_next < MIN_NEIGHBOR_GAP:
                    if debug:
                        print(f"       SKIP next-neighbor: "
                              f"dist_to_next={dist_to_next:.0f}s "
                              f"< {MIN_NEIGHBOR_GAP:.0f}s "
                              f"({seconds_to_hms(real_t)} â†’ "
                              f"{seconds_to_hms(gap_end_sec)})")
                    if real_t >= gap_end_sec - MIN_NEIGHBOR_GAP:
                        break
                    i += 1
                    continue

                ctx_lo = max(0, abs_word_idx - 2)
                ctx_hi = min(words_total, abs_word_idx + 3)
                ctx    = ' '.join(tokens[word_to_tok[j]] for j in range(ctx_lo, ctx_hi))
                warn   = "âœ…" if gap_from <= 35 else ("âš ï¸" if gap_from <= 45 else "âŒ")
                method = "REAL" if sub_segments else "ESTIMATED"

                if debug:
                    print(f"       inject={seconds_to_hms(real_t)} Î”={delta:+.1f}s "
                          f"gap_from={gap_from:.0f}s {warn} [{method}] "
                          f"sent_end={found_sent_end}")
                    print(f"       Â«...{ctx}...Â»")

                inserts.append((tok_idx, seconds_to_hms(real_t)))
                log.append({
                    "real_t":   real_t,
                    "delta":    round(delta, 1),
                    "gap_from": round(gap_from, 1),
                    "ctx":      ctx,
                    "method":   method,
                })
                last_t = real_t
                i      = inject_at + 1
                continue
            i += 1

    if not inserts:
        return seg_text, log

    result = list(tokens)
    for tok_idx, ts_str in sorted(inserts, key=lambda x: -x[0]):
        result.insert(tok_idx + 1, ts_str)

    return ' '.join(result), log


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def find_existing_timestamps(text):
    """
    ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ²ÑĞµ ÑƒĞ¶Ğµ Ğ²ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ğµ timestamp Ğ² Ñ‚ĞµĞºÑÑ‚Ğµ.
    Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ ÑĞ¿Ğ¸ÑĞ¾Ğº {'ts': '00:32:59', 'sec': 1979, 'pos': 42}
    """
    pattern = r'\b(\d{2}:\d{2}:\d{2})\b'
    found   = []
    for m in re.finditer(pattern, text):
        h, mn, s = m.group(1).split(':')
        found.append({
            'ts':  m.group(1),
            'sec': int(h) * 3600 + int(mn) * 60 + int(s),
            'pos': m.start()
        })
    return found


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ†• v17.17: insert_intermediate_timestamps â€” Ğ»Ğ¾Ğ³Ğ¸ĞºĞ° run_insert Ğ¸Ğ· ÑĞ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ğ¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def insert_intermediate_timestamps(segments, interval=30.0, debug=True):
    """
    ğŸ†• v17.17: Ğ¢ĞµĞ»Ğ¾ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ·Ğ°Ğ¼ĞµĞ½ĞµĞ½Ğ¾ Ğ½Ğ° run_insert Ğ¸Ğ· ÑĞ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ğ¸ ALL GREEN.

    ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ ÑĞ²Ğ¾Ğ¹ÑÑ‚Ğ²Ğ° (Ğ¸Ğ· ÑĞ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ğ¸):
    - ts Ğ²ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ÑÑ ĞŸĞ•Ğ Ğ•Ğ” Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸ĞµĞ¼, w_idx = Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ
    - w_idx += sent_words ĞŸĞĞ¡Ğ›Ğ• append(sent) â€” Ğ½Ğµ Ğ¼ĞµĞ½ÑĞµÑ‚ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ñ Ğ¸Ğ½Ğ¶ĞµĞºÑ‚Ğ°
    - ĞĞ•Ğ¢ Ğ±Ğ»Ğ¾ĞºĞ° Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‚Ğ° existing_ts (ÑƒÑÑ‚Ñ€Ğ°Ğ½ĞµĞ½Ñ‹ Ğ´ÑƒĞ±Ğ»Ğ¸)
    - gap_fixer_v2 Ğ¸Ğ´Ñ‘Ñ‚ Ğ¿Ğ¾ÑÑ‚-Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ´Ğ¾Ğ¼, Ğ½Ğ¾ Ğ¿Ñ€Ğ¸ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¸Ğ½Ğ¶ĞµĞºÑ‚Ğ°Ñ… Ğ´Ğ°Ñ‘Ñ‚ 0
    - BAG_F guard (scale > 1.8) ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ñ‘Ğ½
    - sentences < 2 â†’ gap_fixer_v2 Ğ½Ğ°Ğ¿Ñ€ÑĞ¼ÑƒÑ (ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ñ‘Ğ½)
    """
    if debug:
        print(f"\nğŸ•’ Ğ’ÑÑ‚Ğ°Ğ²ĞºĞ° Ğ¿Ñ€Ğ¾Ğ¼ĞµĞ¶ÑƒÑ‚Ğ¾Ñ‡Ğ½Ñ‹Ñ… timestamp (interval={interval}s, mode=v17.17)...")

    injection_count    = 0
    skipped_duplicates = 0
    total_delta        = 0.0
    delta_count        = 0

    for seg_idx, seg in enumerate(segments):
        start    = seg.get('start', 0)
        end      = seg.get('end',   0)
        duration = end - start

        if duration <= interval:
            if debug and duration > 25:
                print(f"  â„¹ï¸  SHORT SKIP: [{seg.get('time','???')}] Ğ´Ğ»Ğ¸Ñ‚={duration:.0f}s â‰¤ {interval}s")
            continue

        text = seg.get('text', '')

        existing_ts   = find_existing_timestamps(text)
        existing_secs = [e['sec'] for e in existing_ts]

        if existing_secs:
            tail = end - max(existing_secs)
            if tail <= interval * 1.5:
                if debug:
                    print(f"  âœ… SKIP (covered): [{seg.get('time','???')}] "
                          f"Ñ…Ğ²Ğ¾ÑÑ‚={tail:.0f}s â‰¤ {interval * 1.5:.0f}s")
                continue

        clean_text = re.sub(r'\s*\b\d{2}:\d{2}:\d{2}\b\s*', ' ', text).strip()

        sub_segments    = seg.get('sub_segments', [])
        total_pre_words = sum(s.get('words', 0) for s in sub_segments)
        has_real_data   = bool(sub_segments) and total_pre_words > 0

        sentences = re.split(r'([.!?]+)\s+', clean_text)
        sentences = [''.join(sentences[i:i+2]).strip()
                     for i in range(0, len(sentences), 2)]
        sentences = [s for s in sentences if s]

        # sentences < 2 â†’ gap_fixer_v2 Ğ½Ğ°Ğ¿Ñ€ÑĞ¼ÑƒÑ (BAG_D fallback)
        if len(sentences) < 2:
            if debug:
                snippet    = clean_text[:120].replace('\n', ' ')
                punct_count = len(re.findall(r'[.!?]', clean_text))
                print(f"  âš ï¸  BAG_D SKIP: Ğ±Ğ»Ğ¾Ğº [{seg.get('time','???')}â€“{seconds_to_hms(end)}] "
                      f"Ğ´Ğ»Ğ¸Ñ‚={duration:.0f}s â€” sentences<2, Ñ‚Ğ°Ğ¹Ğ¼ĞºĞ¾Ğ´ ĞĞ• Ğ²ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½")
                print(f"      Ğ¢ĞµĞºÑÑ‚ (Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ¾): '{snippet}...'")
                print(f"      Ğ—Ğ½Ğ°ĞºĞ¾Ğ² Ğ¿ÑƒĞ½ĞºÑ‚ÑƒĞ°Ñ†Ğ¸Ğ¸ [.!?]: {punct_count} | "
                      f"Ğ¡Ğ»Ğ¾Ğ²: {len(clean_text.split())} | "
                      f"Ğ¡Ğ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²: {len(clean_text)}")
            seg['text'], _gap_log = gap_fixer_v2(
                text, start, end,
                sub_segments, total_pre_words,
                interval=interval, threshold=45.0,
                lookahead=12, debug=debug
            )
            if _gap_log:
                injection_count += len(_gap_log)
                if debug:
                    print(f"     ğŸ”§ gap_fixer_v2 (sentences<2): +{len(_gap_log)} inject(s)")
            continue

        words_total = len(clean_text.split())

        # BAG_F guard: scale-Ğ°Ğ½Ğ¾Ğ¼Ğ°Ğ»Ğ¸Ñ Ğ¿Ğ¾ÑĞ»Ğµ split
        _SCALE_ANOMALY_THRESHOLD = 1.8
        if has_real_data and words_total > 0:
            _scale = total_pre_words / words_total
            if _scale > _SCALE_ANOMALY_THRESHOLD:
                if debug:
                    print(f"  âš ï¸  BAG_F GUARD [{seg.get('time', '???')}] "
                          f"{seg.get('speaker', '?')}: "
                          f"scale={_scale:.3f} > {_SCALE_ANOMALY_THRESHOLD} "
                          f"(pre={total_pre_words} / post={words_total}) "
                          f"â€” sub_segments Ğ¾Ñ‚ Ñ€Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»Ñ Ğ¿Ğ¾ÑĞ»Ğµ split, fallback ESTIMATED")
                sub_segments    = []
                total_pre_words = 0
                has_real_data   = False

        if debug:
            mode = "ğŸ¯ REAL (sub_segments)" if has_real_data else "ğŸ“ ESTIMATED (word proportion)"
            print(f"\n  â”€â”€ Ğ¡ĞµĞ³Ğ¼ĞµĞ½Ñ‚ [{seg.get('time','???')}] {seg.get('speaker')} â”€â”€")
            print(f"     Ğ´Ğ»Ğ¸Ñ‚={duration:.1f}s | ÑĞ»Ğ¾Ğ²(post)={words_total} | Ñ€ĞµĞ¶Ğ¸Ğ¼={mode}")
            if has_real_data:
                print(f"     sub_segments: {len(sub_segments)} ÑˆÑ‚ | "
                      f"words(pre-clean)={total_pre_words} | "
                      f"scale={total_pre_words/words_total:.3f}")
                for si, sub in enumerate(sub_segments):
                    print(f"       sub[{si}]: [{seconds_to_hms(sub['start'])}-"
                          f"{seconds_to_hms(sub['end'])}] words={sub['words']}")
            if existing_secs:
                print(f"     existing ts: {[e['ts'] for e in existing_ts]} "
                      f"(Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ´, Ñ…Ğ²Ğ¾ÑÑ‚ > {interval * 1.5:.0f}s)")

        # â”€â”€ ĞĞ¡ĞĞĞ’ĞĞĞ™ Ğ¦Ğ˜ĞšĞ› (Ñ‚Ğ¾Ñ‡Ğ½Ğ°Ñ ĞºĞ¾Ğ¿Ğ¸Ñ run_insert Ğ¸Ğ· ÑĞ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ğ¸) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        new_parts = []
        w_idx     = 0
        last_t    = max(existing_secs) if existing_secs else start
        all_ts    = list(existing_secs)

        def covered(t):
            return any(abs(x - t) <= 8.0 for x in all_ts)

        for si, sent in enumerate(sentences):
            is_last = si == len(sentences) - 1
            cur_t   = start + (w_idx / words_total) * duration if words_total else start
            gap     = cur_t - last_t

            main_ok     = gap >= interval and not is_last
            fallback_ok = is_last and gap >= interval / 2 and (end - cur_t) > 15.0

            if (main_ok or fallback_ok) and not covered(cur_t):
                real_t = _get_real_time_for_word(
                    w_idx, words_total, start, end,
                    sub_segments, total_pre_words, debug=False
                )
                new_parts.append(f" {seconds_to_hms(real_t)}")
                all_ts.append(real_t)
                last_t = real_t
                injection_count += 1

                if debug:
                    delta  = real_t - cur_t
                    method = "REAL âœ…    " if has_real_data else "ESTIMATED âš ï¸"
                    tag    = " [FALLBACK]" if fallback_ok else ""
                    print(f"     ğŸ“Œ [{method}]{tag} inject={seconds_to_hms(real_t).strip()} "
                          f"| Î”={delta:+.1f}s "
                          f"| word#{w_idx}/{words_total} "
                          f"| gap={gap:.1f}s")
                    print(f"        â†³ '{sent[:60]}...'")
                    if has_real_data:
                        total_delta += abs(delta)
                        delta_count += 1

            elif (main_ok or fallback_ok) and covered(cur_t):
                skipped_duplicates += 1
                if debug:
                    nearest = min(all_ts, key=lambda t: abs(t - cur_t))
                    print(f"     â­ï¸ Ğ´ÑƒĞ±Ğ»ÑŒ: {seconds_to_hms(cur_t)} "
                          f"(Î”={abs(nearest - cur_t):.1f}s Ğ¾Ñ‚ {seconds_to_hms(nearest)})")

            new_parts.append(sent)
            w_idx += len(sent.split())
        # â”€â”€ ĞšĞĞĞ•Ğ¦ ĞĞ¡ĞĞĞ’ĞĞĞ“Ğ Ğ¦Ğ˜ĞšĞ›Ğ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

        seg['text'] = re.sub(r' {2,}', ' ', ' '.join(new_parts)).strip()

        # gap_fixer_v2 Ğ¿Ğ¾ÑÑ‚-Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ´ (Ğ¿Ñ€Ğ¸ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¸Ğ½Ğ¶ĞµĞºÑ‚Ğ°Ñ… Ğ´Ğ°ÑÑ‚ 0)
        seg['text'], _gap_log = gap_fixer_v2(
            seg['text'], start, end,
            sub_segments, total_pre_words,
            interval=interval, threshold=45.0,
            lookahead=12, debug=debug
        )
        if _gap_log:
            injection_count += len(_gap_log)
            if debug:
                print(f"     ğŸ”§ gap_fixer_v2: +{len(_gap_log)} inject(s)")

    if debug:
        print(f"\n{'â”€'*60}")
        print(f"âœ… Ğ’ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ timestamp : {injection_count}")
        if skipped_duplicates:
            print(f"â­ï¸ ĞŸÑ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½Ğ¾ Ğ´ÑƒĞ±Ğ»ĞµĞ¹   : {skipped_duplicates}")
        if delta_count > 0:
            print(f"ğŸ“Š Ğ¡Ñ€ĞµĞ´Ğ½Ğ¸Ğ¹ |Î”| (REAL) : {total_delta/delta_count:.1f}s "
                  f"Ğ¿Ğ¾ {delta_count} Ğ¸Ğ½Ğ¶ĞµĞºÑ†Ğ¸ÑĞ¼")
        if injection_count == 0 and skipped_duplicates == 0:
            print(f"âœ… Ğ‘Ğ»Ğ¾ĞºĞ¾Ğ² >30s Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾")

    return segments


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def correct_timestamp_drift(segments, debug=True):
    """
    ğŸ†• v16.22: FIX Ğ‘ĞĞ“ #2 - Timestamp Ğ½Ğ°Ğ·Ğ°Ğ´
    ğŸ†• v16.19: Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ÑĞµÑ‚ ÑĞ´Ğ²Ğ¸Ğ³ timestamp Ğ¿Ğ¾ÑĞ»Ğµ gap filling
    """
    if debug:
        print(f"\nğŸ”§ Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ ÑĞ´Ğ²Ğ¸Ğ³Ğ° timestamp Ğ¿Ğ¾ÑĞ»Ğµ gap filling...")

    corrections      = 0
    skipped_backward = 0

    for i in range(1, len(segments)):
        prev_seg    = segments[i - 1]
        current_seg = segments[i]

        prev_end      = prev_seg.get('end',   0)
        current_start = current_seg.get('start', 0)

        gap = current_start - prev_end

        if -10.0 <= gap <= 0.5:
            old_start = current_start
            new_start = prev_end

            if new_start >= old_start:
                current_seg['start'] = new_start
                current_seg['time']  = seconds_to_hms(new_start)

                if debug and abs(old_start - new_start) > 1.0:
                    print(f"  â±ï¸ {seconds_to_hms(old_start)} â†’ "
                          f"{seconds_to_hms(new_start)} "
                          f"(ÑĞ´Ğ²Ğ¸Ğ³ {new_start - old_start:+.1f}s)")

                corrections += 1
            else:
                if debug:
                    print(f"  â­ï¸ ĞŸĞ ĞĞŸĞ£Ğ¡ĞšĞĞ•Ğœ: {seconds_to_hms(old_start)} â†’ "
                          f"{seconds_to_hms(new_start)} "
                          f"(ÑĞ´Ğ²Ğ¸Ğ³ Ğ½Ğ°Ğ·Ğ°Ğ´ {new_start - old_start:.1f}s)")
                skipped_backward += 1

    if debug:
        if corrections:
            print(f"âœ… Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ timestamp: {corrections}")
        if skipped_backward:
            print(f"â­ï¸ ĞŸÑ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½Ğ¾ (Ğ½Ğ°Ğ·Ğ°Ğ´): {skipped_backward}")
        if corrections == 0 and skipped_backward == 0:
            print(f"âœ… Ğ¡Ğ´Ğ²Ğ¸Ğ³Ğ¾Ğ² Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾")

    return segments
