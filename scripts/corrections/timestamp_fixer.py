#!/usr/bin/env python3
"""
corrections/timestamp_fixer.py - Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ timestamp

ğŸ†• v17.11: FIX BAG_F â€” guard Ğ¿Ñ€Ğ¾Ñ‚Ğ¸Ğ² scale-Ğ°Ğ½Ğ¾Ğ¼Ğ°Ğ»Ğ¸Ğ¸ Ğ¿Ğ¾ÑĞ»Ğµ split
           split_mixed_speaker_segments() Ğ½Ğ°ÑĞ»ĞµĞ´ÑƒĞµÑ‚ sub_segments Ğ¾Ñ‚ Ñ€Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»Ñ.
           Ğ£ Ğ´Ğ¾Ñ‡ĞµÑ€Ğ½ĞµĞ³Ğ¾ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ° scale = total_pre_words/words_post >> 1.8
           â†’ _get_real_time_for_word() Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ·Ğ° Ğ¿Ñ€ĞµĞ´ĞµĞ»Ñ‹ seg.end â†’ Ğ¸Ğ½Ğ²ĞµÑ€ÑĞ¸Ñ.
           FIX: if scale > 1.8 â†’ fallback ESTIMATED (Ğ»Ğ¸Ğ½ĞµĞ¹Ğ½Ğ°Ñ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ¿Ğ¾Ğ»ÑÑ†Ğ¸Ñ)
ğŸ†• v17.10: Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ A â€” Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ğµ timestamp Ñ‡ĞµÑ€ĞµĞ· sub_segments Ğ¸Ğ· merge_replicas
           Ğ’Ğ¼ĞµÑÑ‚Ğ¾ word-proportion Ğ¿Ğ¾ Ğ²ÑĞµĞ¼Ñƒ Ğ±Ğ»Ğ¾ĞºÑƒ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ†Ñ‹
           Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Whisper-ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ². Debug: estimated vs real vs Î”.
ğŸ†• v16.28: FIX Ğ‘ĞĞ“ #3 - ĞŸĞ¾Ñ‚ĞµÑ€Ñ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ĞµĞ³Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ
ğŸ†• v16.22: FIX Ğ‘ĞĞ“ #1 - Ğ”ÑƒĞ±Ğ»Ğ¸Ñ€ÑƒÑÑ‰Ğ¸ĞµÑÑ timestamp
ğŸ†• v16.22: FIX Ğ‘ĞĞ“ #2 - Timestamp Ğ½Ğ°Ğ·Ğ°Ğ´
ğŸ†• v16.19: ĞšĞ Ğ˜Ğ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ™ FIX - Timestamp injection Ğ² Ğ±Ğ»Ğ¾ĞºĞ¸ >30 ÑĞµĞº
"""

import re
from core.utils import seconds_to_hms


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ†• v17.10: Helper â€” Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ²Ñ€ĞµĞ¼Ñ Ñ‡ĞµÑ€ĞµĞ· sub_segments
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _get_real_time_for_word(word_idx, total_words_post, seg_start, seg_end,
                             sub_segments, total_pre_words, debug=False):
    """
    ğŸ†• v17.10: Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµÑ‚ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ²Ñ€ĞµĞ¼Ñ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ word_idx.

    ĞœĞ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ñ Ğ¸Ğ· post-clean Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²Ğ° Ğ² pre-clean,
    Ğ·Ğ°Ñ‚ĞµĞ¼ Ğ¸Ñ‰ĞµÑ‚ Ğ½ÑƒĞ¶Ğ½Ñ‹Ğ¹ sub_segment Ğ¸ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ¿Ğ¾Ğ»Ğ¸Ñ€ÑƒĞµÑ‚ Ğ²Ğ½ÑƒÑ‚Ñ€Ğ¸ Ğ½ĞµĞ³Ğ¾.

    Args:
        word_idx:           ĞŸĞ¾Ğ·Ğ¸Ñ†Ğ¸Ñ Ğ¿ĞµÑ€Ğ²Ğ¾Ğ³Ğ¾ ÑĞ»Ğ¾Ğ²Ğ° Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ (post-clean)
        total_words_post:   Ğ’ÑĞµĞ³Ğ¾ ÑĞ»Ğ¾Ğ² Ğ² merged Ñ‚ĞµĞºÑÑ‚Ğµ (post-clean)
        seg_start:          seg['start'] â€” fallback Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ¾
        seg_end:            seg['end']   â€” fallback ĞºĞ¾Ğ½ĞµÑ†
        sub_segments:       [{'start', 'end', 'words'}, ...] Ğ¸Ğ· merge_replicas
        total_pre_words:    Ğ¡ÑƒĞ¼Ğ¼Ğ° words Ğ¸Ğ· sub_segments (pre-clean)
        debug:              ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°Ñ‚ÑŒ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ debug lookup

    Returns:
        float: Ğ’Ñ€ĞµĞ¼Ñ Ğ² ÑĞµĞºÑƒĞ½Ğ´Ğ°Ñ…
    """
    duration = seg_end - seg_start

    # Fallback: Ğ½ĞµÑ‚ sub_segments â†’ ÑÑ‚Ğ°Ñ€Ğ°Ñ Ğ»Ğ¸Ğ½ĞµĞ¹Ğ½Ğ°Ñ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ¿Ğ¾Ğ»ÑÑ†Ğ¸Ñ
    if not sub_segments or total_pre_words == 0 or total_words_post == 0:
        return seg_start + (word_idx / total_words_post) * duration

    # ĞœĞ°ÑÑˆÑ‚Ğ°Ğ±: post-clean â†’ pre-clean
    scale = total_pre_words / total_words_post
    scaled_idx = word_idx * scale

    cumulative = 0
    for sub in sub_segments:
        sub_words = max(sub.get('words', 1), 1)
        if scaled_idx <= cumulative + sub_words:
            fraction = (scaled_idx - cumulative) / sub_words
            real_time = sub['start'] + fraction * (sub['end'] - sub['start'])
            if debug:
                print(f"      ğŸ” word_idx={word_idx} â†’ scaled={scaled_idx:.1f} â†’ "
                      f"sub [{seconds_to_hms(sub['start'])}-{seconds_to_hms(sub['end'])}] "
                      f"words={sub_words} frac={fraction:.2f} â†’ {seconds_to_hms(real_time)}")
            return real_time
        cumulative += sub_words

    return sub_segments[-1]['end']


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def find_existing_timestamps(text):
    """
    ğŸ†• v17.13: ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ²ÑĞµ ÑƒĞ¶Ğµ Ğ²ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ğµ timestamp Ğ² Ñ‚ĞµĞºÑÑ‚Ğµ.
    Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ ÑĞ¿Ğ¸ÑĞ¾Ğº {'ts': '00:32:59', 'sec': 1979, 'pos': 42}
    """
    pattern = r'\b(\d{2}:\d{2}:\d{2})\b'
    found = []
    for m in re.finditer(pattern, text):
        h, mn, s = m.group(1).split(':')
        found.append({
            'ts':  m.group(1),
            'sec': int(h) * 3600 + int(mn) * 60 + int(s),
            'pos': m.start()
        })
    return found

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def insert_intermediate_timestamps(segments, interval=30.0, debug=True):
    """
    ğŸ†• v17.13: FIX Ğ‘ĞĞ“ â€” Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€Ğ½Ñ‹Ğ¹ Ğ²Ñ‹Ğ·Ğ¾Ğ² Ğ¿Ğ¾ÑĞ»Ğµ auto_merge.
               SKIP Ğ±Ğ»Ğ¾ĞºĞ¾Ğ² Ñƒ ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ñ… Ñ…Ğ²Ğ¾ÑÑ‚ (end - last_existing_ts) â‰¤ interval*1.5.
               Ğ¢Ñ€Ğ¾Ğ³Ğ°ĞµĞ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ±Ğ»Ğ¾ĞºĞ¸ Ñ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾ Ğ½ĞµĞ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ½Ñ‹Ğ¼ Ñ…Ğ²Ğ¾ÑÑ‚Ğ¾Ğ¼ > 45s.
               existing ts Ğ² Ñ‚ĞµĞºÑÑ‚Ğµ Ğ½Ğµ Ğ¿ĞµÑ€ĞµÑÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ¸ Ğ½Ğµ Ğ²Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼.
    ğŸ†• v17.12: FIX Ğ‘ĞĞ“ â€” fallback inject Ğ¿ĞµÑ€ĞµĞ´ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğ¼ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸ĞµĞ¼
    ğŸ†• v17.11: FIX BAG_F â€” guard Ğ¿Ñ€Ğ¾Ñ‚Ğ¸Ğ² scale-Ğ°Ğ½Ğ¾Ğ¼Ğ°Ğ»Ğ¸Ğ¸ Ğ¿Ğ¾ÑĞ»Ğµ split
    ğŸ†• v17.10: Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ A â€” Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ğµ timestamp Ñ‡ĞµÑ€ĞµĞ· sub_segments Ğ¸Ğ· merge_replicas
    ğŸ†• v16.28: FIX Ğ‘ĞĞ“ #3 - ĞŸĞ¾Ñ‚ĞµÑ€Ñ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ĞµĞ³Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ
    ğŸ†• v16.22: FIX Ğ‘ĞĞ“ #1 - Ğ”ÑƒĞ±Ğ»Ğ¸Ñ€ÑƒÑÑ‰Ğ¸ĞµÑÑ timestamp
    ğŸ†• v16.22: FIX Ğ‘ĞĞ“ #2 - Timestamp Ğ½Ğ°Ğ·Ğ°Ğ´
    ğŸ†• v16.19: ĞšĞ Ğ˜Ğ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ™ FIX - Timestamp injection Ğ² Ğ±Ğ»Ğ¾ĞºĞ¸ >30 ÑĞµĞº
    """
    if debug:
        print(f"\nğŸ•’ Ğ’ÑÑ‚Ğ°Ğ²ĞºĞ° Ğ¿Ñ€Ğ¾Ğ¼ĞµĞ¶ÑƒÑ‚Ğ¾Ñ‡Ğ½Ñ‹Ñ… timestamp (interval={interval}s, mode=v17.13)...")

    injection_count    = 0
    skipped_duplicates = 0
    total_delta        = 0.0
    delta_count        = 0

    for seg_idx, seg in enumerate(segments):
        start    = seg.get('start', 0)
        end      = seg.get('end',   0)
        duration = end - start

        if duration <= interval:
            if debug and duration > 25:
                print(f"  â„¹ï¸  SHORT SKIP: [{seg.get('time','???')}] Ğ´Ğ»Ğ¸Ñ‚={duration:.0f}s â‰¤ {interval}s")
            continue

        text = seg.get('text', '')

        # ğŸ†• v17.13: ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ğ¼ existing timestamp Ğ¾Ñ‚ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰ĞµĞ³Ğ¾ Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ´Ğ°
        existing_ts   = find_existing_timestamps(text)
        existing_secs = [e['sec'] for e in existing_ts]

        # ğŸ†• v17.13: SKIP ĞµÑĞ»Ğ¸ Ñ…Ğ²Ğ¾ÑÑ‚ ÑƒĞ¶Ğµ Ğ¿Ğ¾ĞºÑ€Ñ‹Ñ‚ â€” Ğ½Ğµ Ñ‚Ñ€Ğ¾Ğ³Ğ°ĞµĞ¼ Ğ±Ğ»Ğ¾Ğº Ğ²Ğ¾Ğ¾Ğ±Ñ‰Ğµ
        if existing_secs:
            tail = end - max(existing_secs)
            if tail <= interval * 1.5:
                if debug:
                    print(f"  âœ… SKIP (covered): [{seg.get('time','???')}] "
                          f"Ñ…Ğ²Ğ¾ÑÑ‚={tail:.0f}s â‰¤ {interval * 1.5:.0f}s")
                continue

        # Ğ”Ğ»Ñ Ğ¿Ğ¾Ğ´ÑÑ‡Ñ‘Ñ‚Ğ° ÑĞ»Ğ¾Ğ² Ğ¸ split â€” ÑƒĞ±Ğ¸Ñ€Ğ°ĞµĞ¼ existing ts Ğ¸Ğ· Ñ‚ĞµĞºÑÑ‚Ğ°
        clean_text = re.sub(r'\s*\b\d{2}:\d{2}:\d{2}\b\s*', ' ', text).strip()

        sub_segments    = seg.get('sub_segments', [])
        total_pre_words = sum(s.get('words', 0) for s in sub_segments)
        has_real_data   = bool(sub_segments) and total_pre_words > 0

        sentences = re.split(r'([.!?]+)\s+', clean_text)
        sentences = [''.join(sentences[i:i+2]).strip()
                     for i in range(0, len(sentences), 2)]
        sentences = [s for s in sentences if s]

        if len(sentences) < 2:
            if debug:
                snippet = clean_text[:120].replace('\n', ' ')
                print(f"  âš ï¸  BAG_D SKIP: Ğ±Ğ»Ğ¾Ğº [{seg.get('time','???')}â€“{seconds_to_hms(end)}] "
                      f"Ğ´Ğ»Ğ¸Ñ‚={duration:.0f}s â€” sentences<2, Ñ‚Ğ°Ğ¹Ğ¼ĞºĞ¾Ğ´ ĞĞ• Ğ²ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½")
                print(f"      Ğ¢ĞµĞºÑÑ‚ (Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ¾): '{snippet}...'")
                punct_count = len(re.findall(r'[.!?]', clean_text))
                print(f"      Ğ—Ğ½Ğ°ĞºĞ¾Ğ² Ğ¿ÑƒĞ½ĞºÑ‚ÑƒĞ°Ñ†Ğ¸Ğ¸ [.!?]: {punct_count} | "
                      f"Ğ¡Ğ»Ğ¾Ğ²: {len(clean_text.split())} | "
                      f"Ğ¡Ğ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²: {len(clean_text)}")
            continue

        words_total = len(clean_text.split())

        _SCALE_ANOMALY_THRESHOLD = 1.8
        if has_real_data and words_total > 0:
            _scale = total_pre_words / words_total
            if _scale > _SCALE_ANOMALY_THRESHOLD:
                if debug:
                    print(f"  âš ï¸  BAG_F GUARD [{seg.get('time', '???')}] "
                          f"{seg.get('speaker', '?')}: "
                          f"scale={_scale:.3f} > {_SCALE_ANOMALY_THRESHOLD} "
                          f"(pre={total_pre_words} / post={words_total}) "
                          f"â€” sub_segments Ğ¾Ñ‚ Ñ€Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»Ñ Ğ¿Ğ¾ÑĞ»Ğµ split, fallback ESTIMATED")
                sub_segments    = []
                total_pre_words = 0
                has_real_data   = False

        if debug:
            mode = "ğŸ¯ REAL (sub_segments)" if has_real_data else "ğŸ“ ESTIMATED (word proportion)"
            print(f"\n  â”€â”€ Ğ¡ĞµĞ³Ğ¼ĞµĞ½Ñ‚ [{seg.get('time','???')}] {seg.get('speaker')} â”€â”€")
            print(f"     Ğ´Ğ»Ğ¸Ñ‚={duration:.1f}s | ÑĞ»Ğ¾Ğ²(post)={words_total} | Ñ€ĞµĞ¶Ğ¸Ğ¼={mode}")
            if has_real_data:
                print(f"     sub_segments: {len(sub_segments)} ÑˆÑ‚ | "
                      f"words(pre-clean)={total_pre_words} | "
                      f"scale={total_pre_words/words_total:.3f}")
                for si, s in enumerate(sub_segments):
                    print(f"       sub[{si}]: [{seconds_to_hms(s['start'])}-"
                          f"{seconds_to_hms(s['end'])}] words={s['words']}")
            if existing_secs:
                print(f"     existing ts: {[e['ts'] for e in existing_ts]} "
                      f"(Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ñ…Ğ¾Ğ´, Ñ…Ğ²Ğ¾ÑÑ‚ > {interval * 1.5:.0f}s)")

        new_text_parts   = []
        current_word_idx = 0

        # ğŸ†• v17.13: ÑÑ‚Ğ°Ñ€Ñ‚ÑƒĞµĞ¼ Ğ¾Ñ‚ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ĞµĞ³Ğ¾ existing ts
        last_inject_time  = max(existing_secs) if existing_secs else start
        all_inject_times  = list(existing_secs)
        injected_this_seg = len(existing_secs) > 0

        def _already_covered(t, window=8.0):
            return any(abs(ts - t) <= window for ts in all_inject_times)

        for sent_idx, sent in enumerate(sentences):
            sent_words = len(sent.split())
            is_last    = (sent_idx == len(sentences) - 1)

            current_time   = (start + (current_word_idx / words_total) * duration
                               if words_total > 0 else start)
            gap_since_last = current_time - last_inject_time

            should_inject_main = (
                gap_since_last >= interval
                and not is_last
            )
            # Fallback: Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ĞµĞµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ, Ñ…Ğ²Ğ¾ÑÑ‚ > interval/2
            should_inject_fallback = (
                is_last
                and gap_since_last >= interval / 2
            )

            if should_inject_main or should_inject_fallback:
                if _already_covered(current_time):
                    if debug:
                        nearest = min(all_inject_times, key=lambda t: abs(t - current_time))
                        print(f"     â­ï¸ Ğ´ÑƒĞ±Ğ»ÑŒ: {seconds_to_hms(current_time)} "
                              f"(Î”={abs(nearest - current_time):.1f}s Ğ¾Ñ‚ {seconds_to_hms(nearest)})")
                    skipped_duplicates += 1
                else:
                    real_time = _get_real_time_for_word(
                        current_word_idx, words_total, start, end,
                        sub_segments, total_pre_words, debug=False
                    )
                    timestamp_str = f" {seconds_to_hms(real_time)} "
                    new_text_parts.append(timestamp_str)

                    all_inject_times.append(real_time)
                    last_inject_time  = real_time
                    injected_this_seg = True
                    injection_count  += 1

                    if debug:
                        delta  = real_time - current_time
                        method = "REAL âœ…    " if has_real_data else "ESTIMATED âš ï¸"
                        tag    = " [FALLBACK]" if should_inject_fallback else ""
                        print(f"     ğŸ“Œ [{method}]{tag} inject={seconds_to_hms(real_time).strip()} "
                              f"| Î”={delta:+.1f}s "
                              f"| word#{current_word_idx}/{words_total} "
                              f"| gap={gap_since_last:.1f}s")
                        print(f"        â†³ '{sent[:60]}...'")
                        if has_real_data:
                            total_delta += abs(delta)
                            delta_count += 1

            new_text_parts.append(sent)
            current_word_idx += sent_words

        # ğŸ†• v17.13: existing ts Ğ² Ñ…Ğ²Ğ¾ÑÑ‚Ğµ (Ğ¿Ğ¾ÑĞ»Ğµ Ğ²ÑĞµÑ… Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹) â€” ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼
        final_word_time = (start + (current_word_idx / words_total) * duration
                           if words_total > 0 else end)
        for ets in sorted(existing_ts, key=lambda x: x['sec']):
            if ets['sec'] > final_word_time:
                new_text_parts.append(f" {ets['ts']} ")

        seg['text'] = ' '.join(new_text_parts)

    if debug:
        print(f"\n{'â”€'*60}")
        print(f"âœ… Ğ’ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ timestamp : {injection_count}")
        if skipped_duplicates:
            print(f"â­ï¸ ĞŸÑ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½Ğ¾ Ğ´ÑƒĞ±Ğ»ĞµĞ¹   : {skipped_duplicates}")
        if delta_count > 0:
            print(f"ğŸ“Š Ğ¡Ñ€ĞµĞ´Ğ½Ğ¸Ğ¹ |Î”| (REAL) : {total_delta/delta_count:.1f}s "
                  f"Ğ¿Ğ¾ {delta_count} Ğ¸Ğ½Ğ¶ĞµĞºÑ†Ğ¸ÑĞ¼")
        if injection_count == 0 and skipped_duplicates == 0:
            print(f"âœ… Ğ‘Ğ»Ğ¾ĞºĞ¾Ğ² >30s Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾")

    return segments

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def correct_timestamp_drift(segments, debug=True):
    """
    ğŸ†• v16.22: FIX Ğ‘ĞĞ“ #2 - Timestamp Ğ½Ğ°Ğ·Ğ°Ğ´
    ğŸ†• v16.19: Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ÑĞµÑ‚ ÑĞ´Ğ²Ğ¸Ğ³ timestamp Ğ¿Ğ¾ÑĞ»Ğµ gap filling

    **ĞŸĞ ĞĞ‘Ğ›Ğ•ĞœĞ (Ğ‘ĞĞ“ #2):**
    Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ ÑĞ´Ğ²Ğ¸Ğ³Ğ°Ğ»Ğ° timestamp ĞĞĞ—ĞĞ”:
    - prev_seg.end = 183.5 (00:03:03)
    - current_seg.start = 186.2 (00:03:06)
    - new_start = prev_end = 183.5  â† ĞœĞ•ĞĞ¬Ğ¨Ğ• Ñ‡ĞµĞ¼ 186.2!
    - Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚: 00:03:06 â†’ 00:03:03 (ĞĞĞ—ĞĞ”!)

    **FIX v16.22:**
    ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ¼Ğ¾Ğ½Ğ¾Ñ‚Ğ¾Ğ½Ğ½Ğ¾ÑÑ‚ÑŒ: new_start Ğ”ĞĞ›Ğ–Ğ•Ğ Ğ±Ñ‹Ñ‚ÑŒ >= old_start
    """
    if debug:
        print(f"\nğŸ”§ Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ ÑĞ´Ğ²Ğ¸Ğ³Ğ° timestamp Ğ¿Ğ¾ÑĞ»Ğµ gap filling...")

    corrections      = 0
    skipped_backward = 0

    for i in range(1, len(segments)):
        prev_seg    = segments[i - 1]
        current_seg = segments[i]

        prev_end      = prev_seg.get('end',   0)
        current_start = current_seg.get('start', 0)

        gap = current_start - prev_end

        if -10.0 <= gap <= 0.5:
            old_start = current_start
            new_start = prev_end

            # ğŸ†• v16.22: FIX Ğ‘ĞĞ“ #2 â€” Ğ½Ğµ Ğ´Ğ²Ğ¸Ğ³Ğ°ĞµĞ¼ Ğ½Ğ°Ğ·Ğ°Ğ´
            if new_start >= old_start:
                current_seg['start'] = new_start
                current_seg['time']  = seconds_to_hms(new_start)

                if debug and abs(old_start - new_start) > 1.0:
                    print(f"  â±ï¸ {seconds_to_hms(old_start)} â†’ "
                          f"{seconds_to_hms(new_start)} "
                          f"(ÑĞ´Ğ²Ğ¸Ğ³ {new_start - old_start:+.1f}s)")

                corrections += 1
            else:
                if debug:
                    print(f"  â­ï¸ ĞŸĞ ĞĞŸĞ£Ğ¡ĞšĞĞ•Ğœ: {seconds_to_hms(old_start)} â†’ "
                          f"{seconds_to_hms(new_start)} "
                          f"(ÑĞ´Ğ²Ğ¸Ğ³ Ğ½Ğ°Ğ·Ğ°Ğ´ {new_start - old_start:.1f}s)")
                skipped_backward += 1

    if debug:
        if corrections:
            print(f"âœ… Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ timestamp: {corrections}")
        if skipped_backward:
            print(f"â­ï¸ ĞŸÑ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½Ğ¾ (Ğ½Ğ°Ğ·Ğ°Ğ´): {skipped_backward}")
        if corrections == 0 and skipped_backward == 0:
            print(f"âœ… Ğ¡Ğ´Ğ²Ğ¸Ğ³Ğ¾Ğ² Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾")

    return segments
