#!/usr/bin/env python3
"""
corrections/speaker_classifier.py - Ğ’ĞµÑĞ¾Ğ²Ğ°Ñ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ¾Ğ² v15 Ğ´Ğ»Ñ v16.0
"""

import re
from core.config import SPEAKER_CLASSIFICATION_CONFIDENCE_THRESHOLD, SPEAKER_CLASSIFICATION_MIN_WORDS

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ’Ğ¡ĞŸĞĞœĞĞ“ĞĞ¢Ğ•Ğ›Ğ¬ĞĞ«Ğ• Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def is_journalist_addressing_speaker(text, word_count):
    """
    ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚, ÑĞ²Ğ»ÑĞµÑ‚ÑÑ Ğ»Ğ¸ Ñ‚ĞµĞºÑÑ‚ Ğ¾Ğ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸ĞµĞ¼ Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚Ğ° Ğº Ğ¡Ğ¿Ğ¸ĞºĞµÑ€Ñƒ

    Args:
        text: Ğ¢ĞµĞºÑÑ‚ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸
        word_count: ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ÑĞ»Ğ¾Ğ² Ğ² Ñ‚ĞµĞºÑÑ‚Ğµ

    Returns:
        bool: True ĞµÑĞ»Ğ¸ ÑÑ‚Ğ¾ Ğ¾Ğ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ğµ Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚Ğ°
    """
    text_lower = text.lower()

    journalist_addressing_patterns = [
        r'\b(?:Ñ…Ğ¾Ñ€Ğ¾ÑˆĞ¾|Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ½Ğ¾|Ğ¿Ğ¾Ğ½ÑÑ‚Ğ½Ğ¾|ÑÑĞ½Ğ¾|ÑĞ¿Ğ°ÑĞ¸Ğ±Ğ¾|Ğ±Ğ»Ğ°Ğ³Ğ¾Ğ´Ğ°Ñ€Ñ)\b',
        r'\b(?:Ğ´Ğ°Ğ²Ğ°Ğ¹Ñ‚Ğµ|Ğ¼Ğ¾Ğ¶ĞµÑ‚Ğµ|Ñ€Ğ°ÑÑĞºĞ°Ğ¶Ğ¸Ñ‚Ğµ|Ğ¾Ğ¿Ğ¸ÑˆĞ¸Ñ‚Ğµ|Ğ¾Ğ±ÑŠÑÑĞ½Ğ¸Ñ‚Ğµ)\b',
        r'\b(?:Ğ½Ğ¸Ñ‡ĞµĞ³Ğ¾\s+ÑÑ‚Ñ€Ğ°ÑˆĞ½Ğ¾Ğ³Ğ¾|Ğ²ÑĞµ\s+(?:Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾|Ñ…Ğ¾Ñ€Ğ¾ÑˆĞ¾|Ğ²\s+Ğ¿Ğ¾Ñ€ÑĞ´ĞºĞµ))\b',
        r'\b(?:Ğ½Ğµ\s+ÑÑ‚Ñ€Ğ°ÑˆĞ½Ğ¾|Ğ½Ğµ\s+Ğ±ĞµĞ´Ğ°|Ğ»Ğ°Ğ´Ğ½Ğ¾|Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾)\b',
        r'\b(?:Ğ¿Ñ€ĞµĞºÑ€Ğ°ÑĞ½Ğ¾|Ğ·Ğ°Ğ¼ĞµÑ‡Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾|Ğ²ĞµĞ»Ğ¸ĞºĞ¾Ğ»ĞµĞ¿Ğ½Ğ¾)\b',
    ]

    has_journalist_addressing = any(
        re.search(p, text_lower) for p in journalist_addressing_patterns
    )

    speaker_monologue_antipatterns = [
        r'\bÑ\s+(?:Ğ´ÑƒĞ¼Ğ°Ñ|ÑÑ‡Ğ¸Ñ‚Ğ°Ñ|Ğ¿Ğ¾Ğ»Ğ°Ğ³Ğ°Ñ|ÑƒĞ²ĞµÑ€ĞµĞ½|Ğ·Ğ½Ğ°Ñ)\b',
        r'\b(?:Ğ´ĞµĞ»Ğ¾\s+Ğ²\s+Ñ‚Ğ¾Ğ¼|ÑÑƒÑ‚ÑŒ\s+Ğ²\s+Ñ‚Ğ¾Ğ¼|Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°\s+Ğ²\s+Ñ‚Ğ¾Ğ¼)\b',
        r'\b(?:Ğ²Ğ¾-Ğ¿ĞµÑ€Ğ²Ñ‹Ñ…|Ğ²Ğ¾-Ğ²Ñ‚Ğ¾Ñ€Ñ‹Ñ…|Ğ²-Ñ‚Ñ€ĞµÑ‚ÑŒĞ¸Ñ…)\b',
        r'\b(?:Ğ¿Ğ¾ÑÑ‚Ğ¾Ğ¼Ñƒ|ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾|Ñ‚Ğ°ĞºĞ¸Ğ¼\s+Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ¼)\b',
    ]

    has_speaker_monologue = any(
        re.search(p, text_lower) for p in speaker_monologue_antipatterns
    )

    return (word_count < 15 and 
            has_journalist_addressing and 
            not has_speaker_monologue)

def has_speaker_monologue_markers(text):
    """
    ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚ Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ Ğ¼Ğ°Ñ€ĞºĞµÑ€Ğ¾Ğ² Ğ¼Ğ¾Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ° Ğ¡Ğ¿Ğ¸ĞºĞµÑ€Ğ°

    Args:
        text: Ğ¢ĞµĞºÑÑ‚ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸

    Returns:
        bool: True ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ Ğ¼Ğ°Ñ€ĞºĞµÑ€Ñ‹ Ğ¼Ğ¾Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ° Ğ¡Ğ¿Ğ¸ĞºĞµÑ€Ğ°
    """
    text_lower = text.lower()

    speaker_monologue_patterns = [
        r'\bÑ\s+(?:Ğ´ÑƒĞ¼Ğ°Ñ|ÑÑ‡Ğ¸Ñ‚Ğ°Ñ|Ğ¿Ğ¾Ğ»Ğ°Ğ³Ğ°Ñ|ÑƒĞ²ĞµÑ€ĞµĞ½|ÑƒĞ±ĞµĞ¶Ğ´ĞµĞ½|ÑƒĞ±ĞµĞ¶Ğ´Ñ‘Ğ½|Ğ·Ğ½Ğ°Ñ|Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ñ|Ğ²Ğ¸Ğ¶Ñƒ|Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑÑ|Ğ¿Ñ€ĞµĞ´Ğ¿Ğ¾Ğ»Ğ°Ğ³Ğ°Ñ)\b',
        r'\b(?:Ñƒ\s+Ğ¼ĞµĞ½Ñ|Ğ¼Ğ½Ğµ|Ğ¼ĞµĞ½Ñ|Ğ¼Ğ½Ğ¾Ğ¹|Ğ¼Ğ½Ğ¾Ñ|Ğ¼Ğ¾Ñ‘|Ğ¼Ğ¾Ñ|Ğ¼Ğ¾Ğ¸|Ğ¼Ğ¾Ğµ|Ğ¼Ğ¾ĞµĞ³Ğ¾|Ğ¼Ğ¾ĞµĞ¹|Ğ¼Ğ¾Ğ¸Ñ…|Ğ¼Ğ¾Ğ¸Ğ¼|Ğ¼Ğ¾Ğ¸Ğ¼Ğ¸)\b',
        r'\b(?:Ğ´ĞµĞ»Ğ¾\s+Ğ²\s+Ñ‚Ğ¾Ğ¼|ÑÑƒÑ‚ÑŒ\s+Ğ²\s+Ñ‚Ğ¾Ğ¼|Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°\s+Ğ²\s+Ñ‚Ğ¾Ğ¼|Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ\s+Ğ²\s+Ñ‚Ğ¾Ğ¼|ÑĞ¼Ñ‹ÑĞ»\s+Ğ²\s+Ñ‚Ğ¾Ğ¼)\b',
        r'\b(?:Ğ²Ğ¾-Ğ¿ĞµÑ€Ğ²Ñ‹Ñ…|Ğ²Ğ¾-Ğ²Ñ‚Ğ¾Ñ€Ñ‹Ñ…|Ğ²-Ñ‚Ñ€ĞµÑ‚ÑŒĞ¸Ñ…|Ğ²-Ñ‡ĞµÑ‚Ğ²ĞµÑ€Ñ‚Ñ‹Ñ…|Ğ²-Ñ‡ĞµÑ‚Ğ²Ñ‘Ñ€Ñ‚Ñ‹Ñ…|Ğ²-Ğ¿ÑÑ‚Ñ‹Ñ…)\b',
        r'\b(?:Ğ¿Ğ¾ÑÑ‚Ğ¾Ğ¼Ñƒ|ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾|Ñ‚Ğ°ĞºĞ¸Ğ¼\s+Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ¼|Ğ²\s+ÑĞ²ÑĞ·Ğ¸\s+Ñ\s+ÑÑ‚Ğ¸Ğ¼|Ğ¾Ñ‚ÑÑĞ´Ğ°|Ğ¸Ğ·\s+ÑÑ‚Ğ¾Ğ³Ğ¾\s+ÑĞ»ĞµĞ´ÑƒĞµÑ‚)\b',
        r'\b(?:Ğ½Ğ°\s+Ğ¼Ğ¾Ğ¹\s+Ğ²Ğ·Ğ³Ğ»ÑĞ´|Ğ¿Ğ¾\s+Ğ¼Ğ¾ĞµĞ¼Ñƒ\s+Ğ¼Ğ½ĞµĞ½Ğ¸Ñ|ĞºĞ°Ğº\s+Ğ¼Ğ½Ğµ\s+ĞºĞ°Ğ¶ĞµÑ‚ÑÑ|Ñ\s+Ğ±Ñ‹\s+ÑĞºĞ°Ğ·Ğ°Ğ»|Ñ\s+Ğ±Ñ‹\s+Ğ¾Ñ‚Ğ¼ĞµÑ‚Ğ¸Ğ»)\b',
        r'\bÑ\s+(?:Ğ¼Ğ¾Ğ³Ñƒ|Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½|Ñ…Ğ¾Ñ‡Ñƒ|Ğ±ÑƒĞ´Ñƒ|ÑÑ‚Ğ°Ğ»|Ğ½Ğ°Ñ‡Ğ°Ğ»|Ğ¿Ñ‹Ñ‚Ğ°ÑÑÑŒ|ÑÑ‚Ğ°Ñ€Ğ°ÑÑÑŒ)\b',
    ]

    return any(re.search(p, text_lower) for p in speaker_monologue_patterns)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ’Ğ•Ğ¡ĞĞ’ĞĞ¯ ĞšĞ›ĞĞ¡Ğ¡Ğ˜Ğ¤Ğ˜ĞšĞĞ¦Ğ˜Ğ¯ v15
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def apply_speaker_classification_v15(segments, speaker_surname, debug=False):
    """
    v15.0: Ğ’ĞµÑĞ¾Ğ²Ğ°Ñ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ¾Ğ² Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ñ‹Ñ… Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ğ¾Ğ²

    ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¹ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚ Ğ¸ Ğ¿ĞµÑ€ĞµĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€ÑƒĞµÑ‚ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ° Ğ¿Ñ€Ğ¸ Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğ¸
    ÑƒĞ±ĞµĞ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ´Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»ÑŒÑÑ‚Ğ². Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ ÑĞ¸ÑÑ‚ĞµĞ¼Ñƒ Ğ²ĞµÑĞ¾Ğ² Ğ´Ğ»Ñ Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸
    Ğ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… ÑÑ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°Ğ½Ğ¸Ğ¹.

    Args:
        segments: Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ¿Ğ¾ÑĞ»Ğµ merge_replicas()
        speaker_surname: Ğ¤Ğ°Ğ¼Ğ¸Ğ»Ğ¸Ñ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ³Ğ¾ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ°
        debug: Ğ•ÑĞ»Ğ¸ True, Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ñ‚ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½ÑƒÑ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ

    Returns:
        (segments, stats) - Ğ¼Ğ¾Ğ´Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¸ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°
    """

    # ĞŸĞ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹ Ğ´Ğ»Ñ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚Ğ°
    JOURNALIST_PATTERNS = {
        'addressing': [
            (r'\b(Ñ€Ğ°ÑÑĞºĞ°Ğ¶Ğ¸Ñ‚Ğµ|Ğ¾Ğ±ÑŠÑÑĞ½Ğ¸Ñ‚Ğµ|Ğ¿Ğ¾ÑÑĞ½Ğ¸Ñ‚Ğµ|ÑƒÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ñ‚Ğµ|ÑĞºĞ°Ğ¶Ğ¸Ñ‚Ğµ)\b', 3),
            (r'\b(Ğ²Ñ‹\s+(?:Ğ¼Ğ¾Ğ¶ĞµÑ‚Ğµ|Ğ·Ğ½Ğ°ĞµÑ‚Ğµ|Ğ¿Ğ¾Ğ¼Ğ½Ğ¸Ñ‚Ğµ|ÑÑ‡Ğ¸Ñ‚Ğ°ĞµÑ‚Ğµ|Ğ´ÑƒĞ¼Ğ°ĞµÑ‚Ğµ))\b', 2),
            (r'\b(ĞºĞ°Ğº\s+Ğ²Ñ‹\s+(?:ÑÑ‡Ğ¸Ñ‚Ğ°ĞµÑ‚Ğµ|Ğ´ÑƒĞ¼Ğ°ĞµÑ‚Ğµ|Ğ¾Ñ†ĞµĞ½Ğ¸Ğ²Ğ°ĞµÑ‚Ğµ))\b', 3),
            (r'\bĞ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²ÑŒÑ‚ĞµÑÑŒ\b', 5),
            (r'\b(Ğ´Ğ°Ğ²Ğ°Ğ¹Ñ‚Ğµ|Ğ¿ĞµÑ€ĞµÑ…Ğ¾Ğ´Ğ¸Ğ¼|Ğ½Ğ°Ñ‡Ğ½ĞµĞ¼|Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ¸Ğ¼)\b', 2),
        ],
        'questions': [
            (r'\?$', 1),  # Ğ’Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ·Ğ½Ğ°Ğº Ğ² ĞºĞ¾Ğ½Ñ†Ğµ
            (r'^(ĞºĞ°Ğº|Ğ¿Ğ¾Ñ‡ĞµĞ¼Ñƒ|Ğ·Ğ°Ñ‡ĞµĞ¼|ĞºĞ¾Ğ³Ğ´Ğ°|Ğ³Ğ´Ğµ|ĞºÑ‚Ğ¾|Ñ‡Ñ‚Ğ¾)\s', 2),  # Ğ’Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ² Ğ½Ğ°Ñ‡Ğ°Ğ»Ğµ
            (r'\b(Ğ½Ğµ\s+Ñ‚Ğ°Ğº|Ğ²ĞµÑ€Ğ½Ğ¾|Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾)\s*\?', 2),
        ],
        'commands': [
            (r'\b(ÑĞ¼Ğ¾Ñ‚Ñ€Ğ¸Ğ¼|ÑĞ»ÑƒÑˆĞ°ĞµĞ¼|Ğ¾Ñ‚Ğ²ĞµÑ‡Ğ°ĞµĞ¼)\s+(?:Ğ½Ğ°|Ğ²)', 2),
            (r'\bĞ¼Ñ‹\s+(?:ÑĞµĞ¹Ñ‡Ğ°Ñ|Ñ‚ĞµĞ¿ĞµÑ€ÑŒ)\s+(?:Ğ¾Ñ‚Ğ²ĞµÑ‡Ğ°ĞµĞ¼|Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ¸Ğ¼|Ğ¾Ğ±ÑÑƒĞ¶Ğ´Ğ°ĞµĞ¼)\b', 2),
        ],
    }

    # ĞŸĞ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹ Ğ´Ğ»Ñ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ Ğ¡Ğ¿Ğ¸ĞºĞµÑ€Ğ°
    SPEAKER_PATTERNS = {
        'monologue': [
            (r'\b(Ñƒ\s+Ğ¼ĞµĞ½Ñ|Ğ¼Ğ½Ğµ|Ñ\s+(?:ÑÑ‡Ğ¸Ñ‚Ğ°Ñ|Ğ´ÑƒĞ¼Ğ°Ñ|Ğ¿Ğ¾Ğ»Ğ°Ğ³Ğ°Ñ|Ğ¿Ğ¾Ğ¼Ğ½Ñ))\b', 2),
            (r'\b(Ğ½Ğ°\s+Ğ¼Ğ¾Ğ¹\s+Ğ²Ğ·Ğ³Ğ»ÑĞ´|Ğ¿Ğ¾\s+Ğ¼Ğ¾ĞµĞ¼Ñƒ\s+Ğ¼Ğ½ĞµĞ½Ğ¸Ñ)\b', 3),
            (r'\b(Ğ¼Ğ¾Ñ‘|Ğ¼Ğ¾Ñ|Ğ¼Ğ¾Ğ¹|Ğ¼Ğ¾Ğ¸)\s+(?:Ğ¼Ğ½ĞµĞ½Ğ¸Ğµ|Ğ¾Ğ¿Ñ‹Ñ‚|Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ|Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°)\b', 3),
        ],
        'facts': [
            (r'\b\d{4}\s*Ğ³Ğ¾Ğ´', 1),  # Ğ”Ğ°Ñ‚Ñ‹
            (r'\b(?:Ğ¾Ğ¿ĞµÑ€Ğ°Ñ†Ğ¸Ñ|ÑÑ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ|Ğ±Ğ¸Ñ‚Ğ²Ğ°|Ñ„Ñ€Ğ¾Ğ½Ñ‚|Ğ°Ñ€Ğ¼Ğ¸Ñ)\b', 1),
        ],
    }

    # Ğ—Ğ°Ñ‰Ğ¸Ñ‚Ñ‹ Ğ¾Ñ‚ Ğ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… ÑÑ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°Ğ½Ğ¸Ğ¹
    PROTECTIONS = {
        'journalist_not_speaker': [
            # "ĞœÑ‹" Ğ² ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğµ Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ñ‹, Ğ½Ğµ Ğ»Ğ¸Ñ‡Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ¿Ñ‹Ñ‚Ğ°
            (r'\bĞ¼Ñ‹\s+(?:ÑĞµĞ¹Ñ‡Ğ°Ñ|Ñ‚ĞµĞ¿ĞµÑ€ÑŒ|Ñ‚ÑƒÑ‚|Ğ·Ğ´ĞµÑÑŒ)\s', -3),
            # ĞĞ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ğµ "Ğ²Ñ‹" Ğº Ğ¡Ğ¿Ğ¸ĞºĞµÑ€Ñƒ
            (r'\bĞ²Ñ‹\s+(?:Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²ÑŒÑ‚ĞµÑÑŒ|Ñ€Ğ°ÑÑĞºĞ°Ğ¶Ğ¸Ñ‚Ğµ|Ğ¾Ğ±ÑŠÑÑĞ½Ğ¸Ñ‚Ğµ)\b', -5),
        ],
    }

    def calculate_speaker_score(text, current_speaker):
        """Ğ Ğ°ÑÑÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ²ĞµÑĞ° Ğ´Ğ»Ñ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ°"""
        text_lower = text.lower()
        journalist_score = 0
        speaker_score = 0
        details = []

        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹ Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚Ğ°
        for category, patterns in JOURNALIST_PATTERNS.items():
            for pattern, weight in patterns:
                if re.search(pattern, text_lower, re.I):
                    journalist_score += weight
                    details.append(f"J:{category}:+{weight}")

        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹ Ğ¡Ğ¿Ğ¸ĞºĞµÑ€Ğ°
        for category, patterns in SPEAKER_PATTERNS.items():
            for pattern, weight in patterns:
                if re.search(pattern, text_lower, re.I):
                    speaker_score += weight
                    details.append(f"S:{category}:+{weight}")

        # ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ÑĞµĞ¼ Ğ·Ğ°Ñ‰Ğ¸Ñ‚Ñ‹
        for pattern, weight in PROTECTIONS['journalist_not_speaker']:
            if re.search(pattern, text_lower, re.I):
                speaker_score += weight  # ĞÑ‚Ñ€Ğ¸Ñ†Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ²ĞµÑ ÑƒĞ¼ĞµĞ½ÑŒÑˆĞ°ĞµÑ‚ Ğ²ĞµÑ Ğ¡Ğ¿Ğ¸ĞºĞµÑ€Ğ°
                details.append(f"PROTECT:S:{weight}")

        return journalist_score, speaker_score, details

    # Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°
    stats = {
        'total_checked': 0,
        'changed_to_journalist': 0,
        'changed_to_speaker': 0,
        'skipped_protections': 0,
        'details': []
    }

    if debug:
        print("\n" + "="*80)
        print("ğŸ¯ v15: Ğ’Ğ•Ğ¡ĞĞ’ĞĞ¯ ĞšĞ›ĞĞ¡Ğ¡Ğ˜Ğ¤Ğ˜ĞšĞĞ¦Ğ˜Ğ¯ Ğ¡ĞŸĞ˜ĞšĞ•Ğ ĞĞ’")
        print("="*80)

    for seg in segments:
        text = seg.get('text', '').strip()
        current_speaker = seg.get('speaker', '')
        time = seg.get('time', '00:00:00')
        word_count = len(text.split())

        # ĞŸÑ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğµ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¸ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ°
        if word_count < SPEAKER_CLASSIFICATION_MIN_WORDS or current_speaker == 'ĞĞ¿ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€':
            continue

        stats['total_checked'] += 1

        j_score, s_score, details = calculate_speaker_score(text, current_speaker)

        # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ğ¿Ğ¾Ñ€Ğ¾Ğ³ Ğ´Ğ»Ñ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ (Ğ¼Ğ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ñ€Ğ°Ğ·Ğ½Ğ¸Ñ†Ğ° Ğ²ĞµÑĞ¾Ğ²)
        CONFIDENCE_THRESHOLD = SPEAKER_CLASSIFICATION_CONFIDENCE_THRESHOLD

        # Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚ â†’ Ğ¡Ğ¿Ğ¸ĞºĞµÑ€
        if current_speaker == 'Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚' and s_score > j_score + CONFIDENCE_THRESHOLD:
            if debug:
                print(f"\n  ğŸ”„ [{time}] Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚ â†’ {speaker_surname}")
                print(f"     Ğ’ĞµÑĞ°: J={j_score}, S={s_score}")
                print(f"     ĞŸĞ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹: {', '.join(details)}")
                print(f"     Ğ¢ĞµĞºÑÑ‚: {text[:80]}...")

            seg['speaker'] = speaker_surname
            stats['changed_to_speaker'] += 1
            stats['details'].append({
                'time': time,
                'from': 'Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚',
                'to': speaker_surname,
                'j_score': j_score,
                's_score': s_score,
                'text': text[:100]
            })

        # Ğ¡Ğ¿Ğ¸ĞºĞµÑ€ â†’ Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚
        elif current_speaker == speaker_surname and j_score > s_score + CONFIDENCE_THRESHOLD:
            if debug:
                print(f"\n  ğŸ”„ [{time}] {speaker_surname} â†’ Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚")
                print(f"     Ğ’ĞµÑĞ°: J={j_score}, S={s_score}")
                print(f"     ĞŸĞ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹: {', '.join(details)}")
                print(f"     Ğ¢ĞµĞºÑÑ‚: {text[:80]}...")

            seg['speaker'] = 'Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚'
            stats['changed_to_journalist'] += 1
            stats['details'].append({
                'time': time,
                'from': speaker_surname,
                'to': 'Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚',
                'j_score': j_score,
                's_score': s_score,
                'text': text[:100]
            })

    if debug:
        print("="*80)
        print(f"âœ… v15: ĞšĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°")
        print(f"   Ğ’ÑĞµĞ³Ğ¾ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞµĞ½Ğ¾: {stats['total_checked']}")
        print(f"   Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¾: {stats['changed_to_journalist'] + stats['changed_to_speaker']}")
        print(f"   â€¢ Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚ â†’ Ğ¡Ğ¿Ğ¸ĞºĞµÑ€: {stats['changed_to_speaker']}")
        print(f"   â€¢ Ğ¡Ğ¿Ğ¸ĞºĞµÑ€ â†’ Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚: {stats['changed_to_journalist']}")
        print(f"   â€¢ ĞŸÑ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½Ğ¾ (Ğ·Ğ°Ñ‰Ğ¸Ñ‚Ñ‹): {stats['skipped_protections']}")
        print("="*80)
        print()

    return segments, stats
