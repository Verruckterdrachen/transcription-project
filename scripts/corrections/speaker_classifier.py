#!/usr/bin/env python3
"""
corrections/speaker_classifier.py - Ğ’ĞµÑĞ¾Ğ²Ğ°Ñ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ¾Ğ² v15 Ğ´Ğ»Ñ v17.5

ğŸ†• v17.5: Ğ ĞĞ¡Ğ¨Ğ˜Ğ Ğ•ĞĞĞ«Ğ™ DEBUG - Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ñ‚Ñ€Ğ°ÑÑĞ¸Ñ€Ğ¾Ğ²ĞºĞ° Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ğ¾Ğ²
- ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ ĞšĞĞšĞ˜Ğ• Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹ ÑÑ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ»Ğ¸
- ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ ĞšĞĞšĞĞ™ Ñ‚ĞµĞºÑÑ‚ ÑĞ¾Ğ²Ğ¿Ğ°Ğ» (matched_text)
- ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ¸Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğ¹ ÑÑ‡Ñ‘Ñ‚ Ğ¸ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğµ
- Ğ¡Ğ¿ĞµÑ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ñ‚Ñ€Ğ°ÑÑĞ¸Ñ€Ğ¾Ğ²ĞºĞ° Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ½Ñ‹Ñ… Ñ€ĞµĞ¿Ğ»Ğ¸Ğº

ğŸ”¥ v16.13: ĞšĞ Ğ˜Ğ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ™ FIX RAW_SPEAKER_ID SYNC Ğ’ CLASSIFICATION
- ĞŸÑ€Ğ¸ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¸ speaker Ğ¢ĞĞšĞ–Ğ• Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ÑĞµÑ‚ÑÑ raw_speaker_id
- Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ñ‹Ğ¹ Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³ speaker_roles Ğ´Ğ»Ñ ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸
"""

# Version: v17.5
# Last updated: 2026-02-19
# ğŸ†• v17.5: Ğ Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ½Ñ‹Ğ¹ DEBUG Ğ´Ğ»Ñ Ğ´Ğ¸Ğ°Ğ³Ğ½Ğ¾ÑÑ‚Ğ¸ĞºĞ¸ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ğ¾Ğ²

import re
from core.config import SPEAKER_CLASSIFICATION_CONFIDENCE_THRESHOLD, SPEAKER_CLASSIFICATION_MIN_WORDS

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ’Ğ¡ĞŸĞĞœĞĞ“ĞĞ¢Ğ•Ğ›Ğ¬ĞĞ«Ğ• Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ˜ (Ğ±ĞµĞ· Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def is_journalist_addressing_speaker(text, word_count):
    """ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚, ÑĞ²Ğ»ÑĞµÑ‚ÑÑ Ğ»Ğ¸ Ñ‚ĞµĞºÑÑ‚ Ğ¾Ğ±Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸ĞµĞ¼ Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚Ğ° Ğº Ğ¡Ğ¿Ğ¸ĞºĞµÑ€Ñƒ"""
    text_lower = text.lower()

    journalist_addressing_patterns = [
        r'\b(?:Ñ…Ğ¾Ñ€Ğ¾ÑˆĞ¾|Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ½Ğ¾|Ğ¿Ğ¾Ğ½ÑÑ‚Ğ½Ğ¾|ÑÑĞ½Ğ¾|ÑĞ¿Ğ°ÑĞ¸Ğ±Ğ¾|Ğ±Ğ»Ğ°Ğ³Ğ¾Ğ´Ğ°Ñ€Ñ)\b',
        r'\b(?:Ğ´Ğ°Ğ²Ğ°Ğ¹Ñ‚Ğµ|Ğ¼Ğ¾Ğ¶ĞµÑ‚Ğµ|Ñ€Ğ°ÑÑĞºĞ°Ğ¶Ğ¸Ñ‚Ğµ|Ğ¾Ğ¿Ğ¸ÑˆĞ¸Ñ‚Ğµ|Ğ¾Ğ±ÑŠÑÑĞ½Ğ¸Ñ‚Ğµ)\b',
        r'\b(?:Ğ½Ğ¸Ñ‡ĞµĞ³Ğ¾\s+ÑÑ‚Ñ€Ğ°ÑˆĞ½Ğ¾Ğ³Ğ¾|Ğ²ÑĞµ\s+(?:Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾|Ñ…Ğ¾Ñ€Ğ¾ÑˆĞ¾|Ğ²\s+Ğ¿Ğ¾Ñ€ÑĞ´ĞºĞµ))\b',
        r'\b(?:Ğ½Ğµ\s+ÑÑ‚Ñ€Ğ°ÑˆĞ½Ğ¾|Ğ½Ğµ\s+Ğ±ĞµĞ´Ğ°|Ğ»Ğ°Ğ´Ğ½Ğ¾|Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾)\b',
        r'\b(?:Ğ¿Ñ€ĞµĞºÑ€Ğ°ÑĞ½Ğ¾|Ğ·Ğ°Ğ¼ĞµÑ‡Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾|Ğ²ĞµĞ»Ğ¸ĞºĞ¾Ğ»ĞµĞ¿Ğ½Ğ¾)\b',
    ]

    has_journalist_addressing = any(
        re.search(p, text_lower) for p in journalist_addressing_patterns
    )

    speaker_monologue_antipatterns = [
        r'\bÑ\s+(?:Ğ´ÑƒĞ¼Ğ°Ñ|ÑÑ‡Ğ¸Ñ‚Ğ°Ñ|Ğ¿Ğ¾Ğ»Ğ°Ğ³Ğ°Ñ|ÑƒĞ²ĞµÑ€ĞµĞ½|Ğ·Ğ½Ğ°Ñ)\b',
        r'\b(?:Ğ´ĞµĞ»Ğ¾\s+Ğ²\s+Ñ‚Ğ¾Ğ¼|ÑÑƒÑ‚ÑŒ\s+Ğ²\s+Ñ‚Ğ¾Ğ¼|Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°\s+Ğ²\s+Ñ‚Ğ¾Ğ¼)\b',
        r'\b(?:Ğ²Ğ¾-Ğ¿ĞµÑ€Ğ²Ñ‹Ñ…|Ğ²Ğ¾-Ğ²Ñ‚Ğ¾Ñ€Ñ‹Ñ…|Ğ²-Ñ‚Ñ€ĞµÑ‚ÑŒĞ¸Ñ…)\b',
        r'\b(?:Ğ¿Ğ¾ÑÑ‚Ğ¾Ğ¼Ñƒ|ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾|Ñ‚Ğ°ĞºĞ¸Ğ¼\s+Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ¼)\b',
    ]

    has_speaker_monologue = any(
        re.search(p, text_lower) for p in speaker_monologue_antipatterns
    )

    return (word_count < 15 and 
            has_journalist_addressing and 
            not has_speaker_monologue)

def has_speaker_monologue_markers(text):
    """ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚ Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ Ğ¼Ğ°Ñ€ĞºĞµÑ€Ğ¾Ğ² Ğ¼Ğ¾Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ° Ğ¡Ğ¿Ğ¸ĞºĞµÑ€Ğ°"""
    text_lower = text.lower()

    speaker_monologue_patterns = [
        r'\bÑ\s+(?:Ğ´ÑƒĞ¼Ğ°Ñ|ÑÑ‡Ğ¸Ñ‚Ğ°Ñ|Ğ¿Ğ¾Ğ»Ğ°Ğ³Ğ°Ñ|ÑƒĞ²ĞµÑ€ĞµĞ½|ÑƒĞ±ĞµĞ¶Ğ´ĞµĞ½|ÑƒĞ±ĞµĞ¶Ğ´Ñ‘Ğ½|Ğ·Ğ½Ğ°Ñ|Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ñ|Ğ²Ğ¸Ğ¶Ñƒ|Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²Ğ»ÑÑ|Ğ¿Ñ€ĞµĞ´Ğ¿Ğ¾Ğ»Ğ°Ğ³Ğ°Ñ)\b',
        r'\b(?:Ñƒ\s+Ğ¼ĞµĞ½Ñ|Ğ¼Ğ½Ğµ|Ğ¼ĞµĞ½Ñ|Ğ¼Ğ½Ğ¾Ğ¹|Ğ¼Ğ½Ğ¾Ñ|Ğ¼Ğ¾Ñ‘|Ğ¼Ğ¾Ñ|Ğ¼Ğ¾Ğ¸|Ğ¼Ğ¾Ğµ|Ğ¼Ğ¾ĞµĞ³Ğ¾|Ğ¼Ğ¾ĞµĞ¹|Ğ¼Ğ¾Ğ¸Ñ…|Ğ¼Ğ¾Ğ¸Ğ¼|Ğ¼Ğ¾Ğ¸Ğ¼Ğ¸)\b',
        r'\b(?:Ğ´ĞµĞ»Ğ¾\s+Ğ²\s+Ñ‚Ğ¾Ğ¼|ÑÑƒÑ‚ÑŒ\s+Ğ²\s+Ñ‚Ğ¾Ğ¼|Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ°\s+Ğ²\s+Ñ‚Ğ¾Ğ¼|Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ\s+Ğ²\s+Ñ‚Ğ¾Ğ¼|ÑĞ¼Ñ‹ÑĞ»\s+Ğ²\s+Ñ‚Ğ¾Ğ¼)\b',
        r'\b(?:Ğ²Ğ¾-Ğ¿ĞµÑ€Ğ²Ñ‹Ñ…|Ğ²Ğ¾-Ğ²Ñ‚Ğ¾Ñ€Ñ‹Ñ…|Ğ²-Ñ‚Ñ€ĞµÑ‚ÑŒĞ¸Ñ…|Ğ²-Ñ‡ĞµÑ‚Ğ²ĞµÑ€Ñ‚Ñ‹Ñ…|Ğ²-Ñ‡ĞµÑ‚Ğ²Ñ‘Ñ€Ñ‚Ñ‹Ñ…|Ğ²-Ğ¿ÑÑ‚Ñ‹Ñ…)\b',
        r'\b(?:Ğ¿Ğ¾ÑÑ‚Ğ¾Ğ¼Ñƒ|ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾|Ñ‚Ğ°ĞºĞ¸Ğ¼\s+Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ¼|Ğ²\s+ÑĞ²ÑĞ·Ğ¸\s+Ñ\s+ÑÑ‚Ğ¸Ğ¼|Ğ¾Ñ‚ÑÑĞ´Ğ°|Ğ¸Ğ·\s+ÑÑ‚Ğ¾Ğ³Ğ¾\s+ÑĞ»ĞµĞ´ÑƒĞµÑ‚)\b',
        r'\b(?:Ğ½Ğ°\s+Ğ¼Ğ¾Ğ¹\s+Ğ²Ğ·Ğ³Ğ»ÑĞ´|Ğ¿Ğ¾\s+Ğ¼Ğ¾ĞµĞ¼Ñƒ\s+Ğ¼Ğ½ĞµĞ½Ğ¸Ñ|ĞºĞ°Ğº\s+Ğ¼Ğ½Ğµ\s+ĞºĞ°Ğ¶ĞµÑ‚ÑÑ|Ñ\s+Ğ±Ñ‹\s+ÑĞºĞ°Ğ·Ğ°Ğ»|Ñ\s+Ğ±Ñ‹\s+Ğ¾Ñ‚Ğ¼ĞµÑ‚Ğ¸Ğ»)\b',
        r'\bÑ\s+(?:Ğ¼Ğ¾Ğ³Ñƒ|Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½|Ñ…Ğ¾Ñ‡Ñƒ|Ğ±ÑƒĞ´Ñƒ|ÑÑ‚Ğ°Ğ»|Ğ½Ğ°Ñ‡Ğ°Ğ»|Ğ¿Ñ‹Ñ‚Ğ°ÑÑÑŒ|ÑÑ‚Ğ°Ñ€Ğ°ÑÑÑŒ)\b',
    ]

    return any(re.search(p, text_lower) for p in speaker_monologue_patterns)

def get_monologue_duration_at_index(segments, end_index, speaker):
    """
    ğŸ”§ v16.9: Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµÑ‚ Ğ´Ğ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ Ğ¼Ğ¾Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ° ÑĞ¿Ğ¸ĞºĞµÑ€Ğ°, Ğ·Ğ°ĞºĞ°Ğ½Ñ‡Ğ¸Ğ²Ğ°ÑÑ‰ĞµĞ³Ğ¾ÑÑ Ğ½Ğ° end_index
    """
    if end_index < 0 or end_index >= len(segments):
        return 0
    
    if segments[end_index].get('speaker') != speaker:
        return 0
    
    # ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ğ¼ Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ¾ Ğ¼Ğ¾Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ°
    monologue_start_idx = end_index
    for i in range(end_index, -1, -1):
        if segments[i].get('speaker') != speaker:
            monologue_start_idx = i + 1
            break
        if i == 0:
            monologue_start_idx = 0
    
    # Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ÑĞµĞ¼ Ğ´Ğ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ
    duration = (segments[end_index].get('end', 0) - 
               segments[monologue_start_idx].get('start', 0))
    return duration

def is_continuation_phrase(text):
    """
    ğŸ†• v16.8: ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚, ÑĞ²Ğ»ÑĞµÑ‚ÑÑ Ğ»Ğ¸ Ñ„Ñ€Ğ°Ğ·Ğ° Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½Ğ¸ĞµĞ¼ Ğ¼Ğ¾Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ°
    """
    text_lower = text.lower().strip()
    
    continuation_patterns = [
        r'^Ñ‚Ğ¾\s+ĞµÑÑ‚ÑŒ\b',
        r'^Ğ²\s+Ñ‡Ğ°ÑÑ‚Ğ½Ğ¾ÑÑ‚Ğ¸\b',
        r'^ĞºÑ€Ğ¾Ğ¼Ğµ\s+Ñ‚Ğ¾Ğ³Ğ¾\b',
        r'^Ğ¿Ğ¾Ğ¼Ğ¸Ğ¼Ğ¾\s+ÑÑ‚Ğ¾Ğ³Ğ¾\b',
        r'^Ñ‚Ğ°ĞºĞ¶Ğµ\b',
        r'^Ğ±Ğ¾Ğ»ĞµĞµ\s+Ñ‚Ğ¾Ğ³Ğ¾\b',
        r'^Ğº\s+Ñ‚Ğ¾Ğ¼Ñƒ\s+Ğ¶Ğµ\b',
        r'^Ğ²Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ¾Ğº\b',
        r'^Ğ¿Ñ€Ğ¸\s+ÑÑ‚Ğ¾Ğ¼\b',
        r'^Ğ¾Ğ´Ğ½Ğ°ĞºĞ¾\b',
        r'^Ğ½Ğ¾\b',
        r'^Ğ°\s+(?:Ñ‚Ğ°ĞºĞ¶Ğµ|ĞµÑ‰Ğµ|ĞµÑ‰Ñ‘)\b',
    ]
    
    return any(re.match(p, text_lower) for p in continuation_patterns)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ†• v17.5: Ğ ĞĞ¡Ğ¨Ğ˜Ğ Ğ•ĞĞĞ«Ğ™ DEBUG
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def calculate_speaker_score_v17_5(text, current_speaker, debug_mode=False):
    """
    ğŸ†• v17.5: Ğ Ğ°ÑÑÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ²ĞµÑĞ° Ñ Ğ”Ğ•Ğ¢ĞĞ›Ğ¬ĞĞ«Ğœ DEBUG
    
    Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚:
        (j_score, s_score, details, matched_patterns)
        
    matched_patterns = [
        {
            'type': 'Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚' | 'Ğ¡Ğ¿Ğ¸ĞºĞµÑ€' | 'Ğ—ĞĞ©Ğ˜Ğ¢Ğ',
            'category': 'addressing' | 'monologue' | ...,
            'pattern': regex,
            'weight': int,
            'matched_text': str  # ğŸ†• Ğ§Ğ¢Ğ Ğ¸Ğ¼ĞµĞ½Ğ½Ğ¾ ÑĞ¾Ğ²Ğ¿Ğ°Ğ»Ğ¾
        },
        ...
    ]
    """
    
    # ĞŸĞ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹ Ğ´Ğ»Ñ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚Ğ°
    JOURNALIST_PATTERNS = {
        'addressing': [
            (r'\b(Ñ€Ğ°ÑÑĞºĞ°Ğ¶Ğ¸Ñ‚Ğµ|Ğ¾Ğ±ÑŠÑÑĞ½Ğ¸Ñ‚Ğµ|Ğ¿Ğ¾ÑÑĞ½Ğ¸Ñ‚Ğµ|ÑƒÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ñ‚Ğµ|ÑĞºĞ°Ğ¶Ğ¸Ñ‚Ğµ)\b', 3),
            (r'\b(Ğ²Ñ‹\s+(?:Ğ¼Ğ¾Ğ¶ĞµÑ‚Ğµ|Ğ·Ğ½Ğ°ĞµÑ‚Ğµ|Ğ¿Ğ¾Ğ¼Ğ½Ğ¸Ñ‚Ğµ|ÑÑ‡Ğ¸Ñ‚Ğ°ĞµÑ‚Ğµ|Ğ´ÑƒĞ¼Ğ°ĞµÑ‚Ğµ))\b', 2),
            (r'\b(ĞºĞ°Ğº\s+Ğ²Ñ‹\s+(?:ÑÑ‡Ğ¸Ñ‚Ğ°ĞµÑ‚Ğµ|Ğ´ÑƒĞ¼Ğ°ĞµÑ‚Ğµ|Ğ¾Ñ†ĞµĞ½Ğ¸Ğ²Ğ°ĞµÑ‚Ğµ))\b', 3),
            (r'\bĞ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²ÑŒÑ‚ĞµÑÑŒ\b', 5),
            (r'\b(Ğ´Ğ°Ğ²Ğ°Ğ¹Ñ‚Ğµ|Ğ¿ĞµÑ€ĞµÑ…Ğ¾Ğ´Ğ¸Ğ¼|Ğ½Ğ°Ñ‡Ğ½ĞµĞ¼|Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ¸Ğ¼)\b', 2),
        ],
        'questions': [
            (r'\?$', 1),
            (r'^(ĞºĞ°Ğº|Ğ¿Ğ¾Ñ‡ĞµĞ¼Ñƒ|Ğ·Ğ°Ñ‡ĞµĞ¼|ĞºĞ¾Ğ³Ğ´Ğ°|Ğ³Ğ´Ğµ|ĞºÑ‚Ğ¾|Ñ‡Ñ‚Ğ¾)\s', 2),
            (r'\b(Ğ½Ğµ\s+Ñ‚Ğ°Ğº|Ğ²ĞµÑ€Ğ½Ğ¾|Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ¾)\s*\?', 2),
        ],
        'commands': [
            (r'\b(ÑĞ¼Ğ¾Ñ‚Ñ€Ğ¸Ğ¼|ÑĞ»ÑƒÑˆĞ°ĞµĞ¼|Ğ¾Ñ‚Ğ²ĞµÑ‡Ğ°ĞµĞ¼)\s+(?:Ğ½Ğ°|Ğ²)', 2),
            (r'\bĞ¼Ñ‹\s+(?:ÑĞµĞ¹Ñ‡Ğ°Ñ|Ñ‚ĞµĞ¿ĞµÑ€ÑŒ)\s+(?:Ğ¾Ñ‚Ğ²ĞµÑ‡Ğ°ĞµĞ¼|Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ¸Ğ¼|Ğ¾Ğ±ÑÑƒĞ¶Ğ´Ğ°ĞµĞ¼)\b', 2),
        ],
    }

    # ĞŸĞ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹ Ğ´Ğ»Ñ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ Ğ¡Ğ¿Ğ¸ĞºĞµÑ€Ğ°
    SPEAKER_PATTERNS = {
        'monologue': [
            (r'\b(Ñƒ\s+Ğ¼ĞµĞ½Ñ|Ğ¼Ğ½Ğµ|Ñ\s+(?:ÑÑ‡Ğ¸Ñ‚Ğ°Ñ|Ğ´ÑƒĞ¼Ğ°Ñ|Ğ¿Ğ¾Ğ»Ğ°Ğ³Ğ°Ñ|Ğ¿Ğ¾Ğ¼Ğ½Ñ))\b', 2),
            (r'\b(Ğ½Ğ°\s+Ğ¼Ğ¾Ğ¹\s+Ğ²Ğ·Ğ³Ğ»ÑĞ´|Ğ¿Ğ¾\s+Ğ¼Ğ¾ĞµĞ¼Ñƒ\s+Ğ¼Ğ½ĞµĞ½Ğ¸Ñ)\b', 3),
            (r'\b(Ğ¼Ğ¾Ñ‘|Ğ¼Ğ¾Ñ|Ğ¼Ğ¾Ğ¹|Ğ¼Ğ¾Ğ¸)\s+(?:Ğ¼Ğ½ĞµĞ½Ğ¸Ğµ|Ğ¾Ğ¿Ñ‹Ñ‚|Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ|Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°)\b', 3),
        ],
        'facts': [
            (r'\b\d{4}\s*Ğ³Ğ¾Ğ´', 1),
            (r'\b(?:Ğ¾Ğ¿ĞµÑ€Ğ°Ñ†Ğ¸Ñ|ÑÑ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ|Ğ±Ğ¸Ñ‚Ğ²Ğ°|Ñ„Ñ€Ğ¾Ğ½Ñ‚|Ğ°Ñ€Ğ¼Ğ¸Ñ)\b', 1),
        ],
    }

    # Ğ—Ğ°Ñ‰Ğ¸Ñ‚Ñ‹ Ğ¾Ñ‚ Ğ»Ğ¾Ğ¶Ğ½Ñ‹Ñ… ÑÑ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°Ğ½Ğ¸Ğ¹
    PROTECTIONS = {
        'journalist_not_speaker': [
            (r'\bĞ¼Ñ‹\s+(?:ÑĞµĞ¹Ñ‡Ğ°Ñ|Ñ‚ĞµĞ¿ĞµÑ€ÑŒ|Ñ‚ÑƒÑ‚|Ğ·Ğ´ĞµÑÑŒ)\s', -3),
            (r'\bĞ²Ñ‹\s+(?:Ğ¿Ñ€ĞµĞ´ÑÑ‚Ğ°Ğ²ÑŒÑ‚ĞµÑÑŒ|Ñ€Ğ°ÑÑĞºĞ°Ğ¶Ğ¸Ñ‚Ğµ|Ğ¾Ğ±ÑŠÑÑĞ½Ğ¸Ñ‚Ğµ)\b', -5),
        ],
    }
    
    text_lower = text.lower()
    journalist_score = 0
    speaker_score = 0
    details = []
    matched_patterns = []  # ğŸ†• Ğ”ĞµÑ‚Ğ°Ğ»Ğ¸ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğ¹

    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹ Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚Ğ°
    for category, patterns in JOURNALIST_PATTERNS.items():
        for pattern, weight in patterns:
            match = re.search(pattern, text_lower, re.I)
            if match:
                journalist_score += weight
                details.append(f"J:{category}:+{weight}")
                matched_patterns.append({
                    'type': 'Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚',
                    'category': category,
                    'pattern': pattern,
                    'weight': weight,
                    'matched_text': match.group(0)  # ğŸ†• Ğ§Ğ¢Ğ Ğ¸Ğ¼ĞµĞ½Ğ½Ğ¾ ÑĞ¾Ğ²Ğ¿Ğ°Ğ»Ğ¾
                })

    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹ Ğ¡Ğ¿Ğ¸ĞºĞµÑ€Ğ°
    for category, patterns in SPEAKER_PATTERNS.items():
        for pattern, weight in patterns:
            match = re.search(pattern, text_lower, re.I)
            if match:
                speaker_score += weight
                details.append(f"S:{category}:+{weight}")
                matched_patterns.append({
                    'type': 'Ğ¡Ğ¿Ğ¸ĞºĞµÑ€',
                    'category': category,
                    'pattern': pattern,
                    'weight': weight,
                    'matched_text': match.group(0)  # ğŸ†• Ğ§Ğ¢Ğ Ğ¸Ğ¼ĞµĞ½Ğ½Ğ¾ ÑĞ¾Ğ²Ğ¿Ğ°Ğ»Ğ¾
                })

    # ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ÑĞµĞ¼ Ğ·Ğ°Ñ‰Ğ¸Ñ‚Ñ‹
    for pattern, weight in PROTECTIONS['journalist_not_speaker']:
        match = re.search(pattern, text_lower, re.I)
        if match:
            speaker_score += weight
            details.append(f"PROTECT:S:{weight}")
            matched_patterns.append({
                'type': 'Ğ—ĞĞ©Ğ˜Ğ¢Ğ',
                'category': 'protection',
                'pattern': pattern,
                'weight': weight,
                'matched_text': match.group(0)
            })

    return journalist_score, speaker_score, details, matched_patterns

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ’Ğ•Ğ¡ĞĞ’ĞĞ¯ ĞšĞ›ĞĞ¡Ğ¡Ğ˜Ğ¤Ğ˜ĞšĞĞ¦Ğ˜Ğ¯ v17.5
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def apply_speaker_classification_v15(segments, speaker_surname, speaker_roles, debug=False):
    """
    v17.5: Ğ’ĞµÑĞ¾Ğ²Ğ°Ñ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ¾Ğ² Ñ Ğ ĞĞ¡Ğ¨Ğ˜Ğ Ğ•ĞĞĞ«Ğœ DEBUG
    
    ğŸ†• v17.5 Ğ ĞĞ¡Ğ¨Ğ˜Ğ Ğ•ĞĞĞ«Ğ™ DEBUG:
    - ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½ÑƒÑ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¼ ÑÑ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ²ÑˆĞµĞ¼ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ğµ
    - Ğ’Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ñ‚ matched_text Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ñ
    - Ğ¡Ğ¿ĞµÑ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ñ‚Ñ€Ğ°ÑÑĞ¸Ñ€Ğ¾Ğ²ĞºĞ° Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ½Ñ‹Ñ… Ñ€ĞµĞ¿Ğ»Ğ¸Ğº
    
    ğŸ”¥ v16.13 ĞšĞ Ğ˜Ğ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ™ FIX:
    - ĞŸÑ€Ğ¸ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¸ speaker Ğ¢ĞĞšĞ–Ğ• Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ÑĞµÑ‚ÑÑ raw_speaker_id
    - Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ñ‹Ğ¹ Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³ speaker_roles (Ğ˜ÑĞ°ĞµĞ² â†’ SPEAKER_01)
    
    ğŸ”§ v16.9 Ğ¤Ğ˜ĞšĞ¡:
    - Continuation phrases Ñ‚ĞµĞ¿ĞµÑ€ÑŒ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑÑÑ‚ÑÑ Ğ¾Ñ‚Ğ½Ğ¾ÑĞ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ĞŸĞ Ğ•Ğ”Ğ«Ğ”Ğ£Ğ©Ğ•Ğ“Ğ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ°

    Args:
        segments: Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ¿Ğ¾ÑĞ»Ğµ merge_replicas()
        speaker_surname: Ğ¤Ğ°Ğ¼Ğ¸Ğ»Ğ¸Ñ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ³Ğ¾ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ°
        speaker_roles: Dict SPEAKER_XX â†’ Ñ€Ğ¾Ğ»ÑŒ (Ğ´Ğ»Ñ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ğ¾Ğ¹ ĞºĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ°Ñ†Ğ¸Ğ¸)
        debug: Ğ•ÑĞ»Ğ¸ True, Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ñ‚ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½ÑƒÑ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ

    Returns:
        (segments, stats) - Ğ¼Ğ¾Ğ´Ğ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¸ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°
    """
    
    # ğŸ†• v16.13: Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ñ‹Ğ¹ Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³ speaker â†’ raw_speaker_id
    reverse_roles = {}
    for raw_id, role in speaker_roles.items():
        reverse_roles[role] = raw_id
    
    if debug:
        print(f"\nğŸ”„ v17.5: ĞĞ±Ñ€Ğ°Ñ‚Ğ½Ñ‹Ğ¹ Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³ ÑĞ¾Ğ·Ğ´Ğ°Ğ½:")
        for role, raw_id in reverse_roles.items():
            print(f"   {role} â†’ {raw_id}")

    # Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°
    stats = {
        'total_checked': 0,
        'changed_to_journalist': 0,
        'changed_to_speaker': 0,
        'skipped_protections': 0,
        'skipped_monologue_context': 0,
        'continuation_phrases_fixed': 0,
        'raw_speaker_id_synced': 0,
        'details': []
    }

    if debug:
        print("\n" + "="*80)
        print("ğŸ¯ v17.5: Ğ’Ğ•Ğ¡ĞĞ’ĞĞ¯ ĞšĞ›ĞĞ¡Ğ¡Ğ˜Ğ¤Ğ˜ĞšĞĞ¦Ğ˜Ğ¯ + Ğ ĞĞ¡Ğ¨Ğ˜Ğ Ğ•ĞĞĞ«Ğ™ DEBUG")
        print("="*80)

    for i, seg in enumerate(segments):
        text = seg.get('text', '').strip()
        current_speaker = seg.get('speaker', '')
        time = seg.get('time', '00:00:00')
        word_count = len(text.split())

        # ĞŸÑ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğµ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ¸ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ°
        if word_count < SPEAKER_CLASSIFICATION_MIN_WORDS or current_speaker == 'ĞĞ¿ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€':
            continue

        stats['total_checked'] += 1

        # ğŸ”§ v16.9: FIXED CONTINUATION PHRASE LOGIC
        if i > 0 and is_continuation_phrase(text):
            prev_seg = segments[i - 1]
            prev_speaker = prev_seg.get('speaker')
            
            prev_monologue_duration = get_monologue_duration_at_index(segments, i - 1, prev_speaker)
            
            if prev_monologue_duration > 30:
                if current_speaker != prev_speaker:
                    if debug:
                        print(f"\n  ğŸ”§ [{time}] CONTINUATION PHRASE FIX")
                        print(f"     {current_speaker} â†’ {prev_speaker} (Ğ¿Ğ¾ÑĞ»Ğµ Ğ¼Ğ¾Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ° {prev_monologue_duration:.1f}s)")
                        print(f"     Ğ¢ĞµĞºÑÑ‚: {text[:80]}...")
                    
                    seg['speaker'] = prev_speaker
                    seg['raw_speaker_id'] = reverse_roles.get(prev_speaker, seg.get('raw_speaker_id'))
                    
                    stats['continuation_phrases_fixed'] += 1
                    stats['raw_speaker_id_synced'] += 1
                    stats['changed_to_speaker'] += 1 if prev_speaker != 'Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚' else 0
                    stats['changed_to_journalist'] += 1 if prev_speaker == 'Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚' else 0
                    continue
                else:
                    if debug:
                        print(f"\n  ğŸ›¡ï¸ [{time}] CONTINUATION PHRASE (ÑƒĞ¶Ğµ Ğ²ĞµÑ€Ğ½Ğ¾)")
                        print(f"     Ğ¡Ğ¿Ğ¸ĞºĞµÑ€: {current_speaker} (Ğ¿Ğ¾ÑĞ»Ğµ Ğ¼Ğ¾Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ° {prev_monologue_duration:.1f}s)")
                    stats['skipped_monologue_context'] += 1
                    continue

        # ğŸ†• v17.5: Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ½Ğ¾Ğ²ÑƒÑ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ñ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¼ DEBUG
        j_score, s_score, details, matched_patterns = calculate_speaker_score_v17_5(
            text, current_speaker, debug_mode=debug
        )

        # ğŸ†• v17.5: Ğ ĞĞ¡Ğ¨Ğ˜Ğ Ğ•ĞĞĞ«Ğ™ DEBUG Ğ´Ğ»Ñ Ğ²ÑĞµÑ… Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¹ Ğ˜Ğ›Ğ˜ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ½Ñ‹Ñ… Ñ€ĞµĞ¿Ğ»Ğ¸Ğº
        show_detailed_debug = (
            debug and (
                j_score > s_score + SPEAKER_CLASSIFICATION_CONFIDENCE_THRESHOLD or
                s_score > j_score + SPEAKER_CLASSIFICATION_CONFIDENCE_THRESHOLD or
                # ğŸ†• DEBUG BAG_F: Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°Ñ‚ÑŒ ÑĞ»ÑƒÑ‡Ğ°Ğ¸ Ğ³Ğ´Ğµ ÑÑ‡Ñ‘Ñ‚ J>0 Ğ½Ğ¾ Ğ±ĞµĞ· Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ
                (current_speaker == speaker_surname and j_score > 0 and j_score <= s_score + SPEAKER_CLASSIFICATION_CONFIDENCE_THRESHOLD)
            )
        ) or "Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ¸Ñ‰ Ñ‚Ğ°Ğº Ğ¸ ÑĞºĞ°Ğ·Ğ°Ğ»" in text.lower()
        
        if show_detailed_debug:
            print(f"\n  ğŸ” [{time}] Ğ”Ğ•Ğ¢ĞĞ›Ğ¬ĞĞ«Ğ™ ĞĞĞĞ›Ğ˜Ğ—")
            print(f"     Ğ¢ĞµĞºÑƒÑ‰Ğ¸Ğ¹ ÑĞ¿Ğ¸ĞºĞµÑ€: {current_speaker}")
            print(f"     Ğ¢ĞµĞºÑÑ‚: {text[:100]}...")
            
            if matched_patterns:
                print(f"     \n     Ğ¡Ğ¾Ğ²Ğ¿Ğ°Ğ²ÑˆĞ¸Ğµ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹:")
                for p in matched_patterns:
                    print(f"       â€¢ {p['type']:10s} | {p['category']:12s} | {p['weight']:+2d} | '{p['matched_text']}'")
            else:
                print(f"     \n     Ğ¡Ğ¾Ğ²Ğ¿Ğ°Ğ²ÑˆĞ¸Ğµ Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹: ĞĞ•Ğ¢")
            
            print(f"     \n     Ğ˜Ğ¢ĞĞ“Ğ: J={j_score}, S={s_score} (Ğ¿Ğ¾Ñ€Ğ¾Ğ³={SPEAKER_CLASSIFICATION_CONFIDENCE_THRESHOLD})")
            print(f"     Ğ Ğ•Ğ¨Ğ•ĞĞ˜Ğ•: ", end="")
            
            if current_speaker == 'Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚' and s_score > j_score + SPEAKER_CLASSIFICATION_CONFIDENCE_THRESHOLD:
                print(f"Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚ â†’ {speaker_surname} (S > J + {SPEAKER_CLASSIFICATION_CONFIDENCE_THRESHOLD})")
            elif current_speaker == speaker_surname and j_score > s_score + SPEAKER_CLASSIFICATION_CONFIDENCE_THRESHOLD:
                print(f"{speaker_surname} â†’ Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚ (J > S + {SPEAKER_CLASSIFICATION_CONFIDENCE_THRESHOLD})")
            else:
                print(f"Ğ‘Ğ•Ğ— Ğ˜Ğ—ĞœĞ•ĞĞ•ĞĞ˜Ğ™ (Ñ€Ğ°Ğ·Ğ½Ğ¸Ñ†Ğ° < {SPEAKER_CLASSIFICATION_CONFIDENCE_THRESHOLD})")

        # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ğ¿Ğ¾Ñ€Ğ¾Ğ³ Ğ´Ğ»Ñ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ
        CONFIDENCE_THRESHOLD = SPEAKER_CLASSIFICATION_CONFIDENCE_THRESHOLD

        # ğŸ†• DEBUG BAG_E: Ğ¼Ğ¸ĞºÑ€Ğ¾-Ñ„Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚Ñ‹ ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ°ĞµĞ¼
        if word_count < SPEAKER_CLASSIFICATION_MIN_WORDS:
            if debug:
                print(f"\n  ğŸ”• [{time}] MICRO-FRAGMENT SKIP (ÑĞ»Ğ¾Ğ²={word_count} < {SPEAKER_CLASSIFICATION_MIN_WORDS})")
                print(f"     Ğ¡Ğ¿Ğ¸ĞºĞµÑ€: {current_speaker} | Ğ¢ĞµĞºÑÑ‚: '{text}'")
                # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ ÑĞ¾ÑĞµĞ´ĞµĞ¹ â€” Ğ¿Ğ¾Ğ´Ğ¾Ğ·Ñ€ĞµĞ²Ğ°ĞµĞ¼ island error
                if i > 0 and i < len(segments) - 1:
                    prev_spk = segments[i-1].get('speaker', '?')
                    next_spk = segments[i+1].get('speaker', '?') if i+1 < len(segments) else '?'
                    if prev_spk == next_spk and prev_spk != current_speaker:
                        print(f"     ğŸ”´ ISLAND SUSPICION: {prev_spk} â†’ [{current_speaker}] â†’ {next_spk}")
            continue

        # Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚ â†’ Ğ¡Ğ¿Ğ¸ĞºĞµÑ€
        if current_speaker == 'Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚' and s_score > j_score + CONFIDENCE_THRESHOLD:
            if not show_detailed_debug and debug:
                print(f"\n  ğŸ”„ [{time}] Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚ â†’ {speaker_surname}")
                print(f"     Ğ’ĞµÑĞ°: J={j_score}, S={s_score}")
                print(f"     ĞŸĞ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹: {', '.join(details)}")
                print(f"     Ğ¢ĞµĞºÑÑ‚: {text[:80]}...")

            seg['speaker'] = speaker_surname
            seg['raw_speaker_id'] = reverse_roles.get(speaker_surname, seg.get('raw_speaker_id'))
            
            stats['changed_to_speaker'] += 1
            stats['raw_speaker_id_synced'] += 1
            stats['details'].append({
                'time': time,
                'from': 'Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚',
                'to': speaker_surname,
                'j_score': j_score,
                's_score': s_score,
                'text': text[:100]
            })

        # Ğ¡Ğ¿Ğ¸ĞºĞµÑ€ â†’ Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚
        elif current_speaker == speaker_surname and j_score > s_score + CONFIDENCE_THRESHOLD:
            if not show_detailed_debug and debug:
                print(f"\n  ğŸ”„ [{time}] {speaker_surname} â†’ Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚")
                print(f"     Ğ’ĞµÑĞ°: J={j_score}, S={s_score}")
                print(f"     ĞŸĞ°Ñ‚Ñ‚ĞµÑ€Ğ½Ñ‹: {', '.join(details)}")
                print(f"     Ğ¢ĞµĞºÑÑ‚: {text[:80]}...")

            seg['speaker'] = 'Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚'
            seg['raw_speaker_id'] = reverse_roles.get('Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚', seg.get('raw_speaker_id'))
            
            stats['changed_to_journalist'] += 1
            stats['raw_speaker_id_synced'] += 1
            stats['details'].append({
                'time': time,
                'from': speaker_surname,
                'to': 'Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚',
                'j_score': j_score,
                's_score': s_score,
                'text': text[:100]
            })

    if debug:
        print("="*80)
        print(f"âœ… v17.5: ĞšĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°")
        print(f"   Ğ’ÑĞµĞ³Ğ¾ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞµĞ½Ğ¾: {stats['total_checked']}")
        print(f"   Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¾: {stats['changed_to_journalist'] + stats['changed_to_speaker']}")
        print(f"   â€¢ Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚ â†’ Ğ¡Ğ¿Ğ¸ĞºĞµÑ€: {stats['changed_to_speaker']}")
        print(f"   â€¢ Ğ¡Ğ¿Ğ¸ĞºĞµÑ€ â†’ Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚: {stats['changed_to_journalist']}")
        print(f"   â€¢ ğŸ”§ Continuation phrases Ğ¸ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¾: {stats['continuation_phrases_fixed']}")
        print(f"   â€¢ ğŸ†• raw_speaker_id ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾: {stats['raw_speaker_id_synced']}")
        print(f"   â€¢ ĞŸÑ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½Ğ¾ (Ğ·Ğ°Ñ‰Ğ¸Ñ‚Ñ‹): {stats['skipped_monologue_context'] + stats['skipped_protections']}")
        print("="*80)
        print()

    return segments, stats
