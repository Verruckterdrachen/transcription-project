#!/usr/bin/env python3
"""
transcribe_v16.py - Ğ“Ğ»Ğ°Ğ²Ğ½Ñ‹Ğ¹ Ñ„Ğ°Ğ¹Ğ» Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ° Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ğ¸ v16.12

ğŸ”¥ v16.13: ĞšĞ Ğ˜Ğ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ™ FIX RAW_SPEAKER_ID SYNC Ğ’ CLASSIFICATION
- speaker_classifier Ñ‚ĞµĞ¿ĞµÑ€ÑŒ ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ raw_speaker_id Ğ¿Ñ€Ğ¸ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¸ speaker
- ĞŸĞµÑ€ĞµĞ´Ğ°Ñ‡Ğ° speaker_roles Ğ² apply_speaker_classification_v15
- Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½ Ğ±Ğ°Ğ³: TXT Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ğ» ÑÑ‚Ğ°Ñ€Ñ‹Ğ¹ speaker Ğ¿Ğ¾ÑĞ»Ğµ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸
- ĞĞ½Ğ°Ğ»Ğ¾Ğ³Ğ¸Ñ‡Ğ½Ñ‹Ğ¹ Ñ„Ğ¸ĞºÑ v16.12, Ğ½Ğ¾ Ğ´Ğ»Ñ ÑÑ‚Ğ°Ğ¿Ğ° 7 (ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ)

ğŸ”¥ v16.12: ĞšĞ Ğ˜Ğ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ™ FIX RAW_SPEAKER_ID + VERSION Ğ’ JSON
- ĞŸÑ€Ğ¸ split Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ÑĞµÑ‚ÑÑ Ğ½Ğµ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ speaker, Ğ½Ğ¾ Ğ¸ raw_speaker_id
- Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ Ğ¿Ğ¾Ğ»Ğµ "pipeline_version" Ğ² JSON metadata
- Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½ Ğ±Ğ°Ğ³: TXT Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ğ» ÑÑ‚Ğ°Ñ€Ñ‹Ğ¹ speaker Ğ²Ğ¼ĞµÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾
- ĞŸĞµÑ€ĞµĞ´Ğ°Ñ‡Ğ° speaker_roles Ğ² split_mixed_speaker_segments

ğŸ”¥ v16.11: ĞŸĞ ĞĞ’Ğ˜Ğ›Ğ¬ĞĞĞ¯ Ğ›ĞĞ“Ğ˜ĞšĞ CONTINUATION PHRASE FIX
- Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ° Ğ»Ğ¾Ğ³Ğ¸ĞºĞ° Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ° Ğ² split_mixed_speaker_segments
- Continuation phrase Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚ÑÑ Ğ’ĞĞ£Ğ¢Ğ Ğ˜ Ñ‚ĞµĞºÑƒÑ‰ĞµĞ³Ğ¾ split (Ğ½Ğµ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ğ¹ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚)
- Ğ•ÑĞ»Ğ¸ Ğ½Ğ°ĞºĞ¾Ğ¿Ğ»ĞµĞ½Ğ¾ >80 ÑĞ»Ğ¾Ğ² â†’ continuation ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑĞµÑ‚ Ñ‚ĞµĞºÑƒÑ‰ĞµĞ³Ğ¾ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ°
- Ğ—Ğ°Ñ‰Ğ¸Ñ‚Ğ° Ğ¾Ñ‚ ÑĞ¼ĞµĞ½Ñ‹ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ° Ğ²Ğ½ÑƒÑ‚Ñ€Ğ¸ Ğ´Ğ»Ğ¸Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¼Ğ¾Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ°

ğŸ”¥ v16.8: DEBUG LOG + LONG MONOLOGUE FIX
- ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ²ÑĞµĞ³Ğ¾ pipeline Ğ² Ñ„Ğ°Ğ¹Ğ»
- Monologue context protection Ğ´Ğ»Ñ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ¾Ğ² >60s
- Continuation phrase detection
- GAP overlap protection

ğŸ”¥ v16.7: AUTO TEST-RESULTS COPY
- ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ ĞºĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ² test-results/latest/
- ĞÑ‡Ğ¸ÑÑ‚ĞºĞ° latest/ Ğ¿ĞµÑ€ĞµĞ´ ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¼ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ¾Ğ¼
- Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ĞºĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ

ğŸ“ Ğ¡Ğ¢Ğ Ğ£ĞšĞ¢Ğ£Ğ Ğ ĞŸĞĞŸĞĞš:
   Ğ¡Ğ¿Ğ¸ĞºĞµÑ€ (Ğ”Ğ”.ĞœĞœ)/
      audio/        â† WAV Ñ„Ğ°Ğ¹Ğ»Ñ‹ Ğ·Ğ´ĞµÑÑŒ
      json/         â† JSON ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑÑÑ‚ÑÑ ÑÑĞ´Ğ°
      txt/          â† TXT ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑĞµÑ‚ÑÑ ÑÑĞ´Ğ°
"""

import os
import sys
import whisper
import torch
import shutil
from pathlib import Path
from tqdm import tqdm
import warnings

# Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ñ‚ĞµĞºÑƒÑ‰ÑƒÑ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ² Ğ¿ÑƒÑ‚ÑŒ Ğ´Ğ»Ñ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¾Ğ²
sys.path.insert(0, str(Path(__file__).parent))

# Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ñ‹ Ğ¼Ğ¾Ğ´ÑƒĞ»ĞµĞ¹
from core.config import HF_TOKEN, VERSION, VERSION_NAME
from core.utils import (
    seconds_to_hms, parse_speaker_folder, adaptive_vad_threshold, gap_detector
)
from core.diarization import (
    diarize_audio, compute_speaker_stats, identify_speaker_roles, 
    align_segment_to_diarization
)
from core.alignment import align_whisper_with_diarization
from core.transcription import transcribe_audio, force_transcribe_diar_gaps

from corrections.hallucinations import (
    filter_hallucination_segments, clean_hallucinations_from_text
)
from corrections.speaker_classifier import apply_speaker_classification_v15
from corrections.boundary_fixer import (
    boundary_correction_raw, split_mixed_speaker_segments
)
from corrections.journalist_commands import detect_journalist_commands_cross_segment
from corrections.text_corrections import text_based_correction

from merge.replica_merger import merge_replicas
from merge.deduplicator import (
    remove_cross_speaker_text_duplicates, deduplicate_segments
)
from merge.validator import (
    validate_adjacent_same_speaker, auto_merge_adjacent_same_speaker,
    generate_validation_report
)

from export.json_export import export_to_json
from export.txt_export import export_to_txt, jsons_to_txt

from huggingface_hub import login

warnings.filterwarnings("ignore")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ†• v16.8: CONSOLE OUTPUT CAPTURE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class TeeOutput:
    """
    ĞšĞ»Ğ°ÑÑ Ğ´Ğ»Ñ Ğ´ÑƒĞ±Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ stdout Ğ² Ñ„Ğ°Ğ¹Ğ» Ğ¸ ĞºĞ¾Ğ½ÑĞ¾Ğ»ÑŒ Ğ¾Ğ´Ğ½Ğ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾
    (Ğ°Ğ½Ğ°Ğ»Ğ¾Ğ³ Unix ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹ 'tee')
    """
    def __init__(self, filename):
        self.terminal = sys.stdout
        self.log = open(filename, 'w', encoding='utf-8')
    
    def write(self, message):
        self.terminal.write(message)
        self.log.write(message)
    
    def flush(self):
        self.terminal.flush()
        self.log.flush()
    
    def close(self):
        if self.log:
            self.log.close()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ’Ğ•Ğ Ğ¡Ğ˜Ğ¯
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

VERSION = "16.13"
VERSION_NAME = "Critical Fix: raw_speaker_id sync in speaker_classifier + version in JSON"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ“Ğ›ĞĞ‘ĞĞ›Ğ¬ĞĞĞ¯ ĞŸĞ•Ğ Ğ•ĞœĞ•ĞĞĞĞ¯ Ğ”Ğ›Ğ¯ PIPELINE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

_pipeline = None

def get_pipeline():
    """Ğ›ĞµĞ½Ğ¸Ğ²Ğ°Ñ Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ pyannote pipeline"""
    global _pipeline
    if _pipeline is None:
        print("ğŸ¤– Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° pyannote pipeline...")
        from pyannote.audio import Pipeline
        _pipeline = Pipeline.from_pretrained("pyannote/speaker-diarization-3.1")
        if torch.cuda.is_available():
            _pipeline.to(torch.device("cuda"))
        print("âœ… Pyannote Ğ³Ğ¾Ñ‚Ğ¾Ğ² (3.1)")
    return _pipeline

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ¡ĞĞ—Ğ”ĞĞĞ˜Ğ• Ğ¡Ğ¢Ğ Ğ£ĞšĞ¢Ğ£Ğ Ğ« ĞŸĞĞŸĞĞš
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def ensure_folder_structure(base_folder):
    """
    Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ñ‚ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ Ğ¿Ğ°Ğ¿Ğ¾Ğº audio/json/txt ĞµÑĞ»Ğ¸ Ğ¸Ñ… Ğ½ĞµÑ‚

    Args:
        base_folder: Path Ğº Ğ¿Ğ°Ğ¿ĞºĞµ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ°

    Returns:
        (audio_dir, json_dir, txt_dir)
    """
    audio_dir = base_folder / "audio"
    json_dir = base_folder / "json"
    txt_dir = base_folder / "txt"

    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ¿Ğ°Ğ¿ĞºĞ¸ ĞµÑĞ»Ğ¸ Ğ¸Ñ… Ğ½ĞµÑ‚
    json_dir.mkdir(exist_ok=True)
    txt_dir.mkdir(exist_ok=True)

    return audio_dir, json_dir, txt_dir

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ĞšĞĞŸĞ˜Ğ ĞĞ’ĞĞĞ˜Ğ• Ğ’ TEST-RESULTS
# ğŸ†• v16.7: ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ ĞºĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° AI
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def copy_to_test_results(json_files, txt_path, speaker_surname, log_path=None):
    """
    ğŸ†• v16.8: ĞšĞ¾Ğ¿Ğ¸Ñ€ÑƒĞµÑ‚ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ + LOG Ğ² test-results/latest/
    
    Args:
        json_files: Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ğ¿ÑƒÑ‚ĞµĞ¹ Ğº JSON Ñ„Ğ°Ğ¹Ğ»Ğ°Ğ¼
        txt_path: ĞŸÑƒÑ‚ÑŒ Ğº TXT Ñ„Ğ°Ğ¹Ğ»Ñƒ
        speaker_surname: Ğ¤Ğ°Ğ¼Ğ¸Ğ»Ğ¸Ñ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ°
        log_path: ĞŸÑƒÑ‚ÑŒ Ğº LOG Ñ„Ğ°Ğ¹Ğ»Ñƒ (Ğ¾Ğ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾)
    """
    # ĞŸÑƒÑ‚ÑŒ Ğº test-results/latest/ Ğ¾Ñ‚Ğ½Ğ¾ÑĞ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ scripts/
    script_dir = Path(__file__).parent
    project_root = script_dir.parent
    test_results_dir = project_root / "test-results" / "latest"
    
    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ÑÑƒÑ‰ĞµÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ°Ğ¿ĞºĞ¸
    if not test_results_dir.exists():
        print(f"\nâš ï¸ ĞŸĞ°Ğ¿ĞºĞ° test-results/latest/ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°, Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ°Ñ ĞºĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ")
        return
    
    print(f"\nğŸ“Š ĞšĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ² test-results/latest/...")
    
    # ĞÑ‡Ğ¸Ñ‰Ğ°ĞµĞ¼ latest/ (ÑƒĞ´Ğ°Ğ»ÑĞµĞ¼ ÑÑ‚Ğ°Ñ€Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹)
    for old_file in test_results_dir.glob("*"):
        if old_file.is_file() and old_file.name != ".gitkeep":
            old_file.unlink()
            print(f"   ğŸ—‘ï¸ Ğ£Ğ´Ğ°Ğ»Ñ‘Ğ½: {old_file.name}")
    
    # ĞšĞ¾Ğ¿Ğ¸Ñ€ÑƒĞµĞ¼ JSON Ñ„Ğ°Ğ¹Ğ»Ñ‹
    copied_json = []
    for json_path in json_files:
        dest = test_results_dir / f"ÑĞºÑĞ¿ĞµÑ€Ñ‚_{json_path.name}"
        shutil.copy2(json_path, dest)
        copied_json.append(dest.name)
        print(f"   âœ… JSON: {dest.name}")
    
    # ĞšĞ¾Ğ¿Ğ¸Ñ€ÑƒĞµĞ¼ TXT
    if txt_path and txt_path.exists():
        dest = test_results_dir / "ÑĞºÑĞ¿ĞµÑ€Ñ‚.txt"
        shutil.copy2(txt_path, dest)
        print(f"   âœ… TXT: {dest.name}")
    
    # ğŸ†• v16.8: ĞšĞ¾Ğ¿Ğ¸Ñ€ÑƒĞµĞ¼ LOG
    if log_path and log_path.exists():
        dest = test_results_dir / "ÑĞºÑĞ¿ĞµÑ€Ñ‚_debug.log"
        shutil.copy2(log_path, dest)
        print(f"   âœ… LOG: {dest.name}")
    
    print(f"\nâœ… Ğ¡ĞºĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾ Ğ² test-results/latest/:") 
    print(f"   - JSON: {len(copied_json)} Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²")
    print(f"   - TXT: 1 Ñ„Ğ°Ğ¹Ğ»")
    if log_path and log_path.exists():
        print(f"   - LOG: 1 Ñ„Ğ°Ğ¹Ğ» (debug)")
    print(f"\nğŸ’¡ Ğ¢ĞµĞ¿ĞµÑ€ÑŒ Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¿Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¸Ñ‚ÑŒ AI Ğ¿Ñ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹:")
    print(f"   'ĞŸÑ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹ test-results/latest/'")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ĞĞ¡ĞĞĞ’ĞĞĞ¯ Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ¯ ĞĞ‘Ğ ĞĞ‘ĞĞ¢ĞšĞ˜ ĞĞ”ĞĞĞ“Ğ Ğ¤ĞĞ™Ğ›Ğ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def process_audio_file(
    wav_path,
    whisper_model,
    speaker_surname,
    json_dir,
    min_speakers=2,
    max_speakers=3,
    debug=False
):
    """
    ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ¾Ğ´Ğ¸Ğ½ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ñ„Ğ°Ğ¹Ğ»

    Args:
        wav_path: Path Ğº WAV Ñ„Ğ°Ğ¹Ğ»Ñƒ
        whisper_model: Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Whisper
        speaker_surname: Ğ¤Ğ°Ğ¼Ğ¸Ğ»Ğ¸Ñ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ³Ğ¾ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ°
        json_dir: Ğ”Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ´Ğ»Ñ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ JSON
        min_speakers: ĞœĞ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ¾Ğ²
        max_speakers: ĞœĞ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ¾Ğ²
        debug: Ğ ĞµĞ¶Ğ¸Ğ¼ Ğ¾Ñ‚Ğ»Ğ°Ğ´ĞºĞ¸

    Returns:
        Path Ğº ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ½Ğ¾Ğ¼Ñƒ JSON Ñ„Ğ°Ğ¹Ğ»Ñƒ
    """
    print(f"\nğŸ¤ {wav_path.name}")

    # ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ pipeline
    pipeline = get_pipeline()

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Ğ­Ğ¢ĞĞŸ 1: Ğ”Ğ˜ĞĞ Ğ˜Ğ—ĞĞ¦Ğ˜Ğ¯
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    diarization = diarize_audio(pipeline, wav_path, min_speakers, max_speakers)

    if not diarization:
        print(f"  âŒ Ğ”Ğ¸Ğ°Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ½Ğµ ÑƒĞ´Ğ°Ğ»Ğ°ÑÑŒ")
        return None

    # Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° ÑĞ¿Ğ¸ĞºĞµÑ€Ğ¾Ğ²
    stats = compute_speaker_stats(diarization)

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Ğ­Ğ¢ĞĞŸ 2: Ğ¢Ğ ĞĞĞ¡ĞšĞ Ğ˜Ğ‘ĞĞ¦Ğ˜Ğ¯
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    audio_duration = max(turn.end for turn, _ in diarization.itertracks())
    vad_threshold = adaptive_vad_threshold(audio_duration)
    print(f"ğŸ“ ĞĞ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ VAD: {vad_threshold}")

    result = transcribe_audio(
        whisper_model,
        wav_path,
        language="ru",
        temperature=0.0,
        beam_size=5,
        vad_threshold=vad_threshold
    )

    if not result or not result.get("segments"):
        print("  âŒ Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ Ğ½Ğµ ÑƒĞ´Ğ°Ğ»Ğ°ÑÑŒ")
        return None

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Ğ­Ğ¢ĞĞŸ 3: Ğ’Ğ«Ğ ĞĞ’ĞĞ˜Ğ’ĞĞĞ˜Ğ• Ğ¡ Ğ”Ğ˜ĞĞ Ğ˜Ğ—ĞĞ¦Ğ˜Ğ•Ğ™
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ñ€Ğ¾Ğ»Ğ¸ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ¾Ğ²
    speaker_roles = identify_speaker_roles(stats, result["segments"])

    # Ğ’Ñ‹Ñ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°ĞµĞ¼
    segments_raw = align_whisper_with_diarization(
        result["segments"],
        diarization,
        speaker_surname,
        speaker_roles
    )

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Ğ­Ğ¢ĞĞŸ 4: ĞšĞĞ Ğ Ğ•ĞšĞ¦Ğ˜Ğ˜
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    # 4.1 Ğ”ĞµÑ‚ĞµĞºÑ†Ğ¸Ñ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´ Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚Ğ°
    segments_raw, cmd_corrections = detect_journalist_commands_cross_segment(
        segments_raw, speaker_surname
    )

    # 4.2 Boundary correction
    segments_raw = boundary_correction_raw(
        segments_raw, speaker_surname, speaker_roles
    )

    # 4.3 Cross-speaker deduplication
    print("\nğŸ”„ Cross-speaker deduplication...")
    segments_raw = remove_cross_speaker_text_duplicates(segments_raw)
    print(f"âœ… ĞŸĞ¾ÑĞ»Ğµ cross-speaker dedup: {len(segments_raw)} ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²")

    # 4.4 Ğ”ĞµĞ´ÑƒĞ¿Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ñ
    print("\nğŸ”„ Ğ”ĞµĞ´ÑƒĞ¿Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ñ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²...")
    segments_raw = deduplicate_segments(segments_raw)
    print(f"âœ… ĞŸĞ¾ÑĞ»Ğµ Ğ´ĞµĞ´ÑƒĞ¿Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸: {len(segments_raw)} ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Ğ­Ğ¢ĞĞŸ 5: GAPS (ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ)
    # ğŸ†• v16.5: Ğ£Ğ¼Ğ½Ğ°Ñ Ğ°Ñ‚Ñ€Ğ¸Ğ±ÑƒÑ†Ğ¸Ñ GAP_FILLED Ğ¿Ğ¾ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¼Ñƒ ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ñƒ
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    gaps = gap_detector(segments_raw, threshold=3.0)
    gap_segments = []

    if gaps:
        print(f"\nğŸ” Ğ“ĞĞŸĞ« WHISPER:")
        for gap in gaps:
            print(f"   ğŸš¨ GAP {gap['gap_hms_start']}â€“{gap['gap_hms_end']} ({gap['duration']}s)")

        # Force transcribe gaps (v16.5: ÑƒĞ¼Ğ½Ğ°Ñ Ğ°Ñ‚Ñ€Ğ¸Ğ±ÑƒÑ†Ğ¸Ñ)
        gap_segments = force_transcribe_diar_gaps(
            whisper_model, wav_path, gaps, segments_raw, speaker_surname
        )

        if gap_segments:
            print(f"  âœ… Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ Ğ¸Ğ· gaps: {len(gap_segments)} ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²")
            segments_raw.extend(gap_segments)
            segments_raw.sort(key=lambda x: x["start"])

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Ğ­Ğ¢ĞĞŸ 6: MERGE REPLICAS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    segments_merged = merge_replicas(segments_raw)

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Ğ­Ğ¢ĞĞŸ 7: SPEAKER CLASSIFICATION v15
    # ğŸ†• v16.13: ĞŸĞµÑ€ĞµĞ´Ğ°Ñ‡Ğ° speaker_roles Ğ´Ğ»Ñ ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ raw_speaker_id
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\n" + "="*70)
    print("ğŸ¯ v15: ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ÑĞµĞ¼ Ğ²ĞµÑĞ¾Ğ²ÑƒÑ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ¾Ğ² (v16.13)...")
    print("="*70)
    segments_merged, classification_stats = apply_speaker_classification_v15(
        segments_merged, speaker_surname, speaker_roles, debug=True  # ğŸ†• v16.13: Ğ¿ĞµÑ€ĞµĞ´Ğ°Ñ‘Ğ¼ speaker_roles
    )
    print("="*70)
    print()

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Ğ­Ğ¢ĞĞŸ 8: TEXT-BASED CORRECTIONS
    # ğŸ†• v16.12: ĞŸĞµÑ€ĞµĞ´Ğ°Ñ‡Ğ° speaker_roles Ğ² split Ğ´Ğ»Ñ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ğ¾Ğ¹ ĞºĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ°Ñ†Ğ¸Ğ¸
    # ğŸ†• v16.11: ĞŸÑ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ°Ñ Ğ»Ğ¾Ğ³Ğ¸ĞºĞ° continuation phrase fix
    # ğŸ†• v16.4: Ğ Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ½Ğ°Ñ Ğ·Ğ°Ñ‰Ğ¸Ñ‚Ğ° Ğ¾Ñ‚ Ğ¿ĞµÑ€ĞµĞ°Ñ‚Ñ€Ğ¸Ğ±ÑƒÑ†Ğ¸Ğ¸ Ğ°Ğ½Ğ¾Ğ½ÑĞ¾Ğ² Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nâœ‚ï¸ Ğ Ğ°Ğ·Ğ´ĞµĞ»ĞµĞ½Ğ¸Ğµ mixed-speaker ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ² (v16.12)...")
    segments_merged = split_mixed_speaker_segments(
        segments_merged, speaker_surname, speaker_roles  # ğŸ†• v16.12: Ğ¿ĞµÑ€ĞµĞ´Ğ°Ñ‘Ğ¼ speaker_roles
    )
    
    print("\nğŸ” Text-based correction (v16.4)...")
    segments_merged = text_based_correction(segments_merged, speaker_surname)

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Ğ­Ğ¢ĞĞŸ 9: Ğ’ĞĞ›Ğ˜Ğ”ĞĞ¦Ğ˜Ğ¯ + AUTO-MERGE
    # ğŸ†• v16.0: ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° raw_speaker_id Ğ¿ĞµÑ€ĞµĞ´ ÑĞ»Ğ¸ÑĞ½Ğ¸ĞµĞ¼
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    errors = validate_adjacent_same_speaker(segments_merged)

    if errors:
        segments_merged = auto_merge_adjacent_same_speaker(segments_merged)
        validate_adjacent_same_speaker(segments_merged)

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # Ğ­Ğ¢ĞĞŸ 10: Ğ­ĞšĞ¡ĞŸĞĞ Ğ¢
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    validation_report = generate_validation_report(segments_merged, speaker_surname)

    file_info = {
        "filename": wav_path.name,
        "duration": audio_duration,
        "speaker_surname": speaker_surname,
        "whisper_model": "large-v3-turbo",
        "vad_threshold": vad_threshold,
        "gaps_detected": len(gaps),
        "gaps_final": len(gaps),
        "retry_added": len(gap_segments),
        "speaker_stats": dict(stats),
        "pipeline_version": VERSION,  # ğŸ†• v16.12: Ğ²ĞµÑ€ÑĞ¸Ñ Ğ² metadata
        "params": {
            "model_name": "large-v3-turbo",
            "language": "ru",
            "min_speakers": min_speakers,
            "max_speakers": max_speakers
        }
    }

    corrections_log = {
        "journalist_commands_detected": len(cmd_corrections),
        "journalist_commands_details": cmd_corrections
    }

    json_path = json_dir / f"{wav_path.stem}.json"
    export_to_json(
        json_path,
        segments_raw,
        segments_merged,
        file_info,
        speaker_roles,
        validation_report,
        corrections_log
    )

    print(f" âœ… {json_path.name} (v{VERSION}, roles={speaker_roles})")
    return json_path

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    """
    Ğ“Ğ»Ğ°Ğ²Ğ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ - Ğ¸Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ñ€ĞµĞ¶Ğ¸Ğ¼
    
    Returns:
        (json_files, txt_path, speaker_surname) Ğ´Ğ»Ñ ĞºĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ² test-results
    """

    # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ
    login(token=HF_TOKEN)

    print(f"ğŸ”¥ ĞŸĞĞ™ĞŸĞ›ĞĞ™Ğ v{VERSION}: {VERSION_NAME}")
    print(f"GPU: {'âœ… CUDA' if torch.cuda.is_available() else 'âš ï¸ CPU'}")
    print("=" * 70)
    print()
    print("ğŸ’¡ v16.12 Ğ˜Ğ—ĞœĞ•ĞĞ•ĞĞ˜Ğ¯:")
    print("   âœ… ĞšĞ Ğ˜Ğ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ™ FIX: raw_speaker_id Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ÑĞµÑ‚ÑÑ Ğ¿Ñ€Ğ¸ split")
    print("   âœ… Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ñ‹Ğ¹ Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³ speaker_roles (Ğ˜ÑĞ°ĞµĞ² â†’ SPEAKER_01)")
    print("   âœ… Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½ Ğ±Ğ°Ğ³: TXT Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ğ» ÑÑ‚Ğ°Ñ€Ñ‹Ğ¹ speaker Ğ²Ğ¼ĞµÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾")
    print("   âœ… Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ Ğ¿Ğ¾Ğ»Ğµ pipeline_version Ğ² JSON metadata")
    print()
    print("ğŸ’¡ v16.11 Ğ˜Ğ—ĞœĞ•ĞĞ•ĞĞ˜Ğ¯:")
    print("   âœ… ĞŸĞ ĞĞ’Ğ˜Ğ›Ğ¬ĞĞĞ¯ Ğ»Ğ¾Ğ³Ğ¸ĞºĞ° continuation phrase fix")
    print("   âœ… ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ° Ğ’ĞĞ£Ğ¢Ğ Ğ˜ Ñ‚ĞµĞºÑƒÑ‰ĞµĞ³Ğ¾ split (Ğ½Ğµ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ğ¹ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚)")
    print()

    # Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ Ğ¿ÑƒÑ‚Ğ¸ Ğº Ğ¿Ğ°Ğ¿ĞºĞµ
    folder_path = input("ğŸ“‚ ĞŸÑƒÑ‚ÑŒ Ğº Ğ¿Ğ°Ğ¿ĞºĞµ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ° (\\\\  Ğ¸Ğ»Ğ¸ /): ").strip().replace('"', '')
    folder = Path(folder_path)

    if not folder.exists():
        print("âŒ ĞŸĞ°Ğ¿ĞºĞ° Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°!")
        return None, None, None

    print(f"âœ… ĞŸĞ°Ğ¿ĞºĞ°: {folder}")

    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ Ğ¿Ğ°Ğ¿Ğ¾Ğº
    audio_dir, json_dir, txt_dir = ensure_folder_structure(folder)

    if not audio_dir.exists():
        print(f"âŒ ĞŸĞ°Ğ¿ĞºĞ° audio/ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°! Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹: {audio_dir}")
        return None, None, None

    print(f"ğŸ“ audio/: {audio_dir}")
    print(f"ğŸ“ json/:  {json_dir}")
    print(f"ğŸ“ txt/:   {txt_dir}")

    # Ğ’Ñ‹Ğ±Ğ¾Ñ€ Ñ€ĞµĞ¶Ğ¸Ğ¼Ğ°
    mode = input("\nâš™ï¸ Ğ ĞµĞ¶Ğ¸Ğ¼ [Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ğ¹]: ").strip().lower() or "Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ğ¹"
    print(f"\nğŸš€ Ğ ĞµĞ¶Ğ¸Ğ¼: {mode} (v{VERSION})")

    # Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Whisper
    print("\nğŸ¤– Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Whisper large-v3-turbo...")
    whisper_model = whisper.load_model("large-v3-turbo")
    print("âœ… Whisper Ğ³Ğ¾Ñ‚Ğ¾Ğ²")

    # ĞŸĞ°Ñ€ÑĞ¸Ğ½Ğ³ Ğ¸Ğ¼ĞµĞ½Ğ¸ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ°
    speaker_surname, date, full_name = parse_speaker_folder(folder.name)
    print(f"\nğŸ‘¤ '{folder.name}' â†’ {full_name}.txt")
    print(f"ğŸ¤– large-v3-turbo + pyannote v{VERSION}...")

    # ĞŸĞ¾Ğ¸ÑĞº WAV Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ² audio/
    wav_files = sorted(audio_dir.glob("*.wav"))

    if not wav_files:
        print(f"âŒ WAV Ñ„Ğ°Ğ¹Ğ»Ñ‹ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹ Ğ² {audio_dir}!")
        return None, None, None

    print(f"\nâœ… ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ WAV: {len(wav_files)}")

    json_files = []

    # ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²
    for wav_path in tqdm(wav_files, desc="JSON + Ğ”Ğ¸Ğ°Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ"):
        json_path = process_audio_file(
            wav_path,
            whisper_model,
            speaker_surname,
            json_dir,
            min_speakers=2,
            max_speakers=3,
            debug=True
        )

        if json_path:
            json_files.append(json_path)

    print(f"\nâœ… JSON: {len(json_files)}/{len(wav_files)}")

    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ TXT
    txt_path = None
    if json_files:
        txt_path = txt_dir / f"{full_name}.txt"
        print(f"\nğŸ“„ {len(json_files)} JSON â†’ {txt_path.name}")
        jsons_to_txt(json_files, txt_path, speaker_surname)
        print(f"âœ… TXT: {txt_path} (v{VERSION})")

    print(f"\nâœ… Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ğ¾! ğŸš€ (v{VERSION})")
    print(f"\nğŸ“‚ Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹:")
    print(f"   JSON: {json_dir}")
    print(f"   TXT:  {txt_dir}")
    
    # Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµĞ¼ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ ĞºĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ² test-results
    return json_files, txt_path, speaker_surname

if __name__ == "__main__":
    # ğŸ†• v16.8: Ğ—Ğ°Ñ…Ğ²Ğ°Ñ‚ console output Ğ² Ñ„Ğ°Ğ¹Ğ»
    log_file = Path.cwd() / "transcription_debug.log"
    
    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ tee Ğ´Ğ»Ñ stdout
    tee = TeeOutput(log_file)
    original_stdout = sys.stdout
    sys.stdout = tee
    
    json_files = None
    txt_path = None
    speaker_surname = None
    
    try:
        # Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ main Ğ¸ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹
        json_files, txt_path, speaker_surname = main()
    finally:
        # Ğ’Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ stdout Ğ¸ Ğ·Ğ°ĞºÑ€Ñ‹Ğ²Ğ°ĞµĞ¼ Ñ„Ğ°Ğ¹Ğ»
        sys.stdout = original_stdout
        tee.close()
        
        # âœ… v16.8.1: ĞšĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ĞŸĞĞ¡Ğ›Ğ• Ğ·Ğ°ĞºÑ€Ñ‹Ñ‚Ğ¸Ñ Ñ„Ğ°Ğ¹Ğ»Ğ°
        if json_files and txt_path and log_file.exists():
            print(f"\nğŸ’¾ DEBUG log ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ñ‘Ğ½: {log_file}")
            copy_to_test_results(json_files, txt_path, speaker_surname, log_file)
        else:
            print(f"\nğŸ’¾ DEBUG log ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ñ‘Ğ½: {log_file}")
            print("   TEST: ĞšĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ² test-results Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½Ğ¾")
