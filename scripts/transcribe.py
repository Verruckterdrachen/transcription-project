#!/usr/bin/env python3
"""
transcribe_v16.py - –ì–ª–∞–≤–Ω—ã–π —Ñ–∞–π–ª –ø–∞–π–ø–ª–∞–π–Ω–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ v16.5

üî• v16.5: SMART GAP ATTRIBUTION
- FIX #1: GAP_FILLED —É–º–Ω–∞—è –∞—Ç—Ä–∏–±—É—Ü–∏—è –ø–æ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–º—É —Å—Ö–æ–¥—Å—Ç–≤—É
- FIX #2: –ó–∞—â–∏—Ç–∞ –æ—Ç –∞—Ç—Ä–∏–±—É—Ü–∏–∏ –∑–∞–ø–∏–Ω–æ–∫/–ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–æ–∫ –ø—Ä–µ–¥—ã–¥—É—â–µ–º—É —Å–ø–∏–∫–µ—Ä—É
- FIX #3: text_similarity() –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∏–∑ utils.py –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ GAP

üî• v16.4: SPEAKER ATTRIBUTION PROTECTION
- FIX #1: split_mixed_speaker_segments ‚Äî –ø–µ—Ä–µ—Å—á–µ—Ç —Ç–∞–π–º–∫–æ–¥–æ–≤ –ø–æ—Å–ª–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è
- FIX #2: text_based_correction ‚Äî –∑–∞—â–∏—Ç–∞ –æ—Ç –ø–µ—Ä–µ–∞—Ç—Ä–∏–±—É—Ü–∏–∏ –∞–Ω–æ–Ω—Å–æ–≤ –≤–æ–ø—Ä–æ—Å–æ–≤
- FIX #3: Context window protection ‚Äî –Ω–µ —Ç—Ä–æ–≥–∞—Ç—å —Å–µ–≥–º–µ–Ω—Ç—ã –≤–Ω—É—Ç—Ä–∏ –º–æ–Ω–æ–ª–æ–≥–æ–≤ >60s
- FIX #4: Confirmation pattern detection ‚Äî –¥–µ—Ç–µ–∫—Ü–∏—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–π ("–ù—É –¥–∞", "–î–∞-–¥–∞")
- FIX #5: Announcement vs Question ‚Äî —Ä–∞–∑–ª–∏—á–µ–Ω–∏–µ –∞–Ω–æ–Ω—Å–∞ –∏ –ø–æ–ª–Ω–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞

v16.0 (–±–∞–∑–æ–≤—ã–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è):
- FIX #1: text_based_correction ‚Äî –∑–∞—â–∏—Ç–∞ –æ—Ç –ø–µ—Ä–µ–∞—Ç—Ä–∏–±—É—Ü–∏–∏ —Å –º–∞—Ä–∫–µ—Ä–∞–º–∏ –ñ—É—Ä–Ω–∞–ª–∏—Å—Ç–∞
- FIX #2: "–î–∞–≤–∞–π—Ç–µ —Å–Ω—è—Ç—å" –ù–ï —É–¥–∞–ª—è–µ—Ç—Å—è (—É–±—Ä–∞–Ω –∏–∑ patterns)
- FIX #3: force_transcribe ‚Äî no_speech_threshold 0.3‚Üí0.2 (–º–µ–Ω—å—à–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤)
- FIX #4: auto_merge ‚Äî –ù–ï —Å–∫–ª–µ–∏–≤–∞–µ—Ç —Å–µ–≥–º–µ–Ω—Ç—ã —Å —Ä–∞–∑–Ω—ã–º–∏ raw_speaker_id
- DEBUG: –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö JSON –Ω–∞ –∫–∞–∂–¥–æ–º —ç—Ç–∞–ø–µ

üìÅ –°–¢–†–£–ö–¢–£–†–ê –ü–ê–ü–û–ö:
   –°–ø–∏–∫–µ—Ä (–î–î.–ú–ú)/
      audio/        ‚Üê WAV —Ñ–∞–π–ª—ã –∑–¥–µ—Å—å
      json/         ‚Üê JSON —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è —Å—é–¥–∞
      txt/          ‚Üê TXT —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è —Å—é–¥–∞
"""

import os
import sys
import whisper
import torch
from pathlib import Path
from tqdm import tqdm
import warnings

# –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–æ–≤
sys.path.insert(0, str(Path(__file__).parent))

# –ò–º–ø–æ—Ä—Ç—ã –º–æ–¥—É–ª–µ–π
from core.config import HF_TOKEN, VERSION, VERSION_NAME
from core.utils import (
    seconds_to_hms, parse_speaker_folder, adaptive_vad_threshold, gap_detector
)
from core.diarization import (
    diarize_audio, compute_speaker_stats, identify_speaker_roles, 
    align_segment_to_diarization
)
from core.alignment import align_whisper_with_diarization
from core.transcription import transcribe_audio, force_transcribe_diar_gaps

from corrections.hallucinations import (
    filter_hallucination_segments, clean_hallucinations_from_text
)
from corrections.speaker_classifier import apply_speaker_classification_v15
from corrections.boundary_fixer import (
    boundary_correction_raw, split_mixed_speaker_segments
)
from corrections.journalist_commands import detect_journalist_commands_cross_segment
from corrections.text_corrections import text_based_correction

from merge.replica_merger import merge_replicas
from merge.deduplicator import (
    remove_cross_speaker_text_duplicates, deduplicate_segments
)
from merge.validator import (
    validate_adjacent_same_speaker, auto_merge_adjacent_same_speaker,
    generate_validation_report
)

from export.json_export import export_to_json
from export.txt_export import export_to_txt, jsons_to_txt

from huggingface_hub import login

warnings.filterwarnings("ignore")

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –í–ï–†–°–ò–Ø
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

VERSION = "16.5"
VERSION_NAME = "Smart GAP Attribution"

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –ì–õ–û–ë–ê–õ–¨–ù–ê–Ø –ü–ï–†–ï–ú–ï–ù–ù–ê–Ø –î–õ–Ø PIPELINE
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

_pipeline = None

def get_pipeline():
    """–õ–µ–Ω–∏–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è pyannote pipeline"""
    global _pipeline
    if _pipeline is None:
        print("ü§ñ –ó–∞–≥—Ä—É–∑–∫–∞ pyannote pipeline...")
        from pyannote.audio import Pipeline
        _pipeline = Pipeline.from_pretrained("pyannote/speaker-diarization-3.1")
        if torch.cuda.is_available():
            _pipeline.to(torch.device("cuda"))
        print("‚úÖ Pyannote –≥–æ—Ç–æ–≤ (3.1)")
    return _pipeline

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –°–û–ó–î–ê–ù–ò–ï –°–¢–†–£–ö–¢–£–†–´ –ü–ê–ü–û–ö
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def ensure_folder_structure(base_folder):
    """
    –°–æ–∑–¥–∞—ë—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫ audio/json/txt –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç

    Args:
        base_folder: Path –∫ –ø–∞–ø–∫–µ —Å–ø–∏–∫–µ—Ä–∞

    Returns:
        (audio_dir, json_dir, txt_dir)
    """
    audio_dir = base_folder / "audio"
    json_dir = base_folder / "json"
    txt_dir = base_folder / "txt"

    # –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫–∏ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
    json_dir.mkdir(exist_ok=True)
    txt_dir.mkdir(exist_ok=True)

    return audio_dir, json_dir, txt_dir

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –û–°–ù–û–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø –û–ë–†–ê–ë–û–¢–ö–ò –û–î–ù–û–ì–û –§–ê–ô–õ–ê
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def process_audio_file(
    wav_path,
    whisper_model,
    speaker_surname,
    json_dir,
    min_speakers=2,
    max_speakers=3,
    debug=False
):
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–∏–Ω –∞—É–¥–∏–æ —Ñ–∞–π–ª

    Args:
        wav_path: Path –∫ WAV —Ñ–∞–π–ª—É
        whisper_model: –ó–∞–≥—Ä—É–∂–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å Whisper
        speaker_surname: –§–∞–º–∏–ª–∏—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Å–ø–∏–∫–µ—Ä–∞
        json_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è JSON
        min_speakers: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ø–∏–∫–µ—Ä–æ–≤
        max_speakers: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ø–∏–∫–µ—Ä–æ–≤
        debug: –†–µ–∂–∏–º –æ—Ç–ª–∞–¥–∫–∏

    Returns:
        Path –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É JSON —Ñ–∞–π–ª—É
    """
    print(f"\nüé§ {wav_path.name}")

    # –ü–æ–ª—É—á–∞–µ–º pipeline
    pipeline = get_pipeline()

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # –≠–¢–ê–ü 1: –î–ò–ê–†–ò–ó–ê–¶–ò–Ø
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    diarization = diarize_audio(pipeline, wav_path, min_speakers, max_speakers)

    if not diarization:
        print(f"  ‚ùå –î–∏–∞—Ä–∏–∑–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å")
        return None

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–ø–∏–∫–µ—Ä–æ–≤
    stats = compute_speaker_stats(diarization)

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # –≠–¢–ê–ü 2: –¢–†–ê–ù–°–ö–†–ò–ë–ê–¶–ò–Ø
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    audio_duration = max(turn.end for turn, _ in diarization.itertracks())
    vad_threshold = adaptive_vad_threshold(audio_duration)
    print(f"üìè –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π VAD: {vad_threshold}")

    result = transcribe_audio(
        whisper_model,
        wav_path,
        language="ru",
        temperature=0.0,
        beam_size=5,
        vad_threshold=vad_threshold
    )

    if not result or not result.get("segments"):
        print("  ‚ùå –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å")
        return None

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # –≠–¢–ê–ü 3: –í–´–†–ê–í–ù–ò–í–ê–ù–ò–ï –° –î–ò–ê–†–ò–ó–ê–¶–ò–ï–ô
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–æ–ª–∏ —Å–ø–∏–∫–µ—Ä–æ–≤
    speaker_roles = identify_speaker_roles(stats, result["segments"])

    # –í—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º
    segments_raw = align_whisper_with_diarization(
        result["segments"],
        diarization,
        speaker_surname,
        speaker_roles
    )

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # –≠–¢–ê–ü 4: –ö–û–†–†–ï–ö–¶–ò–ò
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    # 4.1 –î–µ—Ç–µ–∫—Ü–∏—è –∫–æ–º–∞–Ω–¥ –ñ—É—Ä–Ω–∞–ª–∏—Å—Ç–∞
    segments_raw, cmd_corrections = detect_journalist_commands_cross_segment(
        segments_raw, speaker_surname
    )

    # 4.2 Boundary correction
    segments_raw = boundary_correction_raw(
        segments_raw, speaker_surname, speaker_roles
    )

    # 4.3 Cross-speaker deduplication
    print("\nüîÑ Cross-speaker deduplication...")
    segments_raw = remove_cross_speaker_text_duplicates(segments_raw)
    print(f"‚úÖ –ü–æ—Å–ª–µ cross-speaker dedup: {len(segments_raw)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤")

    # 4.4 –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è
    print("\nüîÑ –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è —Å–µ–≥–º–µ–Ω—Ç–æ–≤...")
    segments_raw = deduplicate_segments(segments_raw)
    print(f"‚úÖ –ü–æ—Å–ª–µ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏: {len(segments_raw)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤")

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # –≠–¢–ê–ü 5: GAPS (–µ—Å–ª–∏ –µ—Å—Ç—å)
    # üÜï v16.5: –£–º–Ω–∞—è –∞—Ç—Ä–∏–±—É—Ü–∏—è GAP_FILLED –ø–æ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–º—É —Å—Ö–æ–¥—Å—Ç–≤—É
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    gaps = gap_detector(segments_raw, threshold=3.0)
    gap_segments = []

    if gaps:
        print(f"\nüîç –ì–ê–ü–´ WHISPER:")
        for gap in gaps:
            print(f"   üö® GAP {gap['gap_hms_start']}‚Äì{gap['gap_hms_end']} ({gap['duration']}s)")

        # Force transcribe gaps (v16.5: —É–º–Ω–∞—è –∞—Ç—Ä–∏–±—É—Ü–∏—è)
        gap_segments = force_transcribe_diar_gaps(
            whisper_model, wav_path, gaps, segments_raw, speaker_surname
        )

        if gap_segments:
            print(f"  ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ –∏–∑ gaps: {len(gap_segments)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
            segments_raw.extend(gap_segments)
            segments_raw.sort(key=lambda x: x["start"])

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # –≠–¢–ê–ü 6: MERGE REPLICAS
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    segments_merged = merge_replicas(segments_raw)

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # –≠–¢–ê–ü 7: SPEAKER CLASSIFICATION v15
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    print("\n" + "="*70)
    print("üéØ v15: –ü—Ä–∏–º–µ–Ω—è–µ–º –≤–µ—Å–æ–≤—É—é –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é —Å–ø–∏–∫–µ—Ä–æ–≤...")
    print("="*70)
    segments_merged, classification_stats = apply_speaker_classification_v15(
        segments_merged, speaker_surname, debug=True
    )
    print("="*70)
    print()

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # –≠–¢–ê–ü 8: TEXT-BASED CORRECTIONS
    # üÜï v16.4: –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –∑–∞—â–∏—Ç–∞ –æ—Ç –ø–µ—Ä–µ–∞—Ç—Ä–∏–±—É—Ü–∏–∏ –∞–Ω–æ–Ω—Å–æ–≤ –≤–æ–ø—Ä–æ—Å–æ–≤
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    print("\n‚úÇÔ∏è –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ mixed-speaker —Å–µ–≥–º–µ–Ω—Ç–æ–≤ (v16.4)...")
    segments_merged = split_mixed_speaker_segments(segments_merged, speaker_surname)
    
    print("\nüîç Text-based correction (v16.4)...")
    segments_merged = text_based_correction(segments_merged, speaker_surname)

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # –≠–¢–ê–ü 9: –í–ê–õ–ò–î–ê–¶–ò–Ø + AUTO-MERGE
    # üÜï v16.0: –ü—Ä–æ–≤–µ—Ä–∫–∞ raw_speaker_id –ø–µ—Ä–µ–¥ —Å–ª–∏—è–Ω–∏–µ–º
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    errors = validate_adjacent_same_speaker(segments_merged)

    if errors:
        segments_merged = auto_merge_adjacent_same_speaker(segments_merged)
        validate_adjacent_same_speaker(segments_merged)

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # –≠–¢–ê–ü 10: –≠–ö–°–ü–û–†–¢
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    validation_report = generate_validation_report(segments_merged, speaker_surname)

    file_info = {
        "filename": wav_path.name,
        "duration": audio_duration,
        "speaker_surname": speaker_surname,
        "whisper_model": "large-v3-turbo",
        "vad_threshold": vad_threshold,
        "gaps_detected": len(gaps),
        "gaps_final": len(gaps),
        "retry_added": len(gap_segments),
        "speaker_stats": dict(stats),
        "params": {
            "model_name": "large-v3-turbo",
            "language": "ru",
            "min_speakers": min_speakers,
            "max_speakers": max_speakers
        }
    }

    corrections_log = {
        "journalist_commands_detected": len(cmd_corrections),
        "journalist_commands_details": cmd_corrections
    }

    json_path = json_dir / f"{wav_path.stem}.json"
    export_to_json(
        json_path,
        segments_raw,
        segments_merged,
        file_info,
        speaker_roles,
        validation_report,
        corrections_log
    )

    print(f" ‚úÖ {json_path.name} (roles={speaker_roles})")
    return json_path

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# MAIN
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è - –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º"""

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    login(token=HF_TOKEN)

    print(f"üî• –ü–ê–ô–ü–õ–ê–ô–ù v{VERSION}: {VERSION_NAME}")
    print(f"GPU: {'‚úÖ CUDA' if torch.cuda.is_available() else '‚ö†Ô∏è CPU'}")
    print("=" * 70)
    print()
    print("üí° v16.5 –ò–ó–ú–ï–ù–ï–ù–ò–Ø:")
    print("   ‚úÖ FIX: GAP_FILLED ‚Äî —É–º–Ω–∞—è –∞—Ç—Ä–∏–±—É—Ü–∏—è –ø–æ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–º—É —Å—Ö–æ–¥—Å—Ç–≤—É")
    print("   ‚úÖ FIX: –ó–∞—â–∏—Ç–∞ –æ—Ç –∞—Ç—Ä–∏–±—É—Ü–∏–∏ –∑–∞–ø–∏–Ω–æ–∫ –ø—Ä–µ–¥—ã–¥—É—â–µ–º—É —Å–ø–∏–∫–µ—Ä—É")
    print("   ‚úÖ FIX: text_similarity() –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ GAP")
    print()
    print("üí° v16.4 –ò–ó–ú–ï–ù–ï–ù–ò–Ø:")
    print("   ‚úÖ FIX: split_mixed_speaker_segments ‚Äî –ø–µ—Ä–µ—Å—á–µ—Ç —Ç–∞–π–º–∫–æ–¥–æ–≤")
    print("   ‚úÖ FIX: text_based_correction ‚Äî –∑–∞—â–∏—Ç–∞ –æ—Ç –∞–Ω–æ–Ω—Å–æ–≤ –≤–æ–ø—Ä–æ—Å–æ–≤")
    print("   ‚úÖ FIX: Context window protection (–º–æ–Ω–æ–ª–æ–≥–∏ >60s)")
    print("   ‚úÖ FIX: Confirmation pattern detection (\"–ù—É –¥–∞\", \"–î–∞-–¥–∞\")")
    print("   ‚úÖ FIX: Announcement vs Question distinction")
    print()
    print("üí° v16.0 –ë–ê–ó–û–í–´–ï –ò–ó–ú–ï–ù–ï–ù–ò–Ø:")
    print("   ‚úÖ FIX: text_based_correction ‚Äî –∑–∞—â–∏—Ç–∞ –æ—Ç –Ω–µ–≤–µ—Ä–Ω–æ–π –∞—Ç—Ä–∏–±—É—Ü–∏–∏")
    print("   ‚úÖ FIX: \"–î–∞–≤–∞–π—Ç–µ —Å–Ω—è—Ç—å\" –ù–ï —É–¥–∞–ª—è–µ—Ç—Å—è")
    print("   ‚úÖ FIX: force_transcribe ‚Äî no_speech 0.2 (–±—ã–ª–æ 0.3)")
    print("   ‚úÖ FIX: auto_merge ‚Äî –ø—Ä–æ–≤–µ—Ä–∫–∞ raw_speaker_id")
    print("   ‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø–∞–ø–æ–∫: audio/ ‚Üí json/ + txt/")
    print()

    # –ó–∞–ø—Ä–æ—Å –ø—É—Ç–∏ –∫ –ø–∞–ø–∫–µ
    folder_path = input("üìÇ –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å–ø–∏–∫–µ—Ä–∞ (\\\\\\\\  –∏–ª–∏ /): ").strip().replace('"', '')
    folder = Path(folder_path)

    if not folder.exists():
        print("‚ùå –ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
        return

    print(f"‚úÖ –ü–∞–ø–∫–∞: {folder}")

    # –°–æ–∑–¥–∞—ë–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫
    audio_dir, json_dir, txt_dir = ensure_folder_structure(folder)

    if not audio_dir.exists():
        print(f"‚ùå –ü–∞–ø–∫–∞ audio/ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞! –°–æ–∑–¥–∞–π: {audio_dir}")
        return

    print(f"üìÅ audio/: {audio_dir}")
    print(f"üìÅ json/:  {json_dir}")
    print(f"üìÅ txt/:   {txt_dir}")

    # –í—ã–±–æ—Ä —Ä–µ–∂–∏–º–∞
    mode = input("\n‚öôÔ∏è –†–µ–∂–∏–º [—Ç–æ—á–Ω—ã–π]: ").strip().lower() or "—Ç–æ—á–Ω—ã–π"
    print(f"\nüöÄ –†–µ–∂–∏–º: {mode} (v{VERSION})")

    # –ó–∞–≥—Ä—É–∑–∫–∞ Whisper
    print("\nü§ñ –ó–∞–≥—Ä—É–∑–∫–∞ Whisper large-v3-turbo...")
    whisper_model = whisper.load_model("large-v3-turbo")
    print("‚úÖ Whisper –≥–æ—Ç–æ–≤")

    # –ü–∞—Ä—Å–∏–Ω–≥ –∏–º–µ–Ω–∏ —Å–ø–∏–∫–µ—Ä–∞
    speaker_surname, date, full_name = parse_speaker_folder(folder.name)
    print(f"\nüë§ '{folder.name}' ‚Üí {full_name}.txt")
    print(f"ü§ñ large-v3-turbo + pyannote v{VERSION}...")

    # –ü–æ–∏—Å–∫ WAV —Ñ–∞–π–ª–æ–≤ –≤ audio/
    wav_files = sorted(audio_dir.glob("*.wav"))

    if not wav_files:
        print(f"‚ùå WAV —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ {audio_dir}!")
        return

    print(f"\n‚úÖ –ù–∞–π–¥–µ–Ω–æ WAV: {len(wav_files)}")

    json_files = []

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤
    for wav_path in tqdm(wav_files, desc="JSON + –î–∏–∞—Ä–∏–∑–∞—Ü–∏—è"):
        json_path = process_audio_file(
            wav_path,
            whisper_model,
            speaker_surname,
            json_dir,
            min_speakers=2,
            max_speakers=3,
            debug=True
        )

        if json_path:
            json_files.append(json_path)

    print(f"\n‚úÖ JSON: {len(json_files)}/{len(wav_files)}")

    # –°–æ–∑–¥–∞–Ω–∏–µ TXT
    if json_files:
        txt_path = txt_dir / f"{full_name}.txt"
        print(f"\nüìÑ {len(json_files)} JSON ‚Üí {txt_path.name}")
        jsons_to_txt(json_files, txt_path, speaker_surname)
        print(f"‚úÖ TXT: {txt_path} (v{VERSION})")

    print(f"\n‚úÖ –ì–æ—Ç–æ–≤–æ! üöÄ (v{VERSION})")
    print(f"\nüìÇ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
    print(f"   JSON: {json_dir}")
    print(f"   TXT:  {txt_dir}")

if __name__ == "__main__":
    main()
