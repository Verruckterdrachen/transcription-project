#!/usr/bin/env python3
"""
transcribe_v16.py - Ğ“Ğ»Ğ°Ğ²Ğ½Ñ‹Ğ¹ Ñ„Ğ°Ğ¹Ğ» Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½Ğ° Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ğ¸ v16.28

ğŸ”¥ v16.28: FIX clean_loops() - Ğ·Ğ°Ğ¼ĞµĞ½Ğ° Ğ½Ğ° "..." Ğ²Ğ¼ĞµÑÑ‚Ğ¾ ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¸Ñ
- v16.27 ÑƒĞ´Ğ°Ğ»ÑĞ» loops â†’ Ğ¿Ğ¾Ñ‚ĞµÑ€Ñ ÑĞ¼Ñ‹ÑĞ»Ğ° Ñ‚ĞµĞºÑÑ‚Ğ°
- v16.28 Ğ·Ğ°Ğ¼ĞµĞ½ÑĞµÑ‚ loops Ğ½Ğ° "..." â†’ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ñ‘Ğ½
- Threshold: 95% (Ğ¾Ñ‡ĞµĞ½ÑŒ ÑÑ‚Ñ€Ğ¾Ğ³Ğ¾, Ğ½Ğµ 75%!)
- Min n-gram: 4 ÑĞ»Ğ¾Ğ²Ğ° (Ğ½Ğµ 2!)
- Gap-filled: threshold 97%

ğŸ”¥ v16.27: FIX hallucination loops - clean_loops() Ñ€ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ
- Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ° Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ clean_loops() Ğ´Ğ»Ñ ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¸Ñ repeating n-grams
- N-gram Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· (2-8 ÑĞ»Ğ¾Ğ²) Ñ adaptive threshold
- ĞšĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğµ Ñ„Ñ€Ğ°Ğ·Ñ‹ (<5 ÑĞ»Ğ¾Ğ²) â†’ 85%, Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğµ â†’ 75%
- Gap-filled ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ñ‹: threshold +10%
- Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ° Ğ² clean_hallucinations_from_text()

ğŸ”¥ v16.26: FIX Ğ´ÑƒĞ±Ğ»ĞµĞ¹ timestamp - ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ replica_merger + txt_export
- txt_export Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚ Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ğµ inner timestamps Ğ¾Ñ‚ replica_merger
- Ğ£ÑÑ‚Ñ€Ğ°Ğ½ĞµĞ½Ñ‹ Ğ´ÑƒĞ±Ğ»Ğ¸: "00:00:56 00:00:56" â†’ "00:00:56"

ğŸ”¥ v16.25: ĞĞ¢ĞšĞĞ¢ txt_export.py Ğº v16.3 + Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ğ¹ FIX Ğ´ÑƒĞ±Ğ»ĞµĞ¹
- Ğ£Ğ´Ğ°Ğ»Ğ¸Ğ»Ğ¸ `\n` Ğ¿ĞµÑ€ĞµĞ´ inner timestamp (Ğ¿Ñ€Ğ¸Ñ‡Ğ¸Ğ½Ğ° Ğ‘ĞĞ“ #2 - Ñ€Ğ°Ğ·Ğ±Ğ¸ĞµĞ½Ğ¸Ğµ ÑÑ‚Ñ€Ğ¾Ğº)
- Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ğ»Ğ¸ ÑƒÑĞ»Ğ¾Ğ²Ğ¸Ğµ `i > 0` Ğ² should_insert (FIX Ğ‘ĞĞ“ #1 - Ğ´ÑƒĞ±Ğ»Ğ¸)
- Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚: TXT Ğ±ĞµĞ· Ğ±Ğ°Ğ³Ğ¾Ğ² v16.22-v16.24

ğŸ”¥ v16.22: FIX Ğ‘ĞĞ“ #1, #2 - Timestamp Ğ´ÑƒĞ±Ğ»Ğ¸ + Ğ½Ğ°Ğ·Ğ°Ğ´
- Ğ‘ĞĞ“ #1: insert_intermediate_timestamps() Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚ Ğ´ÑƒĞ±Ğ»Ğ¸ Ğ¿ĞµÑ€ĞµĞ´ Ğ²ÑÑ‚Ğ°Ğ²ĞºĞ¾Ğ¹
- Ğ‘ĞĞ“ #2: correct_timestamp_drift() Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚ Ğ¼Ğ¾Ğ½Ğ¾Ñ‚Ğ¾Ğ½Ğ½Ğ¾ÑÑ‚ÑŒ (Ğ½Ğµ ÑĞ´Ğ²Ğ¸Ğ³Ğ°ĞµÑ‚ Ğ½Ğ°Ğ·Ğ°Ğ´)
- Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚: TXT Ğ±ĞµĞ· Ğ´ÑƒĞ±Ğ»ĞµĞ¹ timestamp, Ğ±ĞµĞ· Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ğ¾Ğ³Ğ¾ Ñ…Ğ¾Ğ´Ğ° Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸

ğŸ”¥ v16.21: Fix continuation phrase position check (90% â†’ in-split check)
- ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ continuation phrase Ñ‚ĞµĞ¿ĞµÑ€ÑŒ Ğ”Ğ is_continuation_phrase()
- Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½ Ğ±Ğ°Ğ³: Ğ½Ğ°ĞºĞ¾Ğ¿Ğ»ĞµĞ½Ğ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚ (current_text) Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ²ĞºĞ»ÑÑ‡Ğ°Ñ‚ÑŒ Ñ‚ĞµĞºÑƒÑ‰ĞµĞµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ
- Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½ debug output: Ğ¿Ğ¾ĞºĞ°Ğ· Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ Ğ¸ Ñ€Ğ°ÑÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ Ğ´Ğ¾ ĞºĞ¾Ğ½Ñ†Ğ°
- ĞŸĞ¾Ñ€Ğ¾Ğ³: ĞµÑĞ»Ğ¸ Ñ„Ñ€Ğ°Ğ·Ğ° Ğ±Ğ»Ğ¸Ğ¶Ğµ Ğº Ğ½Ğ°Ñ‡Ğ°Ğ»Ñƒ (â‰¤30% Ğ¾Ñ‚ Ğ´Ğ»Ğ¸Ğ½Ñ‹) â†’ ÑÑ‡Ğ¸Ñ‚Ğ°ĞµĞ¼ "Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ¾Ğ¼"

ğŸ”¥ v16.19: ĞšĞ Ğ˜Ğ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ™ FIX - Timestamps + Hallucinations + Continuation
- Ğ’ÑÑ‚Ğ°Ğ²ĞºĞ° Ğ¿Ñ€Ğ¾Ğ¼ĞµĞ¶ÑƒÑ‚Ğ¾Ñ‡Ğ½Ñ‹Ñ… timestamp Ğ² Ğ±Ğ»Ğ¾ĞºĞ¸ >30 ÑĞµĞº (insert_intermediate_timestamps)
- Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ ÑĞ´Ğ²Ğ¸Ğ³Ğ° timestamp Ğ¿Ğ¾ÑĞ»Ğµ gap filling (correct_timestamp_drift)
- Ğ£Ğ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ Ğ´ÑƒĞ±Ğ»ĞµĞ¹ + "ĞŸÑ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½Ğ¸Ğµ ÑĞ»ĞµĞ´ÑƒĞµÑ‚" (filter_hallucination_segments)
- ĞŸĞ¾Ñ€Ğ¾Ğ³ continuation phrase: 80% â†’ 90% (boundary_fixer.py)

ğŸ”¥ v16.16: ĞšĞ Ğ˜Ğ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ™ FIX - Word Boundary Ğ² regex Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ğ°Ñ…!
- Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½ \\b (word boundary) Ğ² Ğ½Ğ°Ñ‡Ğ°Ğ»Ğµ Ğ²ÑĞµÑ… regex Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ğ¾Ğ²
- Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½ Ğ±Ğ°Ğ³: 'Ğ²Ñ‹\\s+' Ğ»Ğ¾Ğ²Ğ¸Ğ» "Ğ²Ñ‹ " Ğ²Ğ½ÑƒÑ‚Ñ€Ğ¸ ÑĞ»Ğ¾Ğ² (ĞĞµĞ²Ñ‹, ÑĞ¾Ğ²Ñ‹, ĞºÑ€Ğ¾Ğ²Ñ‹)
- Ğ¢ĞµĞ¿ĞµÑ€ÑŒ Ğ¿Ğ¾Ğ¸ÑĞº Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ†ĞµĞ»Ñ‹Ñ… ÑĞ»Ğ¾Ğ²: '\\bĞ²Ñ‹\\s+', '\\bÑ€Ğ°ÑÑĞºĞ°Ğ¶Ğ¸Ñ‚Ğµ\\b' Ğ¸ Ñ‚.Ğ´.
- ĞŸÑ€ĞµĞ´Ğ¾Ñ‚Ğ²Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ğµ FALSE POSITIVE Ğ² is_journalist_phrase() Ğ¸ is_expert_phrase()
- Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ° Ğ¾ÑˆĞ¸Ğ±ĞºĞ°: "Ğ¢Ğ¾ ĞµÑÑ‚ÑŒ Ñ Ğ½ĞµĞ±Ğ¾Ğ»ÑŒÑˆĞ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²Ğ° Ğ·ĞµĞ¼Ğ»Ğ¸ Ğ½Ğ° Ğ²Ğ¾ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¾Ğ¼ Ğ±ĞµÑ€ĞµĞ³Ñƒ ĞĞµĞ²Ñ‹..." â†’ Journalist=False âœ…

ğŸ”¥ v16.15: DEBUG OUTPUT Ğ”Ğ›Ğ¯ SPLIT - Ğ½Ğ°Ñ…Ğ¾Ğ´Ğ¸Ğ¼ Ğ²Ğ¸Ğ½Ğ¾Ğ²Ğ½Ğ¸ĞºĞ°!
- Ğ”ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ debug output Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ Ğ² split
- ĞŸĞ¾ĞºĞ°Ğ· Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² is_journalist_phrase, is_expert_phrase, is_continuation
- Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ÑĞ¼ĞµĞ½Ñ‹ current_speaker Ñ Ğ¿Ñ€Ğ¸Ñ‡Ğ¸Ğ½Ğ¾Ğ¹
- ĞŸĞ¾Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ½Ğ°Ğ¹Ñ‚Ğ¸ ĞšĞĞšĞĞ• Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ Ğ¾ÑˆĞ¸Ğ±Ğ¾Ñ‡Ğ½Ğ¾ Ğ¼ĞµĞ½ÑĞµÑ‚ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ°

ğŸ”¥ v16.14: ĞšĞ Ğ˜Ğ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ™ FIX REPLICA MERGER - SPEAKER ĞĞ¢ Ğ¡ĞĞœĞĞ“Ğ Ğ”Ğ›Ğ˜ĞĞĞĞ“Ğ
- replica_merger Ñ‚ĞµĞ¿ĞµÑ€ÑŒ Ğ±ĞµÑ€Ñ‘Ñ‚ speaker/raw_speaker_id Ğ¾Ñ‚ Ğ¡ĞĞœĞĞ“Ğ Ğ”Ğ›Ğ˜ĞĞĞĞ“Ğ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ°
- Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½ Ğ±Ğ°Ğ³: Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¹ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğ¹ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚ "Ğ·Ğ°Ñ€Ğ°Ğ¶Ğ°Ğ»" Ğ²ÑÑ ÑĞºĞ»ĞµĞ¹ĞºÑƒ
- Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½ debug output Ñ Ğ²Ñ‹Ğ±Ğ¾Ñ€Ğ¾Ğ¼ Ğ´Ğ¾Ğ¼Ğ¸Ğ½Ğ¸Ñ€ÑƒÑÑ‰ĞµĞ³Ğ¾ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ°

ğŸ”¥ v16.13: ĞšĞ Ğ˜Ğ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ™ FIX RAW_SPEAKER_ID SYNC Ğ’ CLASSIFICATION
- speaker_classifier Ñ‚ĞµĞ¿ĞµÑ€ÑŒ ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ raw_speaker_id Ğ¿Ñ€Ğ¸ Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğ¸ speaker
- ĞŸĞµÑ€ĞµĞ´Ğ°Ñ‡Ğ° speaker_roles Ğ² apply_speaker_classification_v15
- Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½ Ğ±Ğ°Ğ³: TXT Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ğ» ÑÑ‚Ğ°Ñ€Ñ‹Ğ¹ speaker Ğ¿Ğ¾ÑĞ»Ğµ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸
- ĞĞ½Ğ°Ğ»Ğ¾Ğ³Ğ¸Ñ‡Ğ½Ñ‹Ğ¹ Ñ„Ğ¸ĞºÑ v16.12, Ğ½Ğ¾ Ğ´Ğ»Ñ ÑÑ‚Ğ°Ğ¿Ğ° 7 (ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ)

ğŸ”¥ v16.12: ĞšĞ Ğ˜Ğ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ™ FIX RAW_SPEAKER_ID + VERSION Ğ’ JSON
- ĞŸÑ€Ğ¸ split Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ÑĞµÑ‚ÑÑ Ğ½Ğµ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ speaker, Ğ½Ğ¾ Ğ¸ raw_speaker_id
- Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ Ğ¿Ğ¾Ğ»Ğµ "pipeline_version" Ğ² JSON metadata
- Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½ Ğ±Ğ°Ğ³: TXT Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ğ» ÑÑ‚Ğ°Ñ€Ñ‹Ğ¹ speaker Ğ²Ğ¼ĞµÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾
- ĞŸĞµÑ€ĞµĞ´Ğ°Ñ‡Ğ° speaker_roles Ğ² split_mixed_speaker_segments

ğŸ”¥ v16.11: ĞŸĞ ĞĞ’Ğ˜Ğ›Ğ¬ĞĞĞ¯ Ğ›ĞĞ“Ğ˜ĞšĞ CONTINUATION PHRASE FIX
- Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ° Ğ»Ğ¾Ğ³Ğ¸ĞºĞ° Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ° Ğ² split_mixed_speaker_segments
- Continuation phrase Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚ÑÑ Ğ’ĞĞ£Ğ¢Ğ Ğ˜ Ñ‚ĞµĞºÑƒÑ‰ĞµĞ³Ğ¾ split (Ğ½Ğµ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ğ¹ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚)
- Ğ•ÑĞ»Ğ¸ Ğ½Ğ°ĞºĞ¾Ğ¿Ğ»ĞµĞ½Ğ¾ >80 ÑĞ»Ğ¾Ğ² â†’ continuation ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑĞµÑ‚ Ñ‚ĞµĞºÑƒÑ‰ĞµĞ³Ğ¾ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ°
- Ğ—Ğ°Ñ‰Ğ¸Ñ‚Ğ° Ğ¾Ñ‚ ÑĞ¼ĞµĞ½Ñ‹ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ° Ğ²Ğ½ÑƒÑ‚Ñ€Ğ¸ Ğ´Ğ»Ğ¸Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¼Ğ¾Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ°

ğŸ”¥ v16.8: DEBUG LOG + LONG MONOLOGUE FIX
- ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ²ÑĞµĞ³Ğ¾ pipeline Ğ² Ñ„Ğ°Ğ¹Ğ»
- Monologue context protection Ğ´Ğ»Ñ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ¾Ğ² >60s
- Continuation phrase detection
- GAP overlap protection

ğŸ”¥ v16.7: AUTO TEST-RESULTS COPY
- ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ ĞºĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ² test-results/latest/
- ĞÑ‡Ğ¸ÑÑ‚ĞºĞ° latest/ Ğ¿ĞµÑ€ĞµĞ´ ĞºĞ°Ğ¶Ğ´Ñ‹Ğ¼ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ¾Ğ¼
- Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ĞºĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ

ğŸ“ Ğ¡Ğ¢Ğ Ğ£ĞšĞ¢Ğ£Ğ Ğ ĞŸĞĞŸĞĞš:
	Ğ¡Ğ¿Ğ¸ĞºĞµÑ€ (Ğ”Ğ”.ĞœĞœ)/
		audio/        â† WAV Ñ„Ğ°Ğ¹Ğ»Ñ‹ Ğ·Ğ´ĞµÑÑŒ
		json/         â† JSON ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑÑÑ‚ÑÑ ÑÑĞ´Ğ°
		txt/          â† TXT ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑĞµÑ‚ÑÑ ÑÑĞ´Ğ°
"""

import os
import sys
import whisper
import torch
import shutil
from pathlib import Path
from tqdm import tqdm
import warnings

# Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ñ‚ĞµĞºÑƒÑ‰ÑƒÑ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ² Ğ¿ÑƒÑ‚ÑŒ Ğ´Ğ»Ñ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¾Ğ²
sys.path.insert(0, str(Path(__file__).parent))

# Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ñ‹ Ğ¼Ğ¾Ğ´ÑƒĞ»ĞµĞ¹
from core.config import HF_TOKEN, VERSION, VERSION_NAME
from core.utils import (
	seconds_to_hms, parse_speaker_folder, adaptive_vad_threshold, gap_detector
)
from core.diarization import (
	diarize_audio, compute_speaker_stats, identify_speaker_roles, 
	align_segment_to_diarization
)
from core.alignment import align_whisper_with_diarization
from core.transcription import transcribe_audio, force_transcribe_diar_gaps

from corrections.hallucinations import (
	filter_hallucination_segments, clean_hallucinations_from_text
)
from corrections.speaker_classifier import apply_speaker_classification_v15
from corrections.boundary_fixer import (
	boundary_correction_raw, split_mixed_speaker_segments
)
from corrections.journalist_commands import detect_journalist_commands_cross_segment
from corrections.text_corrections import text_based_correction
from corrections.timestamp_fixer import (  # ğŸ†• v16.19
	insert_intermediate_timestamps, correct_timestamp_drift
)

from merge.replica_merger import merge_replicas
from merge.deduplicator import (
	remove_cross_speaker_text_duplicates, deduplicate_segments
)
from merge.validator import (
	validate_adjacent_same_speaker, auto_merge_adjacent_same_speaker,
	generate_validation_report
)

from export.json_export import export_to_json
from export.txt_export import export_to_txt, jsons_to_txt

from huggingface_hub import login

warnings.filterwarnings("ignore")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ†• v16.8: CONSOLE OUTPUT CAPTURE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class TeeOutput:
	"""
	ĞšĞ»Ğ°ÑÑ Ğ´Ğ»Ñ Ğ´ÑƒĞ±Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ stdout Ğ² Ñ„Ğ°Ğ¹Ğ» Ğ¸ ĞºĞ¾Ğ½ÑĞ¾Ğ»ÑŒ Ğ¾Ğ´Ğ½Ğ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾
	(Ğ°Ğ½Ğ°Ğ»Ğ¾Ğ³ Unix ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹ 'tee')
	"""
	def __init__(self, filename):
			self.terminal = sys.stdout
			self.log = open(filename, 'w', encoding='utf-8')
	
	def write(self, message):
			self.terminal.write(message)
			self.log.write(message)
	
	def flush(self):
			self.terminal.flush()
			self.log.flush()
	
	def close(self):
			if self.log:
					self.log.close()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ’Ğ•Ğ Ğ¡Ğ˜Ğ¯
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

VERSION = "16.28"
VERSION_NAME = "FIX clean_loops() - Ğ·Ğ°Ğ¼ĞµĞ½Ğ° Ğ½Ğ° '...' Ğ²Ğ¼ĞµÑÑ‚Ğ¾ ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¸Ñ"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ“Ğ›ĞĞ‘ĞĞ›Ğ¬ĞĞĞ¯ ĞŸĞ•Ğ Ğ•ĞœĞ•ĞĞĞĞ¯ Ğ”Ğ›Ğ¯ PIPELINE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

_pipeline = None

def get_pipeline():
	"""Ğ›ĞµĞ½Ğ¸Ğ²Ğ°Ñ Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ pyannote pipeline"""
	global _pipeline
	if _pipeline is None:
			print("ğŸ¤– Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° pyannote pipeline...")
			from pyannote.audio import Pipeline
			_pipeline = Pipeline.from_pretrained("pyannote/speaker-diarization-3.1")
			if torch.cuda.is_available():
					_pipeline.to(torch.device("cuda"))
			print("âœ… Pyannote Ğ³Ğ¾Ñ‚Ğ¾Ğ² (3.1)")
	return _pipeline

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ¡ĞĞ—Ğ”ĞĞĞ˜Ğ• Ğ¡Ğ¢Ğ Ğ£ĞšĞ¢Ğ£Ğ Ğ« ĞŸĞĞŸĞĞš
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def ensure_folder_structure(base_folder):
	"""
	Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ñ‚ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ Ğ¿Ğ°Ğ¿Ğ¾Ğº audio/json/txt ĞµÑĞ»Ğ¸ Ğ¸Ñ… Ğ½ĞµÑ‚

	Args:
			base_folder: Path Ğº Ğ¿Ğ°Ğ¿ĞºĞµ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ°

	Returns:
			(audio_dir, json_dir, txt_dir)
	"""
	audio_dir = base_folder / "audio"
	json_dir = base_folder / "json"
	txt_dir = base_folder / "txt"

	# Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ Ğ¿Ğ°Ğ¿ĞºĞ¸ ĞµÑĞ»Ğ¸ Ğ¸Ñ… Ğ½ĞµÑ‚
	json_dir.mkdir(exist_ok=True)
	txt_dir.mkdir(exist_ok=True)

	return audio_dir, json_dir, txt_dir

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ĞšĞĞŸĞ˜Ğ ĞĞ’ĞĞĞ˜Ğ• Ğ’ TEST-RESULTS
# ğŸ†• v16.7: ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ ĞºĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° AI
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def copy_to_test_results(json_files, txt_path, speaker_surname, log_path=None):
	"""
	ğŸ†• v16.18.1: ĞšĞ¾Ğ¿Ğ¸Ñ€ÑƒĞµÑ‚ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ² test-results/latest/ Ğ‘Ğ•Ğ— Ğ¿ĞµÑ€ĞµĞ¸Ğ¼ĞµĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
	
	Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµÑ‚ Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¸Ğ¼ĞµĞ½Ğ° Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ´Ğ»Ñ ÑƒĞ´Ğ¾Ğ±ÑÑ‚Ğ²Ğ° Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ğ¸ Ğ² golden-dataset
	
	Args:
			json_files: Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ğ¿ÑƒÑ‚ĞµĞ¹ Ğº JSON Ñ„Ğ°Ğ¹Ğ»Ğ°Ğ¼
			txt_path: ĞŸÑƒÑ‚ÑŒ Ğº TXT Ñ„Ğ°Ğ¹Ğ»Ñƒ
			speaker_surname: Ğ¤Ğ°Ğ¼Ğ¸Ğ»Ğ¸Ñ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ° (Ğ½Ğµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ Ğ² v16.18.1+)
			log_path: ĞŸÑƒÑ‚ÑŒ Ğº LOG Ñ„Ğ°Ğ¹Ğ»Ñƒ (Ğ¾Ğ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾)
	"""
	# ĞŸÑƒÑ‚ÑŒ Ğº test-results/latest/ Ğ¾Ñ‚Ğ½Ğ¾ÑĞ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ scripts/
	script_dir = Path(__file__).parent
	project_root = script_dir.parent
	test_results_dir = project_root / "test-results" / "latest"
	
	# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ÑÑƒÑ‰ĞµÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ°Ğ¿ĞºĞ¸
	if not test_results_dir.exists():
			print(f"\nâš ï¸ ĞŸĞ°Ğ¿ĞºĞ° test-results/latest/ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°, Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑĞºĞ°Ñ ĞºĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ")
			return
	
	print(f"\nğŸ“Š ĞšĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ² test-results/latest/...")
	
	# ĞÑ‡Ğ¸Ñ‰Ğ°ĞµĞ¼ latest/ (ÑƒĞ´Ğ°Ğ»ÑĞµĞ¼ ÑÑ‚Ğ°Ñ€Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹)
	for old_file in test_results_dir.glob("*"):
			if old_file.is_file() and old_file.name != ".gitkeep":
					old_file.unlink()
					print(f"   ğŸ—‘ï¸ Ğ£Ğ´Ğ°Ğ»Ñ‘Ğ½: {old_file.name}")
	
	# ğŸ†• v16.18.1: ĞšĞ¾Ğ¿Ğ¸Ñ€ÑƒĞµĞ¼ JSON Ñ„Ğ°Ğ¹Ğ»Ñ‹ Ğ‘Ğ•Ğ— Ğ¿ĞµÑ€ĞµĞ¸Ğ¼ĞµĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
	copied_json = []
	for json_path in json_files:
			# Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¸Ğ¼Ñ (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€: NW_Uckpa0001_01.json)
			dest = test_results_dir / json_path.name
			shutil.copy2(json_path, dest)
			copied_json.append(dest.name)
			print(f"   âœ… JSON: {dest.name}")
	
	# ğŸ†• v16.18.1: ĞšĞ¾Ğ¿Ğ¸Ñ€ÑƒĞµĞ¼ TXT Ğ‘Ğ•Ğ— Ğ¿ĞµÑ€ĞµĞ¸Ğ¼ĞµĞ½Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
	if txt_path and txt_path.exists():
			# Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¸Ğ¼Ñ (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€: Ğ˜ÑĞ°ĞµĞ² (02.02).txt)
			dest = test_results_dir / txt_path.name
			shutil.copy2(txt_path, dest)
			print(f"   âœ… TXT: {dest.name}")
	
	# ĞšĞ¾Ğ¿Ğ¸Ñ€ÑƒĞµĞ¼ LOG
	if log_path and log_path.exists():
			# LOG Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ½Ğ°Ğ·Ğ²Ğ°Ñ‚ÑŒ Ğ¿Ğ¾ Ğ±Ğ°Ğ·Ğ¾Ğ²Ğ¾Ğ¼Ñƒ Ğ¸Ğ¼ĞµĞ½Ğ¸ TXT + "_debug.log"
			if txt_path:
					log_dest_name = txt_path.stem + "_debug.log"
			else:
					log_dest_name = "transcription_debug.log"
			
			dest = test_results_dir / log_dest_name
			shutil.copy2(log_path, dest)
			print(f"   âœ… LOG: {dest.name}")
	
	print(f"\nâœ… Ğ¡ĞºĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾ Ğ² test-results/latest/:")
	print(f"   - JSON: {len(copied_json)} Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²")
	print(f"   - TXT: 1 Ñ„Ğ°Ğ¹Ğ»")
	if log_path and log_path.exists():
			print(f"   - LOG: 1 Ñ„Ğ°Ğ¹Ğ» (debug)")
	
	print(f"\nğŸ’¡ Ğ¤Ğ°Ğ¹Ğ»Ñ‹ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ñ‹ Ñ Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ Ğ¸Ğ¼ĞµĞ½Ğ°Ğ¼Ğ¸")
	print(f"   Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ñ‹ Ğº ĞºĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ² golden-dataset (ĞºĞ¾Ğ³Ğ´Ğ° Ğ¿Ğ¾Ğ½Ğ°Ğ´Ğ¾Ğ±Ğ¸Ñ‚ÑÑ)")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ĞĞ¡ĞĞĞ’ĞĞĞ¯ Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ¯ ĞĞ‘Ğ ĞĞ‘ĞĞ¢ĞšĞ˜ ĞĞ”ĞĞĞ“Ğ Ğ¤ĞĞ™Ğ›Ğ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def process_audio_file(
	wav_path,
	whisper_model,
	speaker_surname,
	json_dir,
	min_speakers=2,
	max_speakers=3,
	debug=False
):
	"""
	ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ¾Ğ´Ğ¸Ğ½ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ñ„Ğ°Ğ¹Ğ»

	Args:
			wav_path: Path Ğº WAV Ñ„Ğ°Ğ¹Ğ»Ñƒ
			whisper_model: Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Whisper
			speaker_surname: Ğ¤Ğ°Ğ¼Ğ¸Ğ»Ğ¸Ñ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ³Ğ¾ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ°
			json_dir: Ğ”Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ´Ğ»Ñ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ JSON
			min_speakers: ĞœĞ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ¾Ğ²
			max_speakers: ĞœĞ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ¾Ğ²
			debug: Ğ ĞµĞ¶Ğ¸Ğ¼ Ğ¾Ñ‚Ğ»Ğ°Ğ´ĞºĞ¸

	Returns:
			Path Ğº ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ½Ğ¾Ğ¼Ñƒ JSON Ñ„Ğ°Ğ¹Ğ»Ñƒ
	"""
	print(f"\nğŸ¤ {wav_path.name}")

	# ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ pipeline
	pipeline = get_pipeline()

	# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	# Ğ­Ğ¢ĞĞŸ 1: Ğ”Ğ˜ĞĞ Ğ˜Ğ—ĞĞ¦Ğ˜Ğ¯
	# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	diarization = diarize_audio(pipeline, wav_path, min_speakers, max_speakers)

	if not diarization:
			print(f"  âŒ Ğ”Ğ¸Ğ°Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ½Ğµ ÑƒĞ´Ğ°Ğ»Ğ°ÑÑŒ")
			return None

	# Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° ÑĞ¿Ğ¸ĞºĞµÑ€Ğ¾Ğ²
	stats = compute_speaker_stats(diarization)

	# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	# Ğ­Ğ¢ĞĞŸ 2: Ğ¢Ğ ĞĞĞ¡ĞšĞ Ğ˜Ğ‘ĞĞ¦Ğ˜Ğ¯
	# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	audio_duration = max(turn.end for turn, _ in diarization.itertracks())
	vad_threshold = adaptive_vad_threshold(audio_duration)
	print(f"ğŸ“ ĞĞ´Ğ°Ğ¿Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ VAD: {vad_threshold}")

	result = transcribe_audio(
			whisper_model,
			wav_path,
			language="ru",
			temperature=0.0,
			beam_size=5,
			vad_threshold=vad_threshold
	)

	if not result or not result.get("segments"):
			print("  âŒ Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ°Ñ†Ğ¸Ñ Ğ½Ğµ ÑƒĞ´Ğ°Ğ»Ğ°ÑÑŒ")
			return None

	# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	# Ğ­Ğ¢ĞĞŸ 3: Ğ’Ğ«Ğ ĞĞ’ĞĞ˜Ğ’ĞĞĞ˜Ğ• Ğ¡ Ğ”Ğ˜ĞĞ Ğ˜Ğ—ĞĞ¦Ğ˜Ğ•Ğ™
	# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	# ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ñ€Ğ¾Ğ»Ğ¸ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ¾Ğ²
	speaker_roles = identify_speaker_roles(stats, result["segments"])

	# Ğ’Ñ‹Ñ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°ĞµĞ¼
	segments_raw = align_whisper_with_diarization(
			result["segments"],
			diarization,
			speaker_surname,
			speaker_roles
	)

	# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	# Ğ­Ğ¢ĞĞŸ 4: ĞšĞĞ Ğ Ğ•ĞšĞ¦Ğ˜Ğ˜
	# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

	# 4.1 Ğ”ĞµÑ‚ĞµĞºÑ†Ğ¸Ñ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´ Ğ–ÑƒÑ€Ğ½Ğ°Ğ»Ğ¸ÑÑ‚Ğ°
	segments_raw, cmd_corrections = detect_journalist_commands_cross_segment(
			segments_raw, speaker_surname
	)

	# 4.2 Boundary correction
	segments_raw = boundary_correction_raw(
			segments_raw, speaker_surname, speaker_roles
	)

	# 4.3 Cross-speaker deduplication
	print("\nğŸ”„ Cross-speaker deduplication...")
	segments_raw = remove_cross_speaker_text_duplicates(segments_raw)
	print(f"âœ… ĞŸĞ¾ÑĞ»Ğµ cross-speaker dedup: {len(segments_raw)} ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²")

	# 4.4 Ğ”ĞµĞ´ÑƒĞ¿Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ñ
	print("\nğŸ”„ Ğ”ĞµĞ´ÑƒĞ¿Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ñ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²...")
	segments_raw = deduplicate_segments(segments_raw)
	print(f"âœ… ĞŸĞ¾ÑĞ»Ğµ Ğ´ĞµĞ´ÑƒĞ¿Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸: {len(segments_raw)} ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²")

	# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	# Ğ­Ğ¢ĞĞŸ 5: GAPS (ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ)
	# ğŸ†• v16.5: Ğ£Ğ¼Ğ½Ğ°Ñ Ğ°Ñ‚Ñ€Ğ¸Ğ±ÑƒÑ†Ğ¸Ñ GAP_FILLED Ğ¿Ğ¾ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¼Ñƒ ÑÑ…Ğ¾Ğ´ÑÑ‚Ğ²Ñƒ
	# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	gaps = gap_detector(segments_raw, threshold=3.0)
	gap_segments = []

	if gaps:
			print(f"\nğŸ” Ğ“ĞĞŸĞ« WHISPER:")
			for gap in gaps:
					print(f"   ğŸš¨ GAP {gap['gap_hms_start']}â€“{gap['gap_hms_end']} ({gap['duration']}s)")

			# Force transcribe gaps (v16.5: ÑƒĞ¼Ğ½Ğ°Ñ Ğ°Ñ‚Ñ€Ğ¸Ğ±ÑƒÑ†Ğ¸Ñ)
			gap_segments = force_transcribe_diar_gaps(
					whisper_model, wav_path, gaps, segments_raw, speaker_surname
			)

			if gap_segments:
					print(f"  âœ… Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ Ğ¸Ğ· gaps: {len(gap_segments)} ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²")
					segments_raw.extend(gap_segments)
					segments_raw.sort(key=lambda x: x["start"])

	# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	# ğŸ†• v16.19: Ğ­Ğ¢ĞĞŸ 5.2 - TIMESTAMP CORRECTION Ğ¿Ğ¾ÑĞ»Ğµ gap filling
	# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	segments_raw = correct_timestamp_drift(segments_raw, debug=True)

	# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	# Ğ­Ğ¢ĞĞŸ 6: MERGE REPLICAS
	# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	segments_merged = merge_replicas(segments_raw, debug=True) # ğŸ†• v16.20: Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½ debug=True

	# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	# ğŸ†• v16.19: Ğ­Ğ¢ĞĞŸ 6.1 - TIMESTAMP INJECTION Ğ² Ğ±Ğ»Ğ¾ĞºĞ¸ >30 ÑĞµĞº
	# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	segments_merged = insert_intermediate_timestamps(segments_merged, interval=30.0, debug=True)

	# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	# Ğ­Ğ¢ĞĞŸ 7: SPEAKER CLASSIFICATION v15
	# ğŸ†• v16.13: ĞŸĞµÑ€ĞµĞ´Ğ°Ñ‡Ğ° speaker_roles Ğ´Ğ»Ñ ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ raw_speaker_id
	# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	print("\n" + "="*70)
	print("ğŸ¯ v15: ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ÑĞµĞ¼ Ğ²ĞµÑĞ¾Ğ²ÑƒÑ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ¾Ğ² (v16.13)...")
	print("="*70)
	segments_merged, classification_stats = apply_speaker_classification_v15(
			segments_merged, speaker_surname, speaker_roles, debug=True  # ğŸ†• v16.13: Ğ¿ĞµÑ€ĞµĞ´Ğ°Ñ‘Ğ¼ speaker_roles
	)
	print("="*70)
	print()

	# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	# Ğ­Ğ¢ĞĞŸ 8: TEXT-BASED CORRECTIONS
	# ğŸ†• v16.12: ĞŸĞµÑ€ĞµĞ´Ğ°Ñ‡Ğ° speaker_roles Ğ² split Ğ´Ğ»Ñ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ğ¾Ğ¹ ĞºĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ°Ñ†Ğ¸Ğ¸
	# ğŸ†• v16.11: ĞŸÑ€Ğ°Ğ²Ğ¸Ğ»ÑŒĞ½Ğ°Ñ Ğ»Ğ¾Ğ³Ğ¸ĞºĞ° continuation phrase fix
	# ğŸ†• v16.4: Ğ Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ½Ğ°Ñ Ğ·Ğ°Ñ‰Ğ¸Ñ‚Ğ° Ğ¾Ñ‚ Ğ¿ĞµÑ€ĞµĞ°Ñ‚Ñ€Ğ¸Ğ±ÑƒÑ†Ğ¸Ğ¸ Ğ°Ğ½Ğ¾Ğ½ÑĞ¾Ğ² Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²
	# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	print("\nâœ‚ï¸ Ğ Ğ°Ğ·Ğ´ĞµĞ»ĞµĞ½Ğ¸Ğµ mixed-speaker ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ² (v16.21)...")
	segments_merged = split_mixed_speaker_segments(
			segments_merged, speaker_surname, speaker_roles  # ğŸ†• v16.12: Ğ¿ĞµÑ€ĞµĞ´Ğ°Ñ‘Ğ¼ speaker_roles
	)
	
	print("\nğŸ” Text-based correction (v16.4)...")
	segments_merged = text_based_correction(segments_merged, speaker_surname)

	# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	# ğŸ†• v16.19: Ğ­Ğ¢ĞĞŸ 8.1 - HALLUCINATION REMOVAL
	# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	segments_merged = filter_hallucination_segments(segments_merged, debug=True)

	# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	# Ğ­Ğ¢ĞĞŸ 9: Ğ’ĞĞ›Ğ˜Ğ”ĞĞ¦Ğ˜Ğ¯ + AUTO-MERGE
	# ğŸ†• v16.0: ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° raw_speaker_id Ğ¿ĞµÑ€ĞµĞ´ ÑĞ»Ğ¸ÑĞ½Ğ¸ĞµĞ¼
	# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	errors = validate_adjacent_same_speaker(segments_merged)

	if errors:
			segments_merged = auto_merge_adjacent_same_speaker(segments_merged)
			validate_adjacent_same_speaker(segments_merged)

	# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	# Ğ­Ğ¢ĞĞŸ 10: Ğ­ĞšĞ¡ĞŸĞĞ Ğ¢
	# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
	validation_report = generate_validation_report(segments_merged, speaker_surname)

	file_info = {
			"filename": wav_path.name,
			"duration": audio_duration,
			"speaker_surname": speaker_surname,
			"whisper_model": "large-v3-turbo",
			"vad_threshold": vad_threshold,
			"gaps_detected": len(gaps),
			"gaps_final": len(gaps),
			"retry_added": len(gap_segments),
			"speaker_stats": dict(stats),
			"pipeline_version": VERSION,  # ğŸ†• v16.12: Ğ²ĞµÑ€ÑĞ¸Ñ Ğ² metadata
			"params": {
					"model_name": "large-v3-turbo",
					"language": "ru",
					"min_speakers": min_speakers,
					"max_speakers": max_speakers
			}
	}

	corrections_log = {
			"journalist_commands_detected": len(cmd_corrections),
			"journalist_commands_details": cmd_corrections
	}

	json_path = json_dir / f"{wav_path.stem}.json"
	export_to_json(
			json_path,
			segments_raw,
			segments_merged,
			file_info,
			speaker_roles,
			validation_report,
			corrections_log
	)

	print(f" âœ… {json_path.name} (v{VERSION}, roles={speaker_roles})")
	return json_path

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
	"""
	Ğ“Ğ»Ğ°Ğ²Ğ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ - Ğ¸Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ñ€ĞµĞ¶Ğ¸Ğ¼
	
	Returns:
			(json_files, txt_path, speaker_surname) Ğ´Ğ»Ñ ĞºĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ² test-results
	"""

	# Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ
	login(token=HF_TOKEN)

	print(f"ğŸ”¥ ĞŸĞĞ™ĞŸĞ›ĞĞ™Ğ v{VERSION}: {VERSION_NAME}")
	print(f"GPU: {'âœ… CUDA' if torch.cuda.is_available() else 'âš ï¸ CPU'}")
	print("=" * 70)
	print(f"ğŸ’¡ v16.28 Ğ˜Ğ—ĞœĞ•ĞĞ•ĞĞ˜Ğ¯:")
	print("   âœ… clean_loops() Ñ‚ĞµĞ¿ĞµÑ€ÑŒ Ğ—ĞĞœĞ•ĞĞ¯Ğ•Ğ¢ Ğ½Ğ° '...' (ĞĞ• ÑƒĞ´Ğ°Ğ»ÑĞµÑ‚!)")
	print("   âœ… Threshold: 95% (Ğ¾Ñ‡ĞµĞ½ÑŒ ÑÑ‚Ñ€Ğ¾Ğ³Ğ¾)")
	print("   âœ… Min n-gram: 4 ÑĞ»Ğ¾Ğ²Ğ° (Ğ½Ğµ 2!)")
	print("   âœ… Gap-filled: threshold 97%")
	print("   âœ… Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚, ĞĞ• Ñ‚ĞµÑ€ÑĞµĞ¼ ÑĞ¼Ñ‹ÑĞ»!")
	print()
	print(f"ğŸ’¡ v16.27 Ğ˜Ğ—ĞœĞ•ĞĞ•ĞĞ˜Ğ¯:")
	print("   âœ… clean_loops() ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ° - ÑƒĞ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ hallucination loops")
	print("   âœ… N-gram Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· (2-8 ÑĞ»Ğ¾Ğ²) Ñ adaptive threshold")
	print("   âœ… ĞšĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğµ Ñ„Ñ€Ğ°Ğ·Ñ‹ (<5 ÑĞ»Ğ¾Ğ²) â†’ 85%, Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğµ â†’ 75%")
	print("   âœ… Gap-filled ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ñ‹: threshold +10%")
	print()
	print("ğŸ’¡ v16.22 Ğ˜Ğ—ĞœĞ•ĞĞ•ĞĞ˜Ğ¯:")
	print("   âœ… Ğ‘ĞĞ“ #1 FIX: Ğ”ÑƒĞ±Ğ»Ğ¸Ñ€ÑƒÑÑ‰Ğ¸ĞµÑÑ timestamp (00:00:55 00:00:55)")
	print("   âœ… Ğ‘ĞĞ“ #2 FIX: Timestamp Ğ½Ğ°Ğ·Ğ°Ğ´ (00:03:06 â†’ 00:03:03)")
	print("   âœ… insert_intermediate_timestamps: Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ´ÑƒĞ±Ğ»Ñ Ğ¿ĞµÑ€ĞµĞ´ Ğ²ÑÑ‚Ğ°Ğ²ĞºĞ¾Ğ¹")
	print("   âœ… correct_timestamp_drift: Ğ¼Ğ¾Ğ½Ğ¾Ñ‚Ğ¾Ğ½Ğ½Ğ¾ÑÑ‚ÑŒ (Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ²Ğ¿ĞµÑ€Ñ‘Ğ´)")
	print()
	print("ğŸ’¡ v16.21 Ğ˜Ğ—ĞœĞ•ĞĞ•ĞĞ˜Ğ¯:")
	print("   âœ… ĞšĞ Ğ˜Ğ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ™ FIX: ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ continuation phrase")
	print("   âœ… ĞĞ°ĞºĞ¾Ğ¿Ğ»ĞµĞ½Ğ½Ñ‹Ğ¹ Ñ‚ĞµĞºÑÑ‚ Ñ‚ĞµĞ¿ĞµÑ€ÑŒ Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµÑ‚ Ñ‚ĞµĞºÑƒÑ‰ĞµĞµ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ")
	print("   âœ… Threshold: ĞµÑĞ»Ğ¸ Ñ„Ñ€Ğ°Ğ·Ğ° Ğ±Ğ»Ğ¸Ğ¶Ğµ Ğº Ğ½Ğ°Ñ‡Ğ°Ğ»Ñƒ (â‰¤30%) â†’ ÑÑ‡Ğ¸Ñ‚Ğ°ĞµĞ¼ \"Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ¾Ğ¼\"")
	print("   âœ… Debug: Ğ¿Ğ¾ĞºĞ°Ğ· Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ Ğ¸ Ñ€Ğ°ÑÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ Ğ´Ğ¾ ĞºĞ¾Ğ½Ñ†Ğ° Ñ‚ĞµĞºÑÑ‚Ğ°")
	print()
	print("ğŸ’¡ v16.19 Ğ˜Ğ—ĞœĞ•ĞĞ•ĞĞ˜Ğ¯:")
	print("   âœ… Ğ­Ğ¢ĞĞŸ 5.2: Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ ÑĞ´Ğ²Ğ¸Ğ³Ğ° timestamp Ğ¿Ğ¾ÑĞ»Ğµ gap filling")
	print("   âœ… Ğ­Ğ¢ĞĞŸ 6.1: Ğ’ÑÑ‚Ğ°Ğ²ĞºĞ° Ğ¿Ñ€Ğ¾Ğ¼ĞµĞ¶ÑƒÑ‚Ğ¾Ñ‡Ğ½Ñ‹Ñ… timestamp Ğ² Ğ±Ğ»Ğ¾ĞºĞ¸ >30 ÑĞµĞº")
	print("   âœ… Ğ­Ğ¢ĞĞŸ 8.1: Ğ£Ğ´Ğ°Ğ»ĞµĞ½Ğ¸Ğµ Ğ´ÑƒĞ±Ğ»ĞµĞ¹ + 'ĞŸÑ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½Ğ¸Ğµ ÑĞ»ĞµĞ´ÑƒĞµÑ‚'")
	print("   âœ… Continuation phrase threshold: 80% â†’ 90%")
	print()
	print("ğŸ’¡ v16.12 Ğ˜Ğ—ĞœĞ•ĞĞ•ĞĞ˜Ğ¯:")
	print("   âœ… ĞšĞ Ğ˜Ğ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞ˜Ğ™ FIX: raw_speaker_id Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ÑĞµÑ‚ÑÑ Ğ¿Ñ€Ğ¸ split")
	print("   âœ… Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ñ‹Ğ¹ Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³ speaker_roles (Ğ˜ÑĞ°ĞµĞ² â†’ SPEAKER_01)")
	print("   âœ… Ğ˜ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½ Ğ±Ğ°Ğ³: TXT Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ¸Ğ» ÑÑ‚Ğ°Ñ€Ñ‹Ğ¹ speaker Ğ²Ğ¼ĞµÑÑ‚Ğ¾ Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾")
	print("   âœ… Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½Ğ¾ Ğ¿Ğ¾Ğ»Ğµ pipeline_version Ğ² JSON metadata")
	print()
	print("ğŸ’¡ v16.11 Ğ˜Ğ—ĞœĞ•ĞĞ•ĞĞ˜Ğ¯:")
	print("   âœ… ĞŸĞ ĞĞ’Ğ˜Ğ›Ğ¬ĞĞĞ¯ Ğ»Ğ¾Ğ³Ğ¸ĞºĞ° continuation phrase fix")
	print("   âœ… ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ° Ğ’ĞĞ£Ğ¢Ğ Ğ˜ Ñ‚ĞµĞºÑƒÑ‰ĞµĞ³Ğ¾ split (Ğ½Ğµ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ğ¹ ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚)")
	print()

	# Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ Ğ¿ÑƒÑ‚Ğ¸ Ğº Ğ¿Ğ°Ğ¿ĞºĞµ
	folder_path = input("ğŸ“‚ ĞŸÑƒÑ‚ÑŒ Ğº Ğ¿Ğ°Ğ¿ĞºĞµ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ° (\\\\  Ğ¸Ğ»Ğ¸ /): ").strip().replace('"', '')
	folder = Path(folder_path)

	if not folder.exists():
			print("âŒ ĞŸĞ°Ğ¿ĞºĞ° Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°!")
			return None, None, None

	print(f"âœ… ĞŸĞ°Ğ¿ĞºĞ°: {folder}")

	# Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ñƒ Ğ¿Ğ°Ğ¿Ğ¾Ğº
	audio_dir, json_dir, txt_dir = ensure_folder_structure(folder)

	if not audio_dir.exists():
			print(f"âŒ ĞŸĞ°Ğ¿ĞºĞ° audio/ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°! Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹: {audio_dir}")
			return None, None, None

	print(f"ğŸ“ audio/: {audio_dir}")
	print(f"ğŸ“ json/:  {json_dir}")
	print(f"ğŸ“ txt/:   {txt_dir}")

	# Ğ’Ñ‹Ğ±Ğ¾Ñ€ Ñ€ĞµĞ¶Ğ¸Ğ¼Ğ°
	mode = input("\nâš™ï¸ Ğ ĞµĞ¶Ğ¸Ğ¼ [Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ğ¹]: ").strip().lower() or "Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ğ¹"
	print(f"\nğŸš€ Ğ ĞµĞ¶Ğ¸Ğ¼: {mode} (v{VERSION})")

	# Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Whisper
	print("\nğŸ¤– Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Whisper large-v3-turbo...")
	whisper_model = whisper.load_model("large-v3-turbo")
	print("âœ… Whisper Ğ³Ğ¾Ñ‚Ğ¾Ğ²")

	# ĞŸĞ°Ñ€ÑĞ¸Ğ½Ğ³ Ğ¸Ğ¼ĞµĞ½Ğ¸ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ°
	speaker_surname, date, full_name = parse_speaker_folder(folder.name)
	print(f"\nğŸ‘¤ '{folder.name}' â†’ {full_name}.txt")
	print(f"ğŸ¤– large-v3-turbo + pyannote v{VERSION}...")

	# ĞŸĞ¾Ğ¸ÑĞº WAV Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ² audio/
	wav_files = sorted(audio_dir.glob("*.wav"))

	if not wav_files:
			print(f"âŒ WAV Ñ„Ğ°Ğ¹Ğ»Ñ‹ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹ Ğ² {audio_dir}!")
			return None, None, None

	print(f"\nâœ… ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ WAV: {len(wav_files)}")

	json_files = []

	# ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²
	for wav_path in tqdm(wav_files, desc="JSON + Ğ”Ğ¸Ğ°Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ"):
			json_path = process_audio_file(
					wav_path,
					whisper_model,
					speaker_surname,
					json_dir,
					min_speakers=2,
					max_speakers=3,
					debug=True
			)

			if json_path:
					json_files.append(json_path)

	print(f"\nâœ… JSON: {len(json_files)}/{len(wav_files)}")

	# Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ TXT
	txt_path = None
	if json_files:
			txt_path = txt_dir / f"{full_name}.txt"
			print(f"\nğŸ“„ {len(json_files)} JSON â†’ {txt_path.name}")
			jsons_to_txt(json_files, txt_path, speaker_surname)
			print(f"âœ… TXT: {txt_path} (v{VERSION})")

	print(f"\nâœ… Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ğ¾! ğŸš€ (v{VERSION})")
	print(f"\nğŸ“‚ Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹:")
	print(f"   JSON: {json_dir}")
	print(f"   TXT:  {txt_dir}")
	
	# Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµĞ¼ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ ĞºĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ² test-results
	return json_files, txt_path, speaker_surname

if __name__ == "__main__":
	# ğŸ†• v16.8: Ğ—Ğ°Ñ…Ğ²Ğ°Ñ‚ console output Ğ² Ñ„Ğ°Ğ¹Ğ»
	log_file = Path.cwd() / "transcription_debug.log"
	
	# Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‘Ğ¼ tee Ğ´Ğ»Ñ stdout
	tee = TeeOutput(log_file)
	original_stdout = sys.stdout
	sys.stdout = tee
	
	json_files = None
	txt_path = None
	speaker_surname = None
	
	try:
			# Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ main Ğ¸ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹
			json_files, txt_path, speaker_surname = main()
	finally:
			# Ğ’Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ stdout Ğ¸ Ğ·Ğ°ĞºÑ€Ñ‹Ğ²Ğ°ĞµĞ¼ Ñ„Ğ°Ğ¹Ğ»
			sys.stdout = original_stdout
			tee.close()
			
			# âœ… v16.8.1: ĞšĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ ĞŸĞĞ¡Ğ›Ğ• Ğ·Ğ°ĞºÑ€Ñ‹Ñ‚Ğ¸Ñ Ñ„Ğ°Ğ¹Ğ»Ğ°
			if json_files and txt_path and log_file.exists():
					print(f"\nğŸ’¾ DEBUG log ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ñ‘Ğ½: {log_file}")
					copy_to_test_results(json_files, txt_path, speaker_surname, log_file)
			else:
					print(f"\nğŸ’¾ DEBUG log ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ñ‘Ğ½: {log_file}")
					print("   TEST: ĞšĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ² test-results Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½Ğ¾")
