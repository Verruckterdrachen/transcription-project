"""
tests/simulations/sim_bugC_gap_overlap.py
Ğ¡Ğ¸Ğ¼ÑƒĞ»ÑÑ†Ğ¸Ñ BAG_C (Ã—3) + #18: GAP fill Ğ´ÑƒĞ±Ğ»Ğ¸Ñ€ÑƒĞµÑ‚ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚ ÑĞ¾ÑĞµĞ´Ğ½Ğ¸Ñ… ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ².

ROOT CAUSE:
  _remove_gap_overlap_with_next/prev Ğ²Ñ‹Ğ·Ñ‹Ğ²Ğ°Ğ»Ğ¸ÑÑŒ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¿Ñ€Ğ¸ seg_end != original_end.
  _remove_gap_overlap_with_prev: Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ğ¹ == Ğ½Ğµ Ğ»Ğ¾Ğ²Ğ¸Ğ» ASR-Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸ Ğ¸ substring-ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ñ.

FIX v17.12:
  1. ĞĞ±Ğ° Ğ²Ñ‹Ğ·Ğ¾Ğ²Ğ° overlap removal â€” Ğ²ÑĞµĞ³Ğ´Ğ° (Ğ½Ğµ Ğ·Ğ°Ğ²Ğ¸ÑÑÑ‚ Ğ¾Ñ‚ Ñ„Ğ»Ğ°Ğ³Ğ° Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ†)
  2. _remove_gap_overlap_with_prev â€” Ñ‚Ñ€Ğ¸ ÑƒÑ€Ğ¾Ğ²Ğ½Ñ matching:
       exact tail â†’ 1-mismatch fuzzy â†’ substring Ğ² prev
  3. max_check_words Ğ´Ğ»Ñ next: 5 â†’ 7

Ğ—Ğ°Ğ¿ÑƒÑĞº: python tests/simulations/sim_bugC_gap_overlap.py
ĞĞ¶Ğ¸Ğ´Ğ°Ğ½Ğ¸Ğµ: OLD â†’ RED (Ğ´ÑƒĞ±Ğ»ÑŒ Ğ¾ÑÑ‚Ğ°Ñ‘Ñ‚ÑÑ), NEW â†’ GREEN (Ğ´ÑƒĞ±Ğ»ÑŒ ÑƒĞ´Ğ°Ğ»Ñ‘Ğ½)
"""

from difflib import SequenceMatcher
import sys


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Ğ’ÑĞ¿Ğ¾Ğ¼Ğ¾Ğ³Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ (Ğ¾Ğ±Ñ‰Ğ¸Ğµ)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _looks_like_restart(gap_text, next_text, min_shared_ratio=0.50):
    if not gap_text or not next_text:
        return False
    def sig_words(t):
        ws = [w.lower().strip('.,!?;:Â«Â»"()-â€“â€”') for w in t.split()]
        return set(w for w in ws if len(w) >= 4)
    g = sig_words(gap_text)
    n = sig_words(next_text)
    if not g:
        return False
    return (len(g & n) / len(g)) >= min_shared_ratio


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# OLD Ğ²ĞµÑ€ÑĞ¸Ñ (Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ Ğ±Ğ°Ğ³Ğ¸)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _remove_gap_overlap_with_next_OLD(gap_text, next_text, max_check_words=5):
    if not gap_text or not next_text:
        return gap_text
    gap_words  = gap_text.strip().split()
    next_words = next_text.strip().split()
    def normalize(w):
        return w.lower().strip('.,!?;:Â«Â»"()-â€“')
    next_head = [normalize(w) for w in next_words[:max_check_words]]
    for n in range(min(max_check_words, len(gap_words)), 0, -1):
        gap_tail = [normalize(w) for w in gap_words[-n:]]
        if gap_tail == next_head[:n]:
            return ' '.join(gap_words[:-n]).strip()
    last_word = normalize(gap_words[-1])
    if len(last_word) <= 3:
        first_next = next_head[0] if next_head else ""
        if first_next and not first_next.startswith(last_word):
            return ' '.join(gap_words[:-1]).strip()
    return gap_text


def _remove_gap_overlap_with_prev_OLD(gap_text, prev_text, max_check_words=6):
    """OLD: Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğµ == tail ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğµ."""
    if not gap_text or not prev_text:
        return gap_text
    gap_words  = gap_text.strip().split()
    prev_words = prev_text.strip().split()
    def norm(w):
        return w.lower().strip('.,!?;:Â«Â»"()-â€“â€”')
    gap_n  = [norm(w) for w in gap_words]
    prev_n = [norm(w) for w in prev_words]
    for n in range(min(max_check_words, len(gap_words), len(prev_words)), 0, -1):
        if gap_n[:n] == prev_n[-n:]:
            return " ".join(gap_words[n:]).strip()
    return gap_text


def simulate_gap_OLD(gap_text, prev_text, next_text, boundary_adjusted=False):
    text = gap_text
    if next_text and boundary_adjusted:
        text = _remove_gap_overlap_with_next_OLD(text, next_text, max_check_words=5)
        if not text.strip():
            return ""
        if _looks_like_restart(text, next_text):
            return ""
    if prev_text and boundary_adjusted:
        text = _remove_gap_overlap_with_prev_OLD(text, prev_text)
        if not text.strip():
            return ""
    return text


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# NEW Ğ²ĞµÑ€ÑĞ¸Ñ â€” Ñ„Ğ¸ĞºÑ v17.12
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _remove_gap_overlap_with_next_NEW(gap_text, next_text, max_check_words=7):
    if not gap_text or not next_text:
        return gap_text
    gap_words  = gap_text.strip().split()
    next_words = next_text.strip().split()
    def normalize(w):
        return w.lower().strip('.,!?;:Â«Â»"()-â€“')
    next_head = [normalize(w) for w in next_words[:max_check_words]]
    for n in range(min(max_check_words, len(gap_words)), 0, -1):
        gap_tail = [normalize(w) for w in gap_words[-n:]]
        if gap_tail == next_head[:n]:
            return ' '.join(gap_words[:-n]).strip()
    last_word = normalize(gap_words[-1])
    if len(last_word) <= 3:
        first_next = next_head[0] if next_head else ""
        if first_next and not first_next.startswith(last_word):
            return ' '.join(gap_words[:-1]).strip()
    return gap_text


def _remove_gap_overlap_with_prev_NEW(gap_text, prev_text, max_check_words=6):
    """
    NEW v17.12: Ñ‚Ñ€Ğ¸ ÑƒÑ€Ğ¾Ğ²Ğ½Ñ matching.
    1. Ğ¢Ğ¾Ñ‡Ğ½Ğ¾Ğµ tail ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğµ
    2. 1 ASR-Ğ¾ÑˆĞ¸Ğ±ĞºĞ° Ğ´Ğ¾Ğ¿ÑƒÑÑ‚Ğ¸Ğ¼Ğ° (n-1 Ğ¸Ğ· n ÑĞ»Ğ¾Ğ² Ñ‚Ğ¾Ñ‡Ğ½Ñ‹)
    3. Substring: head(GAP) Ğ²ÑÑ‚Ñ€ĞµÑ‡Ğ°ĞµÑ‚ÑÑ Ğ²Ğ½ÑƒÑ‚Ñ€Ğ¸ prev
    """
    if not gap_text or not prev_text:
        return gap_text
    gap_words  = gap_text.strip().split()
    prev_words = prev_text.strip().split()
    def norm(w):
        return w.lower().strip('.,!?;:Â«Â»"()-â€“â€”')
    gap_n  = [norm(w) for w in gap_words]
    prev_n = [norm(w) for w in prev_words]

    # 1. Ğ¢Ğ¾Ñ‡Ğ½Ğ¾Ğµ tail ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğµ
    for n in range(min(max_check_words, len(gap_words), len(prev_words)), 0, -1):
        if gap_n[:n] == prev_n[-n:]:
            return " ".join(gap_words[n:]).strip()

    # 2. 1 ASR-Ğ¾ÑˆĞ¸Ğ±ĞºĞ° Ğ´Ğ¾Ğ¿ÑƒÑÑ‚Ğ¸Ğ¼Ğ°
    for n in range(min(max_check_words, len(gap_words), len(prev_words)), 2, -1):
        tail_prev = prev_n[-n:]
        head_gap  = gap_n[:n]
        mismatches = sum(1 for a, b in zip(head_gap, tail_prev) if a != b)
        if mismatches == 1:
            return " ".join(gap_words[n:]).strip()

    # 3. Substring: head(GAP) Ğ²ÑÑ‚Ñ€ĞµÑ‡Ğ°ĞµÑ‚ÑÑ Ğ²Ğ½ÑƒÑ‚Ñ€Ğ¸ prev
    check_len = min(max_check_words, len(gap_n))
    head_gap  = gap_n[:check_len]
    for start in range(len(prev_n) - check_len + 1):
        if prev_n[start:start + check_len] == head_gap:
            return " ".join(gap_words[check_len:]).strip()

    return gap_text


def simulate_gap_NEW(gap_text, prev_text, next_text, boundary_adjusted=False):
    """NEW: overlap removal Ğ²Ñ‹Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ÑÑ Ğ’Ğ¡Ğ•Ğ“Ğ”Ğ."""
    text = gap_text

    if next_text:
        text = _remove_gap_overlap_with_next_NEW(text, next_text, max_check_words=7)
        if not text.strip():
            return ""
        if _looks_like_restart(text, next_text):
            return ""

    if prev_text:
        text = _remove_gap_overlap_with_prev_NEW(text, prev_text)
        if not text.strip():
            return ""

    return text


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# TEST CASES (Ğ¸ÑĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ğµ)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

TEST_CASES = [
    {
        "id": "TC-01",
        "desc": "BAG_C_3 (00:34:57): Ğ¿Ğ°Ñ‚Ñ€ÑƒĞ»Ğ¸ â€” Ğ³Ñ€Ğ°Ğ½Ğ¸Ñ†Ğ° ĞĞ• Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ° (boundary_adjusted=False)",
        "gap_text":  "Ğ¾Ñ„Ğ¸Ñ†ĞµÑ€ÑĞºĞ¸Ğ¼Ğ¸ Ğ¿Ğ°Ñ‚Ñ€ÑƒĞ»ÑĞ¼Ğ¸ Ğ° ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ Ğ¾Ñ„Ğ¸Ñ†ĞµÑ€ÑĞºĞ¸Ğ¼Ğ¸ Ğ¿Ğ°Ñ‚Ñ€ÑƒĞ»ÑĞ¼Ğ¸",
        "prev_text": "ĞºĞ¾Ğ³Ğ´Ğ° Ğ¿Ñ€Ğ¸Ğ±Ñ‹Ğ²Ğ°ÑÑ‰Ğ°Ñ Ğ°Ñ€Ñ‚Ğ¸Ğ»Ğ»ĞµÑ€Ğ¸Ñ Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞ»Ğ°ÑÑŒ Ğ½Ğµ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾ Ñ€ĞµĞ³ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²Ñ‰Ğ¸ĞºĞ°Ğ¼Ğ¸ Ğ° ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ Ğ¾Ñ„Ğ¸Ñ†ĞµÑ€ÑĞºĞ¸Ğ¼Ğ¸ Ğ¿Ğ°Ñ‚Ñ€ÑƒĞ»ÑĞ¼Ğ¸",
        "next_text": "Ğ¸ ÑÑ‚Ğ¾ Ğ´Ğ°Ğ²Ğ°Ğ»Ğ¾ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾ ÑĞ¾ÑÑ€ĞµĞ´Ğ¾Ñ‚Ğ¾Ñ‡Ğ¸Ñ‚ÑŒ Ğ¾Ğ³Ğ¾Ğ½ÑŒ",
        "boundary_adjusted": False,
        # FIX ÑƒĞ´Ğ°Ğ»ÑĞµÑ‚ Ğ²ĞµĞ´ÑƒÑ‰Ğ¸Ğ¹ overlap Â«Ğ¾Ñ„Ğ¸Ñ†ĞµÑ€ÑĞºĞ¸Ğ¼Ğ¸ Ğ¿Ğ°Ñ‚Ñ€ÑƒĞ»ÑĞ¼Ğ¸Â» Ğ¸Ğ· Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° GAP.
        # ĞÑÑ‚Ğ°Ğ²ÑˆĞµĞµÑÑ Â«Ğ° ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ Ğ¾Ñ„Ğ¸Ñ†ĞµÑ€ÑĞºĞ¸Ğ¼Ğ¸ Ğ¿Ğ°Ñ‚Ñ€ÑƒĞ»ÑĞ¼Ğ¸Â» â€” ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ñ‹Ğ¹ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚.
        "must_contain": "Ğ° ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ Ğ¾Ñ„Ğ¸Ñ†ĞµÑ€ÑĞºĞ¸Ğ¼Ğ¸ Ğ¿Ğ°Ñ‚Ñ€ÑƒĞ»ÑĞ¼Ğ¸",
        "must_not_contain": None,
        "note": "OLD ÑĞºĞ¸Ğ¿Ğ°ĞµÑ‚ prev-overlap (boundary_adjusted=False). NEW ÑƒĞ´Ğ°Ğ»ÑĞµÑ‚ Ğ²ĞµĞ´ÑƒÑ‰Ğ¸Ğ¹ Ğ´ÑƒĞ±Ğ»ÑŒ.",
    },
    {
        "id": "TC-02",
        "desc": "BAG_C_4 (00:27:28): ÑÑ‚Ñ€ĞµĞ»ĞºĞ¾Ğ²Ğ°Ñ Ğ±Ñ€Ğ¸Ğ³Ğ°Ğ´Ğ° â€” substring match Ğ²Ğ½ÑƒÑ‚Ñ€Ğ¸ prev",
        "gap_text":  "ÑÑ‚Ñ€ĞµĞ»ĞºĞ¾Ğ²Ğ°Ñ Ğ±Ñ€Ğ¸Ğ³Ğ°Ğ´Ğ° Ğ´Ğ²Ğ¸Ğ³Ğ°ĞµÑ‚ÑÑ Ğ²Ğ¿ĞµÑ€Ñ‘Ğ´ Ğ½Ğ° ÑƒÑ‡Ğ°ÑÑ‚ĞºĞµ Ğ³Ğ´Ğµ Ğ±Ñ‹Ğ» Ğ·Ğ°Ñ…Ğ²Ğ°Ñ‡ĞµĞ½ Ğ¿Ğ»Ğ°Ñ†Ğ´Ğ°Ñ€Ğ¼",
        "prev_text": "Ğ¸Ğ¼ĞµĞ½Ğ½Ğ¾ ÑÑ‚Ñ€ĞµĞ»ĞºĞ¾Ğ²Ğ°Ñ Ğ±Ñ€Ğ¸Ğ³Ğ°Ğ´Ğ° Ğ´Ğ²Ğ¸Ğ³Ğ°ĞµÑ‚ÑÑ Ğ²Ğ¿ĞµÑ€Ñ‘Ğ´ Ğ½Ğ° ÑƒÑ‡Ğ°ÑÑ‚ĞºĞµ Ğ³Ğ´Ğµ Ğ±Ñ‹Ğ» Ğ·Ğ°Ñ…Ğ²Ğ°Ñ‡ĞµĞ½ Ğ¿Ğ»Ğ°Ñ†Ğ´Ğ°Ñ€Ğ¼ 36-Ğ¹ Ğ´Ğ¸Ğ²Ğ¸Ğ·Ğ¸Ğ¸ Ğ¡Ğ¸Ğ¼Ğ¾Ğ½ÑĞºĞ°",
        "next_text": "36-Ğ¹ Ğ´Ğ¸Ğ²Ğ¸Ğ·Ğ¸Ğ¸ Ğ¡Ğ¸Ğ¼Ğ¾Ğ½ÑĞºĞ° Ğ¸ ÑÑ‚Ğ¾ Ğ¾ĞºĞ°Ğ·Ğ°Ğ»Ğ¾ÑÑŒ Ñ€ĞµÑˆĞ°ÑÑ‰Ğ¸Ğ¼",
        "boundary_adjusted": False,
        # GAP Ñ†ĞµĞ»Ğ¸ĞºĞ¾Ğ¼ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ÑÑ Ğ² prev â†’ Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ Ğ¿Ğ¾Ğ»Ğ½Ğ¾ÑÑ‚ÑŒÑ ÑƒĞ´Ğ°Ğ»Ñ‘Ğ½ (Ğ¿ÑƒÑÑ‚Ğ°Ñ ÑÑ‚Ñ€Ğ¾ĞºĞ°)
        "must_contain": None,
        "must_not_contain": "ÑÑ‚Ñ€ĞµĞ»ĞºĞ¾Ğ²Ğ°Ñ Ğ±Ñ€Ğ¸Ğ³Ğ°Ğ´Ğ° Ğ´Ğ²Ğ¸Ğ³Ğ°ĞµÑ‚ÑÑ",
        "note": "GAP Ñ†ĞµĞ»Ğ¸ĞºĞ¾Ğ¼ â€” substring prev. NEW ÑƒĞ´Ğ°Ğ»ÑĞµÑ‚ Ñ‡ĞµÑ€ĞµĞ· substring match.",
    },
    {
        "id": "TC-03",
        "desc": "BAG_C_5 / #18 (00:21:28): Â«Ğ²Ğ¿Ñ€Ğ°Ğ²ÑŒÂ» Ğ²Ğ¼ĞµÑÑ‚Ğ¾ Â«Ğ²Ğ¿Ğ»Ğ¾Ñ‚ÑŒÂ» â€” 1 ASR mismatch",
        "gap_text":  "Ğ²Ğ¿Ñ€Ğ°Ğ²ÑŒ Ğ´Ğ¾ ÑĞ°Ğ¼Ñ‹Ñ… ĞºÑ€ÑƒĞ¿Ğ½Ñ‹Ñ… ĞºĞ°Ğ»Ğ¸Ğ±Ñ€Ğ¾Ğ² Ğ¸ ĞµÑ‰Ñ‘ Ğ¾Ğ´Ğ½Ğ¸Ğ¼ Ñ„Ğ°ĞºÑ‚Ğ¾Ñ€Ğ¾Ğ¼",
        "prev_text": "Ğ±Ñ‹Ğ»Ğ° Ğ½ĞµĞ¼ĞµÑ†ĞºĞ°Ñ Ğ°Ñ€Ñ‚Ğ¸Ğ»Ğ»ĞµÑ€Ğ¸Ñ Ğ²Ğ¿Ğ»Ğ¾Ñ‚ÑŒ Ğ´Ğ¾ ÑĞ°Ğ¼Ñ‹Ñ… ĞºÑ€ÑƒĞ¿Ğ½Ñ‹Ñ… ĞºĞ°Ğ»Ğ¸Ğ±Ñ€Ğ¾Ğ²",
        "next_text": "ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ ÑƒÑ‡Ğ¸Ñ‚Ñ‹Ğ²Ğ°Ñ‚ÑŒ Ğ±Ñ‹Ğ»Ğ° Ğ½ĞµĞ¼ĞµÑ†ĞºĞ°Ñ Ğ°Ñ€Ñ‚Ğ¸Ğ»Ğ»ĞµÑ€Ğ¸Ñ",
        "boundary_adjusted": False,
        # head_gap[:4] = [Ğ²Ğ¿Ñ€Ğ°Ğ²ÑŒ, Ğ´Ğ¾, ÑĞ°Ğ¼Ñ‹Ñ…, ĞºÑ€ÑƒĞ¿Ğ½Ñ‹Ñ…]
        # tail_prev[-4:] = [Ğ²Ğ¿Ğ»Ğ¾Ñ‚ÑŒ, Ğ´Ğ¾, ÑĞ°Ğ¼Ñ‹Ñ…, ĞºÑ€ÑƒĞ¿Ğ½Ñ‹Ñ…] â†’ 1 mismatch â†’ ÑƒĞ´Ğ°Ğ»ÑĞµĞ¼
        "must_contain": None,
        "must_not_contain": "Ğ²Ğ¿Ñ€Ğ°Ğ²ÑŒ Ğ´Ğ¾ ÑĞ°Ğ¼Ñ‹Ñ… ĞºÑ€ÑƒĞ¿Ğ½Ñ‹Ñ…",
        "note": "1 ASR-Ğ¾ÑˆĞ¸Ğ±ĞºĞ°: Â«Ğ²Ğ¿Ñ€Ğ°Ğ²ÑŒÂ»â‰ Â«Ğ²Ğ¿Ğ»Ğ¾Ñ‚ÑŒÂ», Ğ¾ÑÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ 3 ÑĞ»Ğ¾Ğ²Ğ° Ñ‚Ğ¾Ñ‡Ğ½Ñ‹ â†’ NEW Ğ»Ğ¾Ğ²Ğ¸Ñ‚.",
    },
    {
        "id": "TC-04",
        "desc": "Regression: Ñ‡Ğ¸ÑÑ‚Ñ‹Ğ¹ GAP Ğ±ĞµĞ· overlap Ğ½Ğµ ÑƒĞ´Ğ°Ğ»ÑĞµÑ‚ÑÑ",
        # Ğ¤Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ ÑĞ»Ğ¾Ğ²Ğ¾ Ğ´Ğ»Ğ¸Ğ½Ğ½ĞµĞµ 3 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ² â€” Ğ½Ğµ Ğ¿Ğ¾Ğ¿Ğ°Ğ´Ğ°ĞµÑ‚ Ğ¿Ğ¾Ğ´ fragment guard
        "gap_text":  "Ñ‚Ğ°ĞºĞ¸Ğ¼ Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ¼ ÑƒĞ´Ğ°Ñ€ Ğ±Ñ‹Ğ» Ğ½Ğ°Ğ½ĞµÑÑ‘Ğ½ Ğ¾Ğ´Ğ½Ğ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾ Ñ ÑĞµĞ²ĞµÑ€Ğ°",
        "prev_text": "Ğº ÑÑ‚Ğ¾Ğ¼Ñƒ Ğ¼Ğ¾Ğ¼ĞµĞ½Ñ‚Ñƒ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ ÑĞ¸Ğ»Ñ‹ ÑƒĞ¶Ğµ Ğ²Ñ‹ÑˆĞ»Ğ¸ Ğ½Ğ° Ñ€ÑƒĞ±ĞµĞ¶ Ğ°Ñ‚Ğ°ĞºĞ¸",
        "next_text": "Ñ‡Ñ‚Ğ¾ Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»Ğ¸Ğ»Ğ¾ Ğ¾ĞºÑ€ÑƒĞ¶Ğ¸Ñ‚ÑŒ Ğ³Ñ€ÑƒĞ¿Ğ¿Ğ¸Ñ€Ğ¾Ğ²ĞºÑƒ Ğ¿Ñ€Ğ¾Ñ‚Ğ¸Ğ²Ğ½Ğ¸ĞºĞ° Ğ² ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğµ ÑÑ€Ğ¾ĞºĞ¸",
        "boundary_adjusted": False,
        "must_contain": "Ñ‚Ğ°ĞºĞ¸Ğ¼ Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ¾Ğ¼ ÑƒĞ´Ğ°Ñ€ Ğ±Ñ‹Ğ» Ğ½Ğ°Ğ½ĞµÑÑ‘Ğ½ Ğ¾Ğ´Ğ½Ğ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾ Ñ ÑĞµĞ²ĞµÑ€Ğ°",
        "must_not_contain": None,
        "note": "Ğ§Ğ¸ÑÑ‚Ñ‹Ğ¹ GAP â€” Ğ½Ğµ Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ ÑƒĞ´Ğ°Ğ»ÑÑ‚ÑŒÑÑ Ğ½Ğ¸ OLD Ğ½Ğ¸ NEW.",
    },
    {
        "id": "TC-05",
        "desc": "Regression: boundary_adjusted=True â€” OLD Ğ¸ NEW Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ÑÑ‚ Ğ¾Ğ´Ğ¸Ğ½Ğ°ĞºĞ¾Ğ²Ğ¾",
        "gap_text":  "ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ Ğ¾Ñ„Ğ¸Ñ†ĞµÑ€ÑĞºĞ¸Ğ¼Ğ¸ Ğ¿Ğ°Ñ‚Ñ€ÑƒĞ»ÑĞ¼Ğ¸ ÑÑ‚Ğ¾ Ğ±Ñ‹Ğ»Ğ¾ Ğ²Ğ°Ğ¶Ğ½Ğ¾",
        "prev_text": "Ñ€Ğ°ÑĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞ»Ğ°ÑÑŒ Ğ½Ğµ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾ Ñ€ĞµĞ³ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²Ñ‰Ğ¸ĞºĞ°Ğ¼Ğ¸ Ğ° ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¼Ğ¸ Ğ¾Ñ„Ğ¸Ñ†ĞµÑ€ÑĞºĞ¸Ğ¼Ğ¸ Ğ¿Ğ°Ñ‚Ñ€ÑƒĞ»ÑĞ¼Ğ¸",
        "next_text": "ÑÑ‚Ğ¾ Ğ´Ğ°Ğ²Ğ°Ğ»Ğ¾ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ Ğ±Ñ‹ÑÑ‚Ñ€Ğ¾ ÑĞ¾ÑÑ€ĞµĞ´Ğ¾Ñ‚Ğ¾Ñ‡Ğ¸Ñ‚ÑŒ Ğ¾Ğ³Ğ¾Ğ½ÑŒ",
        "boundary_adjusted": True,
        "must_contain": "ÑÑ‚Ğ¾ Ğ±Ñ‹Ğ»Ğ¾ Ğ²Ğ°Ğ¶Ğ½Ğ¾",
        "must_not_contain": None,
        "note": "ĞŸÑ€Ğ¸ boundary_adjusted=True OLD Ñ‚Ğ¾Ğ¶Ğµ Ğ»Ğ¾Ğ²Ğ¸Ñ‚ overlap (regression).",
    },
]


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# RUNNER
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def run():
    print("=" * 70)
    print("  sim_bugC_gap_overlap.py â€” BAG_C / #18 regression simulation")
    print("=" * 70)

    old_results = []
    new_results = []

    for tc in TEST_CASES:
        out_old = simulate_gap_OLD(
            tc["gap_text"], tc["prev_text"], tc["next_text"],
            boundary_adjusted=tc["boundary_adjusted"]
        )
        out_new = simulate_gap_NEW(
            tc["gap_text"], tc["prev_text"], tc["next_text"],
            boundary_adjusted=tc["boundary_adjusted"]
        )

        def check(output, tc):
            ok = True
            if tc["must_contain"] and tc["must_contain"] not in output:
                ok = False
            if tc["must_not_contain"] and tc["must_not_contain"] in output:
                ok = False
            return ok

        old_ok = check(out_old, tc)
        new_ok = check(out_new, tc)
        old_results.append(old_ok)
        new_results.append(new_ok)

        print(f"\n[{tc['id']}] {tc['desc']}")
        print(f"  Ğ—Ğ°Ğ¼ĞµÑ‚ĞºĞ°: {tc['note']}")
        print(f"  OLD: {'âœ…' if old_ok else 'âŒ'}  result='{out_old[:80]}'")
        print(f"  NEW: {'âœ…' if new_ok else 'âŒ'}  result='{out_new[:80]}'")

    print("\n" + "=" * 70)
    old_score = sum(old_results)
    new_score = sum(new_results)
    total     = len(TEST_CASES)
    print(f"  OLD (Ğ´Ğ¾ v17.12): {old_score}/{total}  "
          f"{'ğŸŸ¢ GREEN' if old_score == total else 'ğŸ”´ RED'}")
    print(f"  NEW (v17.12 FIX): {new_score}/{total}  "
          f"{'ğŸŸ¢ GREEN' if new_score == total else 'ğŸ”´ RED'}")
    print("=" * 70)

    if new_score == total:
        print("\nâœ… SIMULATION GREEN â€” Ñ„Ğ¸ĞºÑ v17.12 Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ğ¾.")
        import sys; sys.exit(0)
    else:
        print("\nâŒ SIMULATION RED â€” Ñ„Ğ¸ĞºÑ Ğ½Ğµ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚, ĞºĞ¾Ğ¼Ğ¼Ğ¸Ñ‚ Ğ·Ğ°Ğ¿Ñ€ĞµÑ‰Ñ‘Ğ½!")
        import sys; sys.exit(1)


if __name__ == "__main__":
    run()
