"""
sim_bugB_clean_loops_rephrase.py
Ğ¢ĞµÑÑ‚ LOOKAHEAD GUARD Ğ´Ğ»Ñ BAG_B â€” Ñ€ĞµÑ„Ñ€Ğ°Ğ· ÑĞ¿Ğ¸ĞºĞµÑ€Ğ° Ğ½Ğµ ÑĞ²Ğ»ÑĞµÑ‚ÑÑ loop artifact
"""
import sys, os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..'))

from difflib import SequenceMatcher
import re

# â”€â”€ ĞœĞ¸Ğ½Ğ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ğ°Ñ‚Ñ‡ clean_loops Ğ´Ğ»Ñ Ñ‚ĞµÑÑ‚Ğ° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
RUSSIAN_STOP_WORDS = {
    'Ğ±Ñ‹Ğ»','Ğ±Ñ‹Ğ»Ğ°','Ğ±Ñ‹Ğ»Ğ¾','Ğ±Ñ‹Ğ»Ğ¸','Ğ²','Ğ²Ğ¾','Ğ½Ğ°','Ñ','Ğº','Ğ¿Ğ¾','Ğ¸Ğ·','Ğ·Ğ°',
    'Ğ¸','Ğ°','Ğ½Ğ¾','Ğ¸Ğ»Ğ¸','Ñ‡Ñ‚Ğ¾','ĞºĞ°Ğº','ĞµÑĞ»Ğ¸','ĞºĞ¾Ğ³Ğ´Ğ°','Ğ½Ğµ','Ğ´Ğ°','Ñ‚Ğ¾','Ñ‚Ğ°Ğº',
    'Ñ','Ñ‚Ñ‹','Ğ¾Ğ½','Ğ¾Ğ½Ğ°','Ğ¼Ñ‹','Ğ²Ñ‹','Ğ¾Ğ½Ğ¸','ÑÑ‚Ğ¾','ÑÑ‚Ğ¾Ñ‚','ÑÑ‚Ğ°','ÑÑ‚Ğ¸',
    'Ñ‚Ğ°Ğ¼','Ñ‚ÑƒÑ‚','ÑƒĞ¶Ğµ','ĞµÑ‰Ğµ','Ğ¾Ñ‡ĞµĞ½ÑŒ',
}
MIN_MEANINGFUL_WORDS = 2
LOOP_WINDOW = 30
LOOKAHEAD_SIM_THRESHOLD = 0.70   # Ğ½Ğ¸Ğ¶Ğµ â†’ Ñ€ĞµÑ„Ñ€Ğ°Ğ· â†’ Ğ½Ğµ ÑƒĞ´Ğ°Ğ»ÑÑ‚ÑŒ


def _count_meaningful(phrase):
    clean = re.sub(r'[.,!?;:Â«Â»"\'()\[\]]', '', phrase.lower())
    return sum(1 for w in clean.split() if w not in RUSSIAN_STOP_WORDS)


def _find_after_anchor(cleaned, anchor_phrase):
    """ĞĞ°Ğ¹Ñ‚Ğ¸ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½ĞµĞµ Ğ²Ñ…Ğ¾Ğ¶Ğ´ĞµĞ½Ğ¸Ğµ anchor Ğ² cleaned[], Ğ²ĞµÑ€Ğ½ÑƒÑ‚ÑŒ 3 ÑĞ»Ğ¾Ğ²Ğ° Ğ¿Ğ¾ÑĞ»Ğµ."""
    anchor_words = re.sub(r'[.,!?;:Â«Â»"\'()\[\]]', '', anchor_phrase.lower()).split()
    if not anchor_words:
        return []
    cleaned_lower = [re.sub(r'[.,!?;:Â«Â»"\'()\[\]]', '', w.lower()) for w in cleaned]
    first = anchor_words[0]
    for i in range(len(cleaned_lower) - 1, -1, -1):
        if cleaned_lower[i] == first:
            return cleaned[i + len(anchor_words): i + len(anchor_words) + 3]
    return []


def clean_loops_patched(text, debug=False):
    words = text.split()
    seen = []
    cleaned = []
    i = 0

    while i < len(words):
        phrase = ' '.join(words[i:i+3])
        phrase_lower = phrase.lower()

        if _count_meaningful(phrase_lower) < MIN_MEANINGFUL_WORDS:
            cleaned.extend(words[i:i+3])
            i += 3
            continue

        is_loop = False
        matched_anchor = None

        for prev_phrase in seen:
            sim = SequenceMatcher(None, phrase_lower, prev_phrase).ratio()
            if sim >= 0.75:
                is_loop = True
                matched_anchor = prev_phrase
                break

        if is_loop:
            # â”€â”€ LOOKAHEAD GUARD â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            after_anchor    = _find_after_anchor(cleaned, matched_anchor)
            after_candidate = words[i+3:i+6]
            if after_anchor and after_candidate:
                sim_after = SequenceMatcher(
                    None,
                    ' '.join(after_anchor).lower(),
                    ' '.join(after_candidate).lower()
                ).ratio()
                if sim_after < LOOKAHEAD_SIM_THRESHOLD:
                    if debug:
                        print(f"  ğŸ”„ Ğ Ğ•Ğ¤Ğ ĞĞ—: after_anchor={after_anchor} "
                              f"vs after_cand={after_candidate} "
                              f"sim={sim_after:.2f} < {LOOKAHEAD_SIM_THRESHOLD} â†’ KEEP")
                    seen.append(phrase_lower)
                    if len(seen) > LOOP_WINDOW:
                        seen.pop(0)
                    cleaned.extend(words[i:i+3])
                    i += 3
                    continue
            # â”€â”€ ĞºĞ¾Ğ½ĞµÑ† LOOKAHEAD GUARD â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

            # Ğ’Ğ¸ÑÑÑ‡Ğ¸Ğ¹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ³ (v17.10)
            last_word = cleaned[-1].lower().rstrip('.,!?Â«Â»') if cleaned else ""
            HANGING = {'Ğ½Ğ°','Ğ²','Ğ²Ğ¾','Ñ','ÑĞ¾','Ğº','Ğ¿Ğ¾','Ğ¸Ğ·','Ğ·Ğ°','Ğ´Ğ¾','Ğ¿Ñ€Ğ¸','Ñ‡ĞµÑ€ĞµĞ·','Ğ¾','Ğ¾Ğ±','Ñƒ','Ğ´Ğ»Ñ','Ğ¾Ñ‚','Ğ¿Ğ¾Ğ´','Ğ½Ğ°Ğ´'}
            if last_word in HANGING:
                seen.append(phrase_lower)
                if len(seen) > LOOP_WINDOW:
                    seen.pop(0)
                cleaned.extend(words[i:i+3])
                i += 3
                continue

            if debug:
                print(f"  ğŸ” LOOP: '{phrase}' â‰ˆ '{matched_anchor}' â†’ DROP")
            i += 1
            continue

        seen.append(phrase_lower)
        if len(seen) > LOOP_WINDOW:
            seen.pop(0)
        cleaned.extend(words[i:i+3])
        i += 3

    return ' '.join(cleaned).strip()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ¢Ğ•Ğ¡Ğ¢Ğ«
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
PASS = "âœ… GREEN"; FAIL = "âŒ RED"
results = []

def run_test(name, text, must_contain, must_not_contain=None):
    result = clean_loops_patched(text, debug=True)
    ok = all(m in result for m in must_contain)
    if must_not_contain:
        ok = ok and all(m not in result for m in must_not_contain)
    results.append(ok)
    print(f"\n{'â”€'*60}")
    print(f"{PASS if ok else FAIL}  {name}")
    print(f"  Ğ’Ğ¥ĞĞ”:  {text[:80]}...")
    print(f"  Ğ’Ğ«Ğ¥ĞĞ”: {result[:80]}...")
    for m in must_contain:
        print(f"  {'âœ…' if m in result else 'âŒ'} ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ '{m}'")
    if must_not_contain:
        for m in must_not_contain:
            print(f"  {'âœ…' if m not in result else 'âŒ'} ĞĞ• ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ '{m}'")


# Ğ¢Ğ•Ğ¡Ğ¢ 1: BAG_B â€” Ñ€ĞµÑ„Ñ€Ğ°Ğ· Ñ Ğ¸Ğ¼ĞµĞ½ĞµĞ¼ Ğ˜ÑĞºÑ€Ñ‹ (Ğ¾Ğ±Ğ° Ğ²Ñ…Ğ¾Ğ¶Ğ´ĞµĞ½Ğ¸Ñ Ğ´Ğ¾Ğ»Ğ¶Ğ½Ñ‹ Ğ¾ÑÑ‚Ğ°Ñ‚ÑŒÑÑ)
run_test(
    "BAG_B: Ñ€ĞµÑ„Ñ€Ğ°Ğ· 'Ğ˜ÑĞºÑ€Ñ‹, Ğ¾Ñ‚Ñ†Ğ¾Ğ¼ ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ¾Ğ³Ğ¾' â†’ 'Ğ˜ÑĞºÑ€Ñ‹, Ğ¾Ñ‚Ñ†Ğ¾Ğ¼ ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ¾Ğ¹'",
    ("ĞŸĞ¾ÑÑ‚Ğ¾Ğ¼Ñƒ Ğ¿Ğ»Ğ°Ğ½ Ğ˜ÑĞºÑ€Ñ‹, Ğ¾Ñ‚Ñ†Ğ¾Ğ¼ ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ¾Ğ³Ğ¾, Ğ±ĞµĞ·ÑƒÑĞ»Ğ¾Ğ²Ğ½Ğ¾, Ğ±Ñ‹Ğ» Ğ¿Ñ€ĞµĞ¶Ğ´Ğµ Ğ²ÑĞµĞ³Ğ¾ "
     "Ğ›ĞµĞ¾Ğ½Ğ¸Ğ´ Ğ“Ğ¾Ğ²Ğ¾Ñ€Ğ¾Ğ², Ğ±Ñ‹Ğ»Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğ° Ğ¿Ğ»Ğ°Ğ½Ğ° Ğ˜ÑĞºÑ€Ñ‹, Ğ¾Ñ‚Ñ†Ğ¾Ğ¼ ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ¾Ğ¹ Ğ±Ñ‹Ğ», "
     "Ğ±ĞµĞ·ÑƒÑĞ»Ğ¾Ğ²Ğ½Ğ¾, Ğ“Ğ¾Ğ²Ğ¾Ñ€Ğ¾Ğ², Ğ±Ñ‹Ğ»Ğ¾ Ñ‚Ğ¾, Ñ‡Ñ‚Ğ¾ Ğ²ĞµÑÑŒ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ğ¹ Ğ¾Ğ¿Ñ‹Ñ‚ Ğ±Ñ‹Ğ» Ğ¿Ñ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½"),
    must_contain=["Ğ¿Ğ»Ğ°Ğ½Ğ° Ğ˜ÑĞºÑ€Ñ‹", "ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ¾Ğ¹"],
    must_not_contain=[]
)

# Ğ¢Ğ•Ğ¡Ğ¢ 2: ĞĞ°ÑÑ‚Ğ¾ÑÑ‰Ğ¸Ğ¹ loop artifact (Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ ÑƒĞ´Ğ°Ğ»Ğ¸Ñ‚ÑŒÑÑ)
run_test(
    "Ğ ĞµĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ loop: Ğ´Ğ¾ÑĞ»Ğ¾Ğ²Ğ½Ğ¾Ğµ Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€ĞµĞ½Ğ¸Ğµ",
    ("ĞĞµĞ¼ĞµÑ†ĞºĞ¸Ğµ Ğ²Ğ¾Ğ¹ÑĞºĞ° Ğ°Ñ‚Ğ°ĞºĞ¾Ğ²Ğ°Ğ»Ğ¸ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ ÑĞ¾Ğ²ĞµÑ‚ÑĞºĞ¸Ñ… Ğ²Ğ¾Ğ¹ÑĞº. "
     "ĞĞµĞ¼ĞµÑ†ĞºĞ¸Ğµ Ğ²Ğ¾Ğ¹ÑĞºĞ° Ğ°Ñ‚Ğ°ĞºĞ¾Ğ²Ğ°Ğ»Ğ¸ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ ÑĞ¾Ğ²ĞµÑ‚ÑĞºĞ¸Ñ… Ğ°Ñ€Ğ¼Ğ¸Ğ¹ Ğ¸ Ğ¿Ñ€Ğ¾Ğ´Ğ²Ğ¸Ğ³Ğ°Ğ»Ğ¸ÑÑŒ Ğ²Ğ¿ĞµÑ€Ñ‘Ğ´."),
    must_contain=["ĞĞµĞ¼ĞµÑ†ĞºĞ¸Ğµ Ğ²Ğ¾Ğ¹ÑĞºĞ°"],
    must_not_contain=[]
)

# Ğ¢Ğ•Ğ¡Ğ¢ 3: BAG_A regression â€” Ğ²Ğ¸ÑÑÑ‡Ğ¸Ğ¹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ³ (Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ¾ÑÑ‚Ğ°Ñ‚ÑŒÑÑ)
run_test(
    "BAG_A regression: Ğ²Ğ¸ÑÑÑ‡Ğ¸Ğ¹ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ³ 'Ğ½Ğ°'",
    ("Ñ„Ñ€Ğ¾Ğ½Ñ‚Ğ° Ğ½Ğ° Ğ¿Ñ€Ğ¾Ñ€Ñ‹Ğ² Ğ±Ğ»Ğ¾ĞºĞ°Ğ´Ñ‹ Ğ¸Ğ·Ğ½ÑƒÑ‚Ñ€Ğ¸. "
     "ĞĞ°Ğ´ĞµĞ¶Ğ´Ğ¾Ğ¹ Ğ½Ğ° Ğ¿Ñ€Ğ¾Ñ€Ñ‹Ğ²Ğ° Ğ±Ğ»Ğ¾ĞºĞ°Ğ´Ğ° Ğ¸Ğ·Ğ½ÑƒÑ‚Ñ€Ğ¸ Ğ±Ñ‹Ğ» Ğ“Ğ¾Ğ²Ğ¾Ñ€Ğ¾Ğ²."),
    must_contain=["Ğ¿Ñ€Ğ¾Ñ€Ñ‹Ğ² Ğ±Ğ»Ğ¾ĞºĞ°Ğ´Ñ‹"],
)

# Ğ¢Ğ•Ğ¡Ğ¢ 4: Ğ ĞµÑ„Ñ€Ğ°Ğ· Ğ±ĞµĞ· ÑƒĞ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ¼ĞµĞ½Ğ¸ (Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½Ğ¸Ğµ Ğ²ÑÑ‘ Ñ€Ğ°Ğ²Ğ½Ğ¾ Ñ€Ğ°Ğ·Ğ½Ğ¾Ğµ)
run_test(
    "Ğ ĞµÑ„Ñ€Ğ°Ğ· Ğ±ĞµĞ· Ğ¸Ğ¼ĞµĞ½Ğ¸ ÑĞ¾Ğ±ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾",
    ("Ğ¾ÑĞ½Ğ¾Ğ²Ñƒ Ğ¾Ğ±Ğ¾Ñ€Ğ¾Ğ½Ñ‹ ÑĞ¾ÑÑ‚Ğ°Ğ²Ğ»ÑĞ»Ğ¸ ÑÑ‚Ñ€ĞµĞ»ĞºĞ¾Ğ²Ñ‹Ğµ Ñ‡Ğ°ÑÑ‚Ğ¸, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ğ´ĞµÑ€Ğ¶Ğ°Ğ»Ğ¸ Ñ„Ñ€Ğ¾Ğ½Ñ‚. "
     "Ğ¾ÑĞ½Ğ¾Ğ²Ñƒ Ğ¾Ğ±Ğ¾Ñ€Ğ¾Ğ½Ñ‹ ÑĞ¾ÑÑ‚Ğ°Ğ²Ğ»ÑĞ»Ğ¸ ÑÑ‚Ñ€ĞµĞ»ĞºĞ¾Ğ²Ñ‹Ğµ Ñ‡Ğ°ÑÑ‚Ğ¸, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¼ Ğ½Ğµ Ñ…Ğ²Ğ°Ñ‚Ğ°Ğ»Ğ¾ Ğ±Ğ¾ĞµĞ¿Ñ€Ğ¸Ğ¿Ğ°ÑĞ¾Ğ²."),
    must_contain=["ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¼ Ğ½Ğµ Ñ…Ğ²Ğ°Ñ‚Ğ°Ğ»Ğ¾"],
)

print(f"\n{'='*60}")
print(f"Ğ˜Ğ¢ĞĞ“: {sum(results)}/{len(results)} GREEN")
